<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="ssdtools">
<title>Model Averaged SSDs • ssdtools</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Model Averaged SSDs">
<meta property="og:description" content="ssdtools">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">ssdtools</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.6.9015</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/ssdtools.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../articles/index.html">Articles</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/bcgov/ssdtools/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Model Averaged SSDs</h1>
                        <h4 data-toc-skip class="author">ssdtools
Team</h4>
            
            <h4 data-toc-skip class="date">2024-05-16</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/bcgov/ssdtools/blob/HEAD/vignettes/model-averaging.Rmd" class="external-link"><code>vignettes/model-averaging.Rmd</code></a></small>
      <div class="d-none name"><code>model-averaging.Rmd</code></div>
    </div>

    
    
<style type="text/css">
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 200px;
}
</style>
<style type="text/css">
.scroll-200 {
  max-height: 200px;
  overflow-y: auto;
  background-color: inherit;
}
</style>
<style>

.box {
  height: auto;
  width: 65%;
  padding: 10px;
  border: 1.5px outset #5C5B5D;
  background-color: #E7E8EC;
  border-radius: 8px;
  text-align: left;
  margin: auto;
}

</style>
<script type="text/x-mathjax-config">MathJax.Hub.Config({  "HTML-CSS": { minScaleAdjust: 0.5, availableFonts: [] }  });
</script><div class="section level2">
<h2 id="background">Background<a class="anchor" aria-label="anchor" href="#background"></a>
</h2>
<p><em>“Many authors have noted that there is no guiding theory in
ecotoxicology to justify any particular distributional form for the SSD
other than that its domain be restricted to the positive real line <span class="citation">(Newman et al. 2000)</span>, <span class="citation">(Zajdlik 2005)</span>, <span class="citation">(Chapman
et al. 2007)</span>, <span class="citation">(Fox 2016)</span>. Indeed,
<span class="citation">(Chapman et al. 2007)</span> described the
identification of a suitable probability model as one of the most
important and difficult choices in the use of SSDs. Compounding this
lack of clarity about the functional form of the SSD is the omnipresent,
and equally vexatious issue of small sample size, meaning that any
plausible candidate model is unlikely to be rejected <span class="citation">(Fox et al. 2021a)</span>. The ssdtools R package uses
a model averaging procedure to avoid the need to a-priori select a
candidate distribution and instead uses a measure of ‘fit’ for each
model to compute weights to be applied to an initial set of candidate
distributions. The method, as applied in the SSD context is described in
detail in <span class="citation">(Fox et al. 2021a)</span>, and
potentially provides a level of flexibility and parsimony that is
difficult to achieve with a single SSD distribution”.</em>         <span class="citation">(Fox et al. 2021b)</span></p>
</div>
<div class="section level2">
<h2 id="preliminaries">Preliminaries<a class="anchor" aria-label="anchor" href="#preliminaries"></a>
</h2>
Before we jump into model averaging and in particular, SSD Model
Averaging, let’s backup a little and consider why we average and the
advantages and disadvantages of averaging.<br><h4 id="preliminaries-1">
The pros and cons of averaging
<a class="anchor" aria-label="anchor" href="#preliminaries-1"></a>
</h4>
<p>We’re all familiar with the process of averaging. Indeed,
<em>averages</em> are pervasive in everyday life - we talk of average
income; mean sea level; average global temperature; average height,
weight, age etc. etc. So what’s the obsession with <em>averaging</em>?
It’s simple really - it’s what statisticians call <u>data reduction</u>
which is just a fancy name to describe the process of summarising a lot
of <em>raw data</em> using a small number of (hopefully) representative
<u>summary statistics</u> such as the mean and the standard deviation.
Clearly, it’s a lot easier to work with just a single mean than all the
individual data values. That’s the upside. The downside is that the
process of data reduction decimates your original data - you lose
information in the process. Nevertheless, the benefits tend to outweigh
this information loss. Indeed, much of ‘conventional’ statistical theory
and practice is focused on the mean. Examples include T-tests, ANOVA,
regression, and clustering. When we talk of an ‘average’ we are usually
referring to the simple, <em>arithmetic mean</em>:<span class="math display">\[\bar{X}=\frac{1}{n}\sum\limits_{i=1}^{n}{{{X}_{i}}}\]</span>
although we recognize there are other types of mean including the
geometric mean, the harmonic mean and the weighted mean. The last of
these is particularly pertinent to model averaging.</p>
<div class="section level3">
<h3 id="weighted-averages">Weighted Averages<a class="anchor" aria-label="anchor" href="#weighted-averages"></a>
</h3>
<p>For the simple arithmetic mean, all of the individual values receive
the same weighting - they each contribute <span class="math inline">\(\frac{1}{n}\)</span> to the summation. While this
is appropriate in many cases, it’s not useful when the components
contribute to varying degrees. An example familiar to ecotoxicologists
is that of a <em>time-varying</em> concentration as shown in the figure
below.<br></p>
<p><img src="images/Figure1.jpg" style="width:90.0%" align="center"></p>
<p>From the figure we see there are 5 concentrations going from left to
to right: <span class="math inline">\(\left\{ 0.25,0.95,0.25,0.12,0.5
\right\}\)</span>. If we were to take the simple arithmetic mean of
these concentrations we get <span class="math inline">\(\bar{X}=0.414\)</span>. But this ignores the
different <em>durations</em> of these 5 concentrations. Of the 170
hours, 63 were at concentration 0.25, 25 at concentration 0.95, 23 at
concentration 0.25, 23 at concentration 0.12, and 36 at concentration
0.50. So if we were to <em>weight</em> these concentrations by time
have:<br><span class="math display">\[{{{\bar{X}}}_{TW}}=\frac{\left(
63\cdot 0.25+25\cdot 0.95+23\cdot 0.25+23\cdot 0.12+36\cdot 0.50
\right)}{\left( 63+25+23+23+36
\right)}=\frac{56.01}{170}=0.33\]</span><br>So, our formula for a
<em>weighted average</em> is:<span class="math display">\[\bar{X}=\sum\limits_{i=1}^{n}{{{w}_{i}}{{X}_{i}}}\]</span>
with <span class="math inline">\(0\le {{w}_{i}}\le 1\)</span> and <span class="math inline">\(\sum\limits_{i=1}^{n}{{{w}_{i}}=1}\)</span>.<br>Note,
the simple arithmetic mean is just a special case of the weighted mean
with <span class="math inline">\(\sum\limits_{i=1}^{n}{{{w}_{i}}=\frac{1}{n}}\)</span>
; <span class="math inline">\(\forall i=1,\ldots ,n\)</span></p>
</div>
</div>
<div class="section level2">
<h2 id="model-averaging">Model Averaging<a class="anchor" aria-label="anchor" href="#model-averaging"></a>
</h2>
<p>The <em>weighted average</em> acknowledges that the elements in the
computation are <u>not</u> of equal ‘importance’. In the example above,
this importance was based on the <em>proportion of time</em> that the
concentration was at a particular level. Bayesians are well-versed in
this concept - the elicitation of <em>prior distributions</em> for model
parameters provides a mechanism for weighting the degree to which the
analysis is informed by existing knowledge versus using a purely
data-driven approach. Model averaging is usually used in the context of
estimating model parameters or quantities derived from a fitted model -
for example an EC50 derived from a C-R model. Let’s motivate the
discussion using the following small dataset of toxicity estimates for
some chemical.</p>
<pre><code><span><span class="co">#&gt;  [1] 1.73 0.57 0.33 0.28 0.30 0.29 2.15 0.80 0.76 0.54 0.42 0.83 0.21 0.18 0.59</span></span></code></pre>
<p>Now, suppose we have only two possibilities for fitting an SSD - both
lognormal distributions. Model 1 is the LN(-1.067,0.414) distribution
while Model 2 is the LN(-0.387,0.617) distribution. A plot of the
empirical <em>cdf</em> and Models 1 and 2 is shown below.</p>
<div class="figure">
<img src="model-averaging_files/figure-html/unnamed-chunk-6-1.png" alt="Emprirical cdf (black); Model 1(green); and Model 2 (blue)" width="672"><p class="caption">
Emprirical cdf (black); Model 1(green); and Model 2 (blue)
</p>
</div>
<p><br>We see that Model 1 fits well in the lower, left region and
poorly in the upper region, while the reverse is true for Model 2. So
using <em>either</em> Model 1 <strong>or</strong> Model 2 is going to
result in a poor fit overall. However, the obvious thing to do is to
<strong>combine</strong> both models. We could just try using 50% of
Model 1 and 50% of Model 2, but that may be sub-optimal. It turns out
that the best fit is obtained by using 44% of Model 1 and 56% of Model
2. Redrawing the plot and adding the <em>weighted average</em> of Models
1 and 2 is shown below.</p>
<div class="figure">
<img src="model-averaging_files/figure-html/unnamed-chunk-7-1.png" alt="Empirical cdf (black); Model 1(green); Model 2 (blue); and averaged Model (red)" width="672"><p class="caption">
Empirical cdf (black); Model 1(green); Model 2 (blue); and averaged
Model (red)
</p>
</div>
<p><br>Clearly the strategy has worked - we now have an excellent
fitting SSD.What about estimation of an <em>HC20</em>? It’s a simple
matter to work out the <em>individual</em> <em>HC20</em> values for
Models 1&amp;2 using the appropriate <code><a href="https://rdrr.io/r/stats/Lognormal.html" class="external-link">qlnorm()</a></code> function in
<code>R</code>. Thus we have:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Model 1 HC20</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Model 1 HC20 ="</span>,<span class="fu"><a href="https://rdrr.io/r/stats/Lognormal.html" class="external-link">qlnorm</a></span><span class="op">(</span><span class="fl">0.2</span>,<span class="op">-</span><span class="fl">1.067</span>,<span class="fl">0.414</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Model 1 HC20 = 0.2428209</span></span>
<span></span>
<span><span class="co"># Model 2 HC20</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Model 2 HC20 ="</span>,<span class="fu"><a href="https://rdrr.io/r/stats/Lognormal.html" class="external-link">qlnorm</a></span><span class="op">(</span><span class="fl">0.2</span>,<span class="op">-</span><span class="fl">0.387</span>,<span class="fl">0.617</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Model 2 HC20 = 0.4040243</span></span></code></pre></div>
<p>What about the averaged distribution? An intuitively appealing
approach would be to apply the same weights to the individual
<em>HC20</em> values as was applied to the respective models. That is
<code>0.44*0.2428209 + 0.56*0.4040243 = 0.33</code>.</p>
<p>So our model-averaged <em>HC20</em> estimate is 0.33. As a check, we
can determine the <em>fraction affected</em> at concentration = 0.33 -
it should of course be 20%. Let’s take a look at the plot.</p>
<p><img src="model-averaging_files/figure-html/unnamed-chunk-9-1.png" width="672"></p>
<p>Something’s wrong - the fraction affected at concentration 0.33 is
30% - <strong>not the required 20%</strong>. This issue is taken up in
the next section</p>
</div>
<div class="section level2">
<h2 id="model-averaged-ssds">Model Averaged SSDs<a class="anchor" aria-label="anchor" href="#model-averaged-ssds"></a>
</h2>
As we’ve just seen, applying the model weights to component <em>HCx</em>
values and summing does <strong>not</strong> produce the correct result.
The reason for this can be explained mathematically as follows (<em>if
your not interested in the mathematical explanation - skip ahead to the
next section</em>).
<h4 id="model-averaged-ssds-1">
The fallacy of weighting individual <em>HCx</em> values
<a class="anchor" aria-label="anchor" href="#model-averaged-ssds-1"></a>
</h4>
<p>The correct expression for a model-averaged SSD is: <span class="math display">\[G\left( x \right) = \sum\limits_{i = 1}^k {{w_i}}
{F_i}\left( x \right)\]</span> where <span class="math inline">\({F_i}\left(  \cdot  \right)\)</span> is the
<em>i<sup>th</sup></em> component SSD (i.e. <em>cdf</em>) and
<em>w<sub>i</sub></em> is the weight assigned to <span class="math inline">\({F_i}\left(  \cdot  \right)\)</span>. <br>Notice
that the function <span class="math inline">\(G\left( x \right)\)</span>
is a proper <em>cumulative distribution function</em> (<em>cdf</em>)
which means for a given quantile, <em>x</em>, <span class="math inline">\(G\left( x \right)\)</span> returns the
<em>cumulative probability</em>: <span class="math display">\[P\left[ {X
\leqslant x} \right]\]</span></p>
<p><br>Now, the <em>incorrect</em> approach takes a weighted sum of the
component <em>inverse cdf’s</em>, that is:</p>
<span class="math display">\[H\left( p \right) = \sum\limits_{i = 1}^k
{{w_i}} {F_i}^{ - 1}\left( p \right)\]</span> where <span class="math inline">\({F_i}^{ - 1}\left(  \cdot  \right)\)</span> is the
<em>i<sup>th</sup></em> <em>inverse cdf</em>. Notice that <span class="math inline">\({G_i}\left(  \cdot  \right)\)</span> is a function
of a <em>quantile</em> and returns a <strong>probability</strong> while
<span class="math inline">\({H_i}\left(  \cdot  \right)\)</span> is a
function of a <em>probability</em> and returns an
<strong>quantile</strong>.
<p>
Now, the <u>correct</u> method of determining the <em>HCx</em> is to
work with the proper model-averaged <em>cdf</em> <span class="math inline">\(G\left( x \right)\)</span>. This means finding the
<strong>inverse</strong> function <span class="math inline">\({G^{ -
1}}\left( p \right)\)</span>. We’ll address how we do this in a moment.
</p>
The reason why <span class="math inline">\(H\left( p \right)\)</span>
does <strong>not</strong> return the correct result is because of <u>the
implicit assumption that the inverse of <span class="math inline">\(G\left( x \right)\)</span> is equivalent to <span class="math inline">\(H\left( p \right)\)</span>.</u> This is akin to
stating the inverse of a <em>sum</em> is equal to the sum of the
inverses i.e. <span class="math display">\[\sum\limits_{i = 1}^n
{\frac{1}{{{X_i}}}}  = \frac{1}{{\sum\limits_{i = 1}^n {{X_i}}
}}{\text{  ???}}\]</span>
<hr>
<b><u>For the mathematical nerds:</u></b> There are some very special
cases where the above identity does in fact hold, but for that you need
to use <strong>complex numbers</strong>.
<p>
For example, consider two complex numbers <span class="math display">\[{\text{a = }}\frac{{\left( {5 - i}
\right)}}{2}{\text{   and     }}b =  - 1.683 - 1.915i\]</span> It can be
shown that <span class="math display">\[\frac{1}{{a + b}} = \frac{1}{a}
+ \frac{1}{b} = 0.126 + 0.372i\]</span>
</p>
<hr>
<p>
Back to the issue at hand, and since we’re not dealing with complex
numbers, it’s safe to say:<span class="math display">\[{G^{ - 1}}\left(
p \right) \ne H\left( p \right)\]</span>
</p>
<p>If you need a visual demonstration, we can plot <span class="math inline">\(G\left( x \right)\)</span> and the
<em>inverse</em> of <span class="math inline">\(H\left( p
\right)\)</span> both as functions of <em>x</em> (a quantile) for our
two-component lognormal distribution above.</p>
<p><img src="model-averaging_files/figure-html/unnamed-chunk-10-1.png" width="768"></p>
Clearly, the two functions are <strong>not</strong> the same and thus
<em>HCx</em> values derived from each will nearly always be different
(as indicated by the positions of the vertical red and green dashed
lines in the Figure above corresponding to the 2 values of the
<em>HC20</em>). (Note: The two curves do cross over at a concentration
of about 1.12 corresponding to the 90<sup>th</sup> percentile, but in
the region of ecotoxicological interest, there is no such cross-over and
so the two approaches will <strong>always</strong> yield different
<em>HCx</em> values with this difference → 0 as x → 0).
<p>
</p>
<p>WE next discuss the use of a model-averaged SSD to obtain the
<em>correct</em> model-averaged <em>HCx</em>.</p>
</div>
<div class="section level2">
<h2 id="computing-a-model-averaged-hcx">Computing a model-averaged <em>HCx</em><a class="anchor" aria-label="anchor" href="#computing-a-model-averaged-hcx"></a>
</h2>
A proper <em>HCx</em> needs to satisfy what David Fox refers to as
<strong>the inversion principle</strong>.
<p>
More formally, the inversion principle states that an <em>HCx</em>
(denoted as <span class="math inline">\({\varphi _x}\)</span>)
<u><i>must</i></u> satisfy the following:
</p>
<p>
<span class="math display">\[df\left( {{\varphi _x}} \right) = x\quad
\quad and\quad \quad qf\left( x \right) = {\varphi _x}\]</span>
</p>
<p>
where <span class="math inline">\(df\left(  \cdot  \right)\)</span> is a
model-averaged <em>distribution function</em> (i.e. SSD) and <span class="math inline">\(qf\left(  \cdot  \right)\)</span> is a
model-averaged <em>quantile function</em>. For this equality to hold, it
is necessary that <span class="math inline">\(qf\left( p \right) = d{f^{
- 1}}\left( p \right)\)</span>.
</p>
<br>So, in our example above, the green curve was taken to be <span class="math inline">\(qf\left( x \right)\)</span> and this was used to
derive <span class="math inline">\({\varphi _x}\)</span> but the
<em>fraction affected</em> <span class="math inline">\(\left\{ { =
df\left( {{\varphi _x}} \right)} \right\}\)</span> at <span class="math inline">\({\varphi _x}\)</span> is computed using the red
curve.
<p>
In <code>ssdtools</code> the following is a check that the inversion
principle holds:
</p>
<p><br></p>
<pre><code><span><span class="co"># Obtain a model-averaged HCx using the ssd_hc() function</span></span>
<span><span class="va">hcp</span><span class="op">&lt;-</span><span class="fu"><a href="../reference/ssd_hc.html">ssd_hc</a></span><span class="op">(</span><span class="va">x</span>, p <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="co"># Check that the inversion principle holds</span></span>
<span><span class="fu"><a href="../reference/ssd_hp.html">ssd_hp</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">hcp</span>, multi_est <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">==</span> <span class="va">p</span>   <span class="co"># this should result in logical `TRUE`</span></span></code></pre>
<p><em>Note: if the <code>multi_est</code> argument is set to
<code>FALSE</code> the test will fail</em>. <br></p>
<p>
</p>
<p>The <em>inversion principle</em> ensures that we only use a
<strong>single</strong> distribution function to compute both the
<em>HCx</em> <em>and</em> the fraction affected. Referring to the figure
below, the <em>HCx</em> is obtained from the MA-SSD (red curve) by
following the → arrows while the fraction affected is obtained by
following the ← arrows.</p>
<p><img src="images/Figure2.jpg" style="width:100.0%" align="center"></p>
<p>
Finally, we’ll briefly discuss how the <em>HCx</em> is computed in
<code>R</code> using the same method as has been implemented in
<code>ssdtools</code>.
</p>
<div class="section level3">
<h3 id="computing-the-hcx-in-rssdtools">Computing the <em>HCx</em> in
<code>R</code>/<code>ssdtools</code><a class="anchor" aria-label="anchor" href="#computing-the-hcx-in-rssdtools"></a>
</h3>
Recall, our MA-SSD was given as <span class="math display">\[G\left( x
\right) = \sum\limits_{i = 1}^k {{w_i}} {F_i}\left( x \right)\]</span>
and an <em>HCx</em> is obtained from the MA-SSD by essentially working
‘in reverse’ by starting at a value of <span class="math inline">\(x\)</span> on the <strong>vertical</strong> scale
in the Figure above and following the → arrows and reading off the
corresponding value on the horizontal scale.
<p>
Obviously, we need to be able to ‘codify’ this process in <code>R</code>
(or any other computer language).<br>Mathematically this is equivalent
to seeking a solution to the following equation:<span class="math display">\[{x:G\left( x \right) = p}\]</span> or,
equivalently:<span class="math display">\[x:G\left( x \right) - p =
0\]</span> for some fraction affected, <span class="math inline">\(p\)</span>.
</p>
<p>
</p>
<p>Finding the solution to this last equation is referred to as
<em>finding the root(s)</em> of the function <span class="math inline">\(G\left( x \right)\)</span> or, as is made clear in
the figure below, <em>finding the zero-crossing</em> of the function
<span class="math inline">\(G\left( x \right)\)</span> for the case
<span class="math inline">\(p=0.2\)</span>.</p>
<p><img src="images/uniroot.jpg" style="width:100.0%" align="center"></p>
<br><p>
In <code>R</code> finding the roots of <span class="math inline">\(x:G\left( x \right) - p = 0\)</span> is achieved
using the <code><a href="https://rdrr.io/r/stats/uniroot.html" class="external-link">uniroot()</a></code> function.
</p>
<p>Help on the <code>uniroot</code> function can be found <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/uniroot.html" class="external-link">here</a></p>
</div>
</div>
<div class="section level2">
<h2 id="where-do-the-model-averaged-weights-come-from">Where do the model-averaged weights come from?<a class="anchor" aria-label="anchor" href="#where-do-the-model-averaged-weights-come-from"></a>
</h2>
<p>This is a little more complex, although we’ll try to provide a
non-mathematical explanation. For those interested in going deeper, a
more comprehensive treatment can be found in <span class="citation">(Burnham and Anderson 2002)</span> and <span class="citation">(Fletcher 2018)</span>.</p>
<p>
</p>
<p>This time, we’ll look at fitting a gamma, lognormal, and pareto
distribution to our sample data:</p>
<pre><code><span><span class="co">#&gt;  [1] 1.73 0.57 0.33 0.28 0.30 0.29 2.15 0.80 0.76 0.54 0.42 0.83 0.21 0.18 0.59</span></span></code></pre>
<p><br>The adequacy (or otherwise) of a fitted model can be assessed
using a variety of numerical measures known as
<strong>goodness-of-fit</strong> or GoF statistics. These are invariably
based on a measure of discrepancy between the emprical data and the
hypothesized model. Common GoF statistics used to test whether the
hypothesis of some specified theoretical probability distribution is
plausible for a given data set include: <em>Kolmogorov-Smirnov test;
Anderson-Darling test; Shapiro-Wilk test;and Cramer-von Mises test</em>.
<a href="https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93von_Mises_criterion" class="external-link">The
Cramer-von Mises</a> test is a good choice and is readily performed
using the <code><a href="https://rdrr.io/pkg/goftest/man/cvm.test.html" class="external-link">cvm.test()</a></code> function in the <code>goftest</code>
package in <code>R</code> as follows:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Conc<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1.73</span>,<span class="fl">0.57</span>,<span class="fl">0.33</span>,<span class="fl">0.28</span>,<span class="fl">0.3</span>,<span class="fl">0.29</span>,<span class="fl">2.15</span>,<span class="fl">0.8</span>,<span class="fl">0.76</span>,<span class="fl">0.54</span>,<span class="fl">0.42</span>,<span class="fl">0.83</span>,<span class="fl">0.21</span>,<span class="fl">0.18</span>,<span class="fl">0.59</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/baddstats/goftest" class="external-link">goftest</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/alexkowa/EnvStats" class="external-link">EnvStats</a></span><span class="op">)</span>  <span class="co"># this is required for the Pareto cdf (ppareto)</span></span>
<span></span>
<span><span class="co"># Examine the fit for the gamma distribution (NB: parameters estimated from the data)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/goftest/man/cvm.test.html" class="external-link">cvm.test</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Conc</span>,null <span class="op">=</span> <span class="st">"pgamma"</span>,shape <span class="op">=</span> <span class="fl">2.0591977</span>,scale <span class="op">=</span> <span class="fl">0.3231032</span>,estimated <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Examine the fit for the lognormal distribution (NB: parameters estimated from the data)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/goftest/man/cvm.test.html" class="external-link">cvm.test</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Conc</span>,null <span class="op">=</span> <span class="st">"plnorm"</span>,meanlog<span class="op">=</span><span class="op">-</span><span class="fl">0.6695120</span>,sd<span class="op">=</span><span class="fl">0.7199573</span>,estimated <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Examine the fit for the Pareto distribution (NB: parameters estimated from the data)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/goftest/man/cvm.test.html" class="external-link">cvm.test</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Conc</span>,null <span class="op">=</span> <span class="st">"ppareto"</span>,location <span class="op">=</span> <span class="fl">0.1800000</span>,shape    <span class="op">=</span> <span class="fl">0.9566756</span>,estimated <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code>    Cramer-von Mises test of goodness-of-fit
    Braun's adjustment using 4 groups
    Null hypothesis: Gamma distribution
    with parameters shape = 2.0591977, scale = 0.3231032
    Parameters assumed to have been estimated from data

data:  dat$Conc
omega2max = 0.34389, p-value = 0.3404


    Cramer-von Mises test of goodness-of-fit
    Braun's adjustment using 4 groups
    Null hypothesis: log-normal distribution
    with parameter meanlog = -0.669512
    Parameters assumed to have been estimated from data

data:  dat$Conc
omega2max = 0.32845, p-value = 0.3719


    Cramer-von Mises test of goodness-of-fit
    Braun's adjustment using 4 groups
    Null hypothesis: distribution ‘ppareto’
    with parameters location = 0.18, shape = 0.9566756
    Parameters assumed to have been estimated from data

data:  dat$Conc
omega2max = 0.31391, p-value = 0.4015</code></pre>
<p>From this output and using a level of significance of <span class="math inline">\(p = 0.05\)</span>, we see that none of the
distributions is implausible. However, if <em>forced</em> to choose just
one distribution, we would choose the <em>Pareto</em> distribution
(smaller values of the <code>omega2max</code> statistic are better).
However, this does not mean that the gamma and lognormal distributions
are of no value in describing the data. We can see from the plot below,
that in fact both the gamma and lognormal distributions do a reasonable
job over the range of toxicity values. The use of the Pareto may be a
questionable choice given it is truncated at 0.18 (which is the minimum
value of our toxicity data). <br></p>
<div class="figure">
<img src="model-averaging_files/figure-html/unnamed-chunk-13-1.png" alt="Emprirical cdf (black); lognormal (green); gamma (blue); and Pareeto (red)" width="672"><p class="caption">
Emprirical cdf (black); lognormal (green); gamma (blue); and Pareeto
(red)
</p>
</div>

<p>
<br>As in the earlier example, we might expect to find a better fitting
distribution by combining <em>all three distributions</em> using a
<em>weighted SSD</em>. The issue we face now is <em>how do we choose the
weights</em> to reflect the relative fits of the three distributions?
Like all tests of statistical significance, a <em>p-value</em> is
computed from the value of the relevant <em>test statistic</em> - in
this case, the value of the <code>omega2max</code> test statistic. For
this particular test, it’s a case of the <u>smaller</u> the better. From
the output above we see that the <code>omega2max</code> values are <span class="math inline">\(0.344\)</span> for the gamma distribution, <span class="math inline">\(0.328\)</span> for the lognormal distribution, and
<span class="math inline">\(0.314\)</span> for the Pareto distribution.
</p>
<p>
We might somewhat naively compute the relative weights as:<br><span class="math inline">\({w_1} = \frac{{{{0.344}^{ - 1}}}}{{\left(
{{{0.344}^{ - 1}} + {{0.328}^{ - 1}} + {{0.314}^{ - 1}}} \right)}} =
0.318\)</span>         <span class="math inline">\({w_2} =
\frac{{{{0.328}^{ - 1}}}}{{\left( {{{0.344}^{ - 1}} + {{0.328}^{ - 1}} +
{{0.314}^{ - 1}}} \right)}} = 0.333\)</span>     and <span class="math inline">\({w_3} = \frac{{{{0.314}^{ - 1}}}}{{\left(
{{{0.344}^{ - 1}} + {{0.328}^{ - 1}} + {{0.314}^{ - 1}}} \right)}} =
0.349\)</span> <br>    (we use <em>reciprocals</em> since smaller values
of <code>omega2max</code> represent better fits). As will be seen
shortly - these are incorrect.
</p>
<p>
However, being based on a simplistic measure of discrepancy between the
<em>observed</em> and <em>hypothesized</em> distributions, the
<code>omega2max</code> statistic is a fairly ‘blunt instrument’ and has
no grounding in information theory which <em>is</em> the basis for
determining the weights that we seek.
</p>
<p><br>A discussion of <em>information theoretic</em> methods for
assessing goodness-of-fit is beyond the scope of this vignette.
Interested readers should consult <span class="citation">(Burnham and
Anderson 2002)</span>. A commonly used metric to determine the
model-average weights is the <strong>Akaike Information
Criterion</strong> or <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion" class="external-link">AIC</a>.
The formula for the <span class="math inline">\(AIC\)</span> is: <span class="math display">\[AIC = 2k - 2\ln \left( \ell  \right)\]</span></p>
where <span class="math inline">\(k\)</span> is the number of model
parameters and <span class="math inline">\(\ell\)</span> is the
<em>likelihood</em> for that model. Again, a full discussion of
statistical likelihood is beyond the present scope. A relatively gentle
introduction can be found <a href="https://ep-news.web.cern.ch/what-likelihood-function-and-how-it-used-particle-physics" class="external-link">here</a>.
<p>
</p>
<p>The likelihood for our three distributions can be computed in
<code>R</code> as follows:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html" class="external-link">dgamma</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Conc</span>,shape <span class="op">=</span> <span class="fl">2.0591977</span>,scale <span class="op">=</span> <span class="fl">0.3231032</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="co">#&gt; [1] -7.020597</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Lognormal.html" class="external-link">dlnorm</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Conc</span>, meanlog <span class="op">=</span> <span class="op">-</span><span class="fl">0.6695120</span>,sdlog   <span class="op">=</span>  <span class="fl">0.7199573</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="co">#&gt; [1] -5.812947</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu">EnvStats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/EnvStats/man/Pareto.html" class="external-link">dpareto</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Conc</span>,location <span class="op">=</span> <span class="fl">0.1800000</span>, shape<span class="op">=</span><span class="fl">0.9566756</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="co">#&gt; [1] -5.621683</span></span></code></pre></div>
<p>From which the <em>AIC</em> values readily follow:</p>
<pre><code><span><span class="co">#&gt; AIC for gamma distribution = 18.04119</span></span>
<span><span class="co">#&gt; AIC for lognormal distribution = 15.62589</span></span>
<span><span class="co">#&gt; AIC for Pareto distribution = 15.24337</span></span></code></pre>

<p>
</p>
<p>As with the <code>omega2max</code> statistic,
<strong>smaller</strong> values of <em>AIC</em> are better. Thus, a
comparison of the AIC values above gives the ranking of distributional
fits (best to worst) as: <em>Pareto &gt; lognormal &gt; gamma</em></p>

<div class="section level3">
<h3 id="computing-model-weights-from-the-aic">Computing model weights from the <code>AIC</code><a class="anchor" aria-label="anchor" href="#computing-model-weights-from-the-aic"></a>
</h3>
<p>We will simply provide a formula for computing the model weights from
the <code>AIC</code> values. More detailed information can be found <a href="https://training.visionanalytix.com/ssd-model-averaging/" class="external-link">here</a>.</p>
<p>The <em>AIC</em> for the <em>i<sup>th</sup></em> distribution fitted
to the data is <span class="math display">\[AI{C_i} = 2{k_i} - 2\ln
\left( {{L_i}} \right)  \]</span> where <span class="math inline">\({L_i}\)</span> is the <em>i<sup>th</sup>
likelihood</em> and <span class="math inline">\({k_i}\)</span> is the
<em>number of parameters</em> for the <em>i<sup>th</sup>
distribution</em>. Next, we form the differences:<span class="math display">\[{\Delta _i} = AI{C_i} - AI{C_0}\]</span> where
<span class="math inline">\(AI{C_0}\)</span> is the <em>AIC</em> for the
<strong>best-fitting</strong> model (i.e.<span class="math inline">\(AI{C_0} = \mathop {\min }\limits_i \left\{
{AI{C_i}} \right\}\)</span> ). The <em>model-averaged weights</em> <span class="math inline">\({w_i}\)</span> are then computed as:</p>
<div style="text-align: center;" font-size: color: class="box">
<b><u>AIC Model averaging weights</u></b>\[{{w}_{i}}=\frac{\exp \left\{ -\frac{1}{2}{{\Delta }_{i}} \right\}}{\sum{\exp \left\{ -\frac{1}{2}{{\Delta }_{i}} \right\}}}\]
</div>
<br><p>
</p>
<p>The model-averaged weights for the gamma, lognormal, and Pareto
distributions used in the previous example can be computed ‘manually’ in
<code>R</code> as follows:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1.73</span>,<span class="fl">0.57</span>,<span class="fl">0.33</span>,<span class="fl">0.28</span>,<span class="fl">0.3</span>,<span class="fl">0.29</span>,<span class="fl">2.15</span>,<span class="fl">0.8</span>,<span class="fl">0.76</span>,<span class="fl">0.54</span>,<span class="fl">0.42</span>,<span class="fl">0.83</span>,<span class="fl">0.21</span>,<span class="fl">0.18</span>,<span class="fl">0.59</span><span class="op">)</span></span>
<span><span class="va">aic</span><span class="op">&lt;-</span><span class="cn">NULL</span></span>
<span><span class="va">k</span><span class="op">&lt;-</span><span class="fl">2</span>  <span class="co"># number of parameters for each of the distributions</span></span>
<span></span>
<span></span>
<span><span class="va">aic</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">&lt;-</span><span class="fl">2</span><span class="op">*</span><span class="va">k</span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html" class="external-link">dgamma</a></span><span class="op">(</span><span class="va">dat</span>,shape <span class="op">=</span> <span class="fl">2.0591977</span>,scale <span class="op">=</span> <span class="fl">0.3231032</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="co"># Gamma distribution</span></span>
<span></span>
<span><span class="va">aic</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">&lt;-</span><span class="fl">2</span><span class="op">*</span><span class="va">k</span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Lognormal.html" class="external-link">dlnorm</a></span><span class="op">(</span><span class="va">dat</span>, meanlog <span class="op">=</span> <span class="op">-</span><span class="fl">0.6695120</span>,sdlog   <span class="op">=</span>  <span class="fl">0.7199573</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>  <span class="co"># lognormal distribution</span></span>
<span></span>
<span><span class="va">aic</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">&lt;-</span><span class="fl">2</span><span class="op">*</span><span class="va">k</span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu">EnvStats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/EnvStats/man/Pareto.html" class="external-link">dpareto</a></span><span class="op">(</span><span class="va">dat</span>,location <span class="op">=</span> <span class="fl">0.1800000</span>, shape<span class="op">=</span><span class="fl">0.9566756</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="co"># Pareto distribution</span></span>
<span></span>
<span><span class="va">delta</span><span class="op">&lt;-</span><span class="va">aic</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">aic</span><span class="op">)</span>  <span class="co">#  compute the delta values</span></span>
<span></span>
<span><span class="va">aic.w</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span><span class="op">*</span><span class="va">delta</span><span class="op">)</span>; <span class="va">aic.w</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">aic.w</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">aic.w</span><span class="op">)</span>,<span class="fl">4</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">" AIC weight for gamma distribution ="</span>,<span class="va">aic.w</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,<span class="st">"\n"</span>,</span>
<span>    <span class="st">"AIC weight for lognormal distribution ="</span>,<span class="va">aic.w</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,<span class="st">"\n"</span>,</span>
<span>    <span class="st">"AIC weight for pareto distribution ="</span>,<span class="va">aic.w</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span>,<span class="st">"\n"</span><span class="op">)</span></span></code></pre></div>
<pre><code> AIC weight for gamma distribution = 0.1191 
 AIC weight for lognormal distribution = 0.3985 
 AIC weight for pareto distribution = 0.4824 </code></pre>

<p>Finally, let’s look at the fitted <em>model-averaged SSD</em>:</p>
<div class="figure">
<img src="model-averaging_files/figure-html/unnamed-chunk-17-1.png" alt="Empirical cdf (black) and model-averaged fit (magenta)" width="768"><p class="caption">
Empirical cdf (black) and model-averaged fit (magenta)
</p>
</div>
<p>As can be seen from the figure above, the model-averaged fit provides
a very good fit to the empirical data.</p>
</div>
<div class="section level3">
<h3 id="correcting-for-distributions-having-differing-numbers-of-parameters">Correcting for distributions having differing numbers of
parameters<a class="anchor" aria-label="anchor" href="#correcting-for-distributions-having-differing-numbers-of-parameters"></a>
</h3>
<p>In deriving the AIC, Akaike had to make certain, strong assumptions.
In addition, the bias factor (the <span class="math inline">\(2k\)</span> term) was derived from theoretical
considerations (such as mathematical <em>expectation</em>) that relate
to <em>infinite</em> sample sizes. For small sample sizes, the AIC is
likely to select models having too many parameters (i.e models which
<em>over-fit</em>) In 1978, Sugiura proposed a modification to the AIC
to address this problem, although it too relied on a number of
assumptions. This ‘correction’ to the AIC for small samples (referred to
as <span class="math inline">\(AI{{C}_{c}}\)</span>) is:</p>
<div style="text-align: center;" font-size: color: class="box">
<b><u>Corrected Akaike Information Criterion (AICc)</u></b>\[AI{{C}_{c}}=AIC+\frac{2{{k}^{2}}+2k}{n-k-1}\]where <i>n</i> is the sample size and <i>k</i> is the number of parameters.
</div>
<p><br>It is clear from the formula for <span class="math inline">\(AI{{C}_{c}}\)</span> that for   <span class="math inline">\(n\gg k\)</span>,    <span class="math inline">\(AI{{C}_{c}}\simeq AIC\)</span>. The issue of
sample size is ubiquitous in statistics, but even more so in
ecotoxicology where logistical and practical limitations invariably mean
we are dealing with (pathologically) small sample sizes. There are no
hard and fast rules as to what constitutes an <em>appropriate</em>
sample size for SSD modelling. However, Professor David Fox’s personal
rule of thumb which works quite well is:</p>
<div style="text-align: center;" font-size: color: class="box">
<b><u>Sample size rule-of-thumb for SSD modelling</u></b> \[n\ge 5k+1\]where <i>n</i> is the sample size and <i>k</i> is the number of parameters.
</div>
<p><br>Since most of the common SSD models are 2-parameter, we should be
aiming to have a sample size of at least 11. For 3-parameter models
(like the Burr III), the minimum sample size is 16 and if we wanted to
fit a mixture of two, 2-parameter models (eg.
<em>logNormal-logNormal</em> or <em>logLogistic-logLogistic</em>) the
sample size should be <em>at least</em> 26. Sadly, this is rarely the
case in practice!</p>
</div>
<div class="section level3">
<h3 id="model-averaging-in-ssdtools">Model-Averaging in <code>ssdtools</code><a class="anchor" aria-label="anchor" href="#model-averaging-in-ssdtools"></a>
</h3>
<p>Please see the <a href="https://poissonconsulting.github.io/ssdtools/articles/ssdtools.html" class="external-link">Getting
started with ssdtools</a> vignette for examples of obtaining
model-averaged <em>HCx</em> values and predictions using
<code>ssdtools</code>.</p>
</div>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-model_averaging" class="csl-entry">
Burnham K, Anderson D (2002) <a href="https://link.springer.com/book/10.1007/b97636" class="external-link">Model selection and
multimodel inference - a practical information-theoretic approach</a>.
Springer
</div>
<div id="ref-chapman_2007" class="csl-entry">
Chapman PR, Hart A, Roelofs W, et al (2007) Methods of uncertainty
analysis. In: A H (ed) EUFRAM Concerted Action to Develop a European
Framework for Probabilistic Risk Assessment of the Environmental Impacts
of Pesticides, Vol 2, Detailed Reports on Role, Methods, Reporting and
Validation
</div>
<div id="ref-fletcher" class="csl-entry">
Fletcher D (2018) <a href="https://link.springer.com/book/10.1007/978-3-662-58541-2" class="external-link">Model
averaging</a>. Springer
</div>
<div id="ref-fox_2016" class="csl-entry">
Fox DR (2016) <a href="https://shop.elsevier.com/books/marine-ecotoxicology/blasco/978-0-12-803371-5" class="external-link">Contemporary
methods for statistical design and analysis</a>. In: Blasco J, Chapman
PM, Campana O, Hampel M (eds) Marine Ecotoxicology
</div>
<div id="ref-fox_recent_2021" class="csl-entry">
Fox DR, Dam RA, Fisher R, et al (2021a) Recent <span>Developments</span>
in <span>Species</span> <span>Sensitivity</span>
<span>Distribution</span> <span>Modeling</span>. Environmental
Toxicology and Chemistry 40:293–308. <a href="https://doi.org/10.1002/etc.4925" class="external-link">https://doi.org/10.1002/etc.4925</a>
</div>
<div id="ref-fox_methodologies_2021" class="csl-entry">
Fox DR, Fisher R, Thorley JL, Schwarz C (2021b) <a href="https://environmetrics.net/docs/FOX%20and%20FISHER%20Final_final_report_rev2.3.pdf?189db0&amp;189db0" class="external-link">Joint
investigation into <span class="nocase">statistical</span> <span class="nocase">methodologies</span> underpinning the <span class="nocase">derivation</span> of <span class="nocase">toxicant</span>
<span class="nocase">guideline</span> <span class="nocase">values</span>
in <span>Australia</span> and <span>New Zealand</span></a>.
Environmetrics Australia; Australian Institute of Marine Science
</div>
<div id="ref-newman_2000" class="csl-entry">
Newman MC, Ownby DR, Mézin LCA, et al (2000) Applying <span class="nocase">species-sensitivity distributions</span> in <span class="nocase">ecological</span> <span class="nocase">risk
assessment</span>: Assumptions of <span class="nocase">distribution
type</span> and sufficient <span class="nocase">numbers of
species</span>. Environmental Toxicology and Chemistry 19:508–515. <a href="https://doi.org/10.1002/etc.5620190233" class="external-link">https://doi.org/10.1002/etc.5620190233</a>
</div>
<div id="ref-Zajdlik_2005" class="csl-entry">
Zajdlik B (2005) Statistical analysis of the SSD approach for
development of canadian water quality guidelines. Zajdlik; Associates
</div>
</div>
</div>
<div class="section level2">
<h2 id="licensing">Licensing<a class="anchor" aria-label="anchor" href="#licensing"></a>
</h2>
<p>Copyright 2018-2024 Province of British Columbia<br>
Copyright 2021 Environment and Climate Change Canada<br>
Copyright 2023-2024 Australian Government Department of Climate Change,
Energy, the Environment and Water</p>
<p>The documentation is released under the <a href="https://creativecommons.org/licenses/by/4.0/" class="external-link">CC BY 4.0
License</a></p>
<p>The code is released under the <a href="https://www.apache.org/licenses/LICENSE-2.0" class="external-link">Apache License
2.0</a></p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://github.com/joethorley" class="external-link">Joe Thorley</a>, <a href="https://www.aims.gov.au/about/our-people/dr-rebecca-fisher" class="external-link">Rebecca Fisher</a>, <a href="https://training.ecotox.science/who-we-are/" class="external-link">David Fox</a>, <a href="https://www.sfu.ca/stat-actsci/department/profiles/carl-schwarz.html" class="external-link">Carl Schwarz</a>, <a href="https://www2.gov.bc.ca/" class="external-link">Province of British Columbia</a>, <a href="https://www.canada.ca/en/environment-climate-change.html" class="external-link">Environment and Climate Change Canada</a>, <a href="https://www.dcceew.gov.au/" class="external-link">Australian Government Department of Climate Change, Energy, the Environment and Water</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
