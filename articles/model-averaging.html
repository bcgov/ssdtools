<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Model Averaging SSDs • ssdtools</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Model Averaging SSDs">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">ssdtools</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">2.5.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/ssdtools.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item"><a class="nav-link" href="../articles/index.html">Articles</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/bcgov/ssdtools/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Model Averaging SSDs</h1>
                        <h4 data-toc-skip class="author">ssdtools
Team</h4>
            
            <h4 data-toc-skip class="date">2025-12-01</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/bcgov/ssdtools/blob/main/vignettes/articles/model-averaging.Rmd" class="external-link"><code>vignettes/articles/model-averaging.Rmd</code></a></small>
      <div class="d-none name"><code>model-averaging.Rmd</code></div>
    </div>

    
    
<style type="text/css">
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 200px;
}
</style>
<style type="text/css">
.scroll-200 {
  max-height: 200px;
  overflow-y: auto;
  background-color: inherit;
}
</style>
<style>

.box {
  height: auto;
  width: 65%;
  padding: 10px;
  border: 1.5px outset #5C5B5D;
  background-color: #E7E8EC;
  border-radius: 8px;
  text-align: left;
  margin: auto;
}

</style>
<script type="text/x-mathjax-config">MathJax.Hub.Config({  "HTML-CSS": { minScaleAdjust: 0.5, availableFonts: [] }  });
</script><div class="section level2">
<h2 id="background">Background<a class="anchor" aria-label="anchor" href="#background"></a>
</h2>
<blockquote>
<p>Many authors have noted that there is no guiding theory in
ecotoxicology to justify any particular distributional form for the SSD
other than that its domain be restricted to the positive real line <span class="citation">(Newman et al. 2000)</span>, <span class="citation">(Zajdlik 2005)</span>, <span class="citation">(Chapman
et al. 2007)</span>, <span class="citation">(David R. Fox 2016)</span>.
Indeed, <span class="citation">(Chapman et al. 2007)</span> described
the identification of a suitable probability model as one of the most
important and difficult choices in the use of SSDs. Compounding this
lack of clarity about the functional form of the SSD is the omnipresent,
and equally vexatious issue of small sample size, meaning that any
plausible candidate model is unlikely to be rejected <span class="citation">(D. R. Fox et al. 2021)</span>. The ssdtools R package
uses a model averaging procedure to avoid the need to a-priori select a
candidate distribution and instead uses a measure of ‘fit’ for each
model to compute weights to be applied to an initial set of candidate
distributions. The method, as applied in the SSD context is described in
detail in <span class="citation">(D. R. Fox et al. 2021)</span>, and
potentially provides a level of flexibility and parsimony that is
difficult to achieve with a single SSD distribution.</p>
</blockquote>
<p><span class="citation">(D. Fox et al. 2022)</span></p>
</div>
<div class="section level2">
<h2 id="preliminaries">Preliminaries<a class="anchor" aria-label="anchor" href="#preliminaries"></a>
</h2>
<p>Before we jump into model averaging and in particular, SSD Model
Averaging, let’s backup a little and consider why we average and the
advantages and disadvantages of averaging.</p>
<div class="section level4">
<h4 id="the-pros-and-cons-of-averaging">The pros and cons of averaging<a class="anchor" aria-label="anchor" href="#the-pros-and-cons-of-averaging"></a>
</h4>
<p>We’re all familiar with the process of averaging. Indeed,
<em>averages</em> are pervasive in everyday life - we talk of average
income; mean sea level; average global temperature; average height,
weight, age etc. etc. So what’s the obsession with <em>averaging</em>?
It’s simple really - it’s what statisticians call <u>data reduction</u>
which is just a fancy name to describe the process of summarising a lot
of <em>raw data</em> using a small number of (hopefully) representative
<u>summary statistics</u> such as the mean and the standard deviation.
Clearly, it’s a lot easier to work with just a single mean than all the
individual data values. That’s the upside. The downside is that the
process of data reduction decimates your original data - you lose
information in the process. Nevertheless, the benefits tend to outweigh
this information loss. Indeed, much of ‘conventional’ statistical theory
and practice is focused on the mean. Examples include T-tests, ANOVA,
regression, and clustering. When we talk of an ‘average’ we are usually
referring to the simple, <em>arithmetic
mean</em>:<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>X</mi><mo accent="true">‾</mo></mover><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>X</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\bar{X}=\frac{1}{n}\sum\limits_{i=1}^{n}{{{X}_{i}}}</annotation></semantics></math>
although we recognize there are other types of mean including the
geometric mean, the harmonic mean and the weighted mean. The last of
these is particularly pertinent to model averaging.</p>
</div>
<div class="section level3">
<h3 id="weighted-averages">Weighted Averages<a class="anchor" aria-label="anchor" href="#weighted-averages"></a>
</h3>
<p>For the simple arithmetic mean, all of the individual values receive
the same weighting - they each contribute
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mn>1</mn><mi>n</mi></mfrac><annotation encoding="application/x-tex">\frac{1}{n}</annotation></semantics></math>
to the summation. While this is appropriate in many cases, it’s not
useful when the components contribute to varying degrees. An example
familiar to ecotoxicologists is that of a <em>time-varying</em>
concentration as shown in the figure below.<br></p>
<p><img src="images/Figure1.jpg" style="width:90.0%" align="center" alt="A hypothetical time series showing a concentration measurement changing over time, with different time periods associated with different concentrations."><br></p>
<p>From the figure we see there are 5 concentrations going from left to
to right:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">{</mo><mn>0.25</mn><mo>,</mo><mn>0.95</mn><mo>,</mo><mn>0.25</mn><mo>,</mo><mn>0.12</mn><mo>,</mo><mn>0.5</mn><mo stretchy="true" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\left\{ 0.25,0.95,0.25,0.12,0.5 \right\}</annotation></semantics></math>.
If we were to take the simple arithmetic mean of these concentrations we
get
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>X</mi><mo accent="true">‾</mo></mover><mo>=</mo><mn>0.414</mn></mrow><annotation encoding="application/x-tex">\bar{X}=0.414</annotation></semantics></math>.
But this ignores the different <em>durations</em> of these 5
concentrations. Of the 170 hours, 63 were at concentration 0.25, 25 at
concentration 0.95, 23 at concentration 0.25, 23 at concentration 0.12,
and 36 at concentration 0.50. So if we were to <em>weight</em> these
concentrations by time
have:<br><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>X</mi><mo accent="true">‾</mo></mover><mrow><mi>T</mi><mi>W</mi></mrow></msub><mo>=</mo><mfrac><mrow><mo stretchy="true" form="prefix">(</mo><mn>63</mn><mo>⋅</mo><mn>0.25</mn><mo>+</mo><mn>25</mn><mo>⋅</mo><mn>0.95</mn><mo>+</mo><mn>23</mn><mo>⋅</mo><mn>0.25</mn><mo>+</mo><mn>23</mn><mo>⋅</mo><mn>0.12</mn><mo>+</mo><mn>36</mn><mo>⋅</mo><mn>0.50</mn><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>63</mn><mo>+</mo><mn>25</mn><mo>+</mo><mn>23</mn><mo>+</mo><mn>23</mn><mo>+</mo><mn>36</mn><mo stretchy="true" form="postfix">)</mo></mrow></mfrac><mo>=</mo><mfrac><mn>56.01</mn><mn>170</mn></mfrac><mo>=</mo><mn>0.33</mn></mrow><annotation encoding="application/x-tex">{{{\bar{X}}}_{TW}}=\frac{\left( 63\cdot 0.25+25\cdot 0.95+23\cdot 0.25+23\cdot 0.12+36\cdot 0.50 \right)}{\left( 63+25+23+23+36 \right)}=\frac{56.01}{170}=0.33</annotation></semantics></math><br>So,
our formula for a <em>weighted average</em>
is:<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>X</mi><mo accent="true">‾</mo></mover><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msub><mi>w</mi><mi>i</mi></msub><msub><mi>X</mi><mi>i</mi></msub></mrow></mrow><annotation encoding="application/x-tex">\bar{X}=\sum\limits_{i=1}^{n}{{{w}_{i}}{{X}_{i}}}</annotation></semantics></math>
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>≤</mo><msub><mi>w</mi><mi>i</mi></msub><mo>≤</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0\le {{w}_{i}}\le 1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msub><mi>w</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow></mrow><annotation encoding="application/x-tex">\sum\limits_{i=1}^{n}{{{w}_{i}}=1}</annotation></semantics></math>.
<br>Note, the simple arithmetic mean is just a special case of the
weighted mean with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msub><mi>w</mi><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac></mrow></mrow><annotation encoding="application/x-tex">\sum\limits_{i=1}^{n}{{{w}_{i}}=\frac{1}{n}}</annotation></semantics></math>
;
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∀</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">\forall i=1,\ldots ,n</annotation></semantics></math></p>
</div>
</div>
<div class="section level2">
<h2 id="model-averaging">Model Averaging<a class="anchor" aria-label="anchor" href="#model-averaging"></a>
</h2>
<p>The <em>weighted average</em> acknowledges that the elements in the
computation are <u>not</u> of equal ‘importance’. In the example above,
this importance was based on the <em>proportion of time</em> that the
concentration was at a particular level. Bayesians are well-versed in
this concept - the elicitation of <em>prior distributions</em> for model
parameters provides a mechanism for weighting the degree to which the
analysis is informed by existing knowledge versus using a purely
data-driven approach. Model averaging is usually used in the context of
estimating model parameters or quantities derived from a fitted model -
for example an EC50 derived from a C-R model. Let’s motivate the
discussion using the following small dataset of toxicity estimates for
some chemical.</p>
<pre><code><span><span class="co">#&gt;  [1] 1.73 0.57 0.33 0.28 0.30 0.29 2.15 0.80 0.76 0.54 0.42 0.83 0.21 0.18 0.59</span></span></code></pre>
<p>Now, suppose we have only two possibilities for fitting an SSD - both
lognormal distributions. Model 1 is the LN(-1.067,0.414) distribution
while Model 2 is the LN(-0.387,0.617) distribution. A plot of the
empirical <em>cdf</em> and Models 1 and 2 is shown below.</p>
<div class="figure">
<img src="model-averaging_files/figure-html/unnamed-chunk-6-1.png" class="r-plt" alt="The example data ploted as an empirical cumulative distribution function. Two fitted lines are shown for two different lognormal distributions, one that fits the lower left tail, and another that fits the upper right tail." width="672"><p class="caption">
Emprirical cdf (black); Model 1(green); and Model 2 (blue)
</p>
</div>
<p><br>We see that Model 1 fits well in the lower, left region and
poorly in the upper region, while the reverse is true for Model 2. So
using <em>either</em> Model 1 <strong>or</strong> Model 2 is going to
result in a poor fit overall. However, the obvious thing to do is to
<strong>combine</strong> both models. We could just try using 50% of
Model 1 and 50% of Model 2, but that may be sub-optimal. It turns out
that the best fit is obtained by using 44% of Model 1 and 56% of Model
2. Redrawing the plot and adding the <em>weighted average</em> of Models
1 and 2 is shown below.</p>
<div class="figure">
<img src="model-averaging_files/figure-html/unnamed-chunk-7-1.png" class="r-plt" alt="The example data ploted as an empirical cumulative distribution function. Two fitted lines are shown for two different lognormal distributions, one that fits the lower left tail, and another that fits the upper right tail. A third line shows the weighted average of these two distributions, which appears between the two inidividual distributions and fits the data well." width="672"><p class="caption">
Empirical cdf (black); Model 1(green); Model 2 (blue); and averaged
Model (red)
</p>
</div>
<p><br>Clearly the strategy has worked - we now have an excellent
fitting SSD. What about estimation of an <em>HC20</em>? It’s a simple
matter to work out the <em>individual</em> <em>HC20</em> values for
Models 1&amp;2 using the appropriate <code><a href="https://rdrr.io/r/stats/Lognormal.html" class="external-link">qlnorm()</a></code> function in
<code>R</code>. Thus we have:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Model 1 HC20</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Model 1 HC20 ="</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Lognormal.html" class="external-link">qlnorm</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="op">-</span><span class="fl">1.067</span>, <span class="fl">0.414</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Model 1 HC20 = 0.2428209</span></span>
<span></span>
<span><span class="co"># Model 2 HC20</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Model 2 HC20 ="</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Lognormal.html" class="external-link">qlnorm</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="op">-</span><span class="fl">0.387</span>, <span class="fl">0.617</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Model 2 HC20 = 0.4040243</span></span></code></pre></div>
<p>What about the averaged distribution? An intuitively appealing
approach would be to apply the same weights to the individual
<em>HC20</em> values as was applied to the respective models. That is
<code>0.44*0.2428209 + 0.56*0.4040243 = 0.33</code>.</p>
<p>So our model-averaged <em>HC20</em> estimate is 0.33. As a check, we
can determine the <em>fraction affected</em> at concentration = 0.33 -
it should of course be 20%. Let’s take a look at the plot.</p>
<p><img src="model-averaging_files/figure-html/unnamed-chunk-9-1.png" class="r-plt" alt="The weighted average of the two lognormal distributions, as fitted to the example data. Highlighted is the corresponding fraction affected at a concentration of 0.33, which is at 30 percent." width="672"></p>
<p>Something’s wrong - the fraction affected at concentration 0.33 is
30% - <strong>not the required 20%</strong>. This issue is taken up in
the next section</p>
</div>
<div class="section level2">
<h2 id="model-averaged-ssds">Model Averaged SSDs<a class="anchor" aria-label="anchor" href="#model-averaged-ssds"></a>
</h2>
<p>As we’ve just seen, applying the model weights to component
<em>HCx</em> values and summing does <strong>not</strong> produce the
correct result. The reason for this can be explained mathematically as
follows (<em>if your not interested in the mathematical explanation -
skip ahead to the next section</em>).</p>
<h4 id="model-averaged-ssds-1">
The fallacy of weighting individual <em>HCx</em> values
<a class="anchor" aria-label="anchor" href="#model-averaged-ssds-1"></a>
</h4>
<p>The correct expression for a model-averaged SSD is:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>w</mi><mi>i</mi></msub><msub><mi>F</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">G\left( x \right) = \sum\limits_{i = 1}^k {{w_i}} {F_i}\left( x \right)</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">{F_i}\left(  \cdot  \right)</annotation></semantics></math>
is the <em>i<sup>th</sup></em> component SSD (i.e. <em>cdf</em>) and
<em>w<sub>i</sub></em> is the weight assigned to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">{F_i}\left(  \cdot  \right)</annotation></semantics></math>.
<br>Notice that the function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">G\left( x \right)</annotation></semantics></math>
is a proper <em>cumulative distribution function</em> (<em>cdf</em>)
which means for a given quantile, <em>x</em>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">G\left( x \right)</annotation></semantics></math>
returns the <em>cumulative probability</em>:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>X</mi><mo>≤</mo><mi>x</mi><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">P\left[ {X \leqslant x} \right]</annotation></semantics></math></p>
<p><br>Now, the <em>incorrect</em> approach takes a weighted sum of the
component <em>inverse cdfs</em>, that is:</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>w</mi><mi>i</mi></msub><msup><msub><mi>F</mi><mi>i</mi></msub><mrow><mo>−</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">H\left( p \right) = \sum\limits_{i = 1}^k {{w_i}} {F_i}^{ - 1}\left( p \right)</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><msub><mi>F</mi><mi>i</mi></msub><mrow><mo>−</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">{F_i}^{ - 1}\left(  \cdot  \right)</annotation></semantics></math>
is the <em>i<sup>th</sup></em> <em>inverse cdf</em>. Notice that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">{G_i}\left(  \cdot  \right)</annotation></semantics></math>
is a function of a <em>quantile</em> and returns a
<strong>probability</strong> while
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">{H_i}\left(  \cdot  \right)</annotation></semantics></math>
is a function of a <em>probability</em> and returns an
<strong>quantile</strong>.
<p>
Now, the <u>correct</u> method of determining the <em>HCx</em> is to
work with the proper model-averaged <em>cdf</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">G\left( x \right)</annotation></semantics></math>.
This means finding the <strong>inverse</strong> function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>G</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">{G^{ - 1}}\left( p \right)</annotation></semantics></math>.
We’ll address how we do this in a moment.
</p>
The reason why
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">H\left( p \right)</annotation></semantics></math>
does <strong>not</strong> return the correct result is because of <u>the
implicit assumption that the inverse of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">G\left( x \right)</annotation></semantics></math>
is equivalent to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">H\left( p \right)</annotation></semantics></math>.</u>
This is akin to stating the inverse of a <em>sum</em> is equal to the
sum of the inverses i.e.
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mfrac><mn>1</mn><msub><mi>X</mi><mi>i</mi></msub></mfrac><mo>=</mo><mfrac><mn>1</mn><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>X</mi><mi>i</mi></msub></mrow></mfrac><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> ???</mtext></mrow></mrow><annotation encoding="application/x-tex">\sum\limits_{i = 1}^n {\frac{1}{{{X_i}}}}  = \frac{1}{{\sum\limits_{i = 1}^n {{X_i}} }}{\text{  ???}}</annotation></semantics></math><hr>
<b><u>For the mathematical nerds:</u></b> There are some very special
cases where the above identity does in fact hold, but for that you need
to use <strong>complex numbers</strong>.
<p>
For example, consider two complex numbers
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mtext mathvariant="normal">a = </mtext><mspace width="0.333em"></mspace></mrow><mfrac><mrow><mo stretchy="true" form="prefix">(</mo><mn>5</mn><mo>−</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></mfrac><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> and </mtext><mspace width="0.333em"></mspace></mrow><mi>b</mi><mo>=</mo><mo>−</mo><mn>1.683</mn><mo>−</mo><mn>1.915</mn><mi>i</mi></mrow><annotation encoding="application/x-tex">{\text{a = }}\frac{{\left( {5 - i} \right)}}{2}{\text{   and     }}b =  - 1.683 - 1.915i</annotation></semantics></math>
It can be shown that
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mrow><mi>a</mi><mo>+</mo><mi>b</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>a</mi></mfrac><mo>+</mo><mfrac><mn>1</mn><mi>b</mi></mfrac><mo>=</mo><mn>0.126</mn><mo>+</mo><mn>0.372</mn><mi>i</mi></mrow><annotation encoding="application/x-tex">\frac{1}{{a + b}} = \frac{1}{a} + \frac{1}{b} = 0.126 + 0.372i</annotation></semantics></math></p>
<hr>
<p>
Back to the issue at hand, and since we’re not dealing with complex
numbers, it’s safe to
say:<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>G</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≠</mo><mi>H</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">{G^{ - 1}}\left( p \right) \ne H\left( p \right)</annotation></semantics></math></p>
<p>If you need a visual demonstration, we can plot
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">G\left( x \right)</annotation></semantics></math>
and the <em>inverse</em> of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">H\left( p \right)</annotation></semantics></math>
both as functions of <em>x</em> (a quantile) for our two-component
lognormal distribution above.</p>
<p><img src="model-averaging_files/figure-html/unnamed-chunk-10-1.png" class="r-plt" alt="The weighted average of the two lognormal distributions, as fitted to the example data, plotted as a line for the incorrect weighting method, as well as the correct weighting method. The line for two methods do not overlap, although they do cross at a value of 1.12. Because they do not overlap, the two methods will return a different concentration for the 80 percent fraction affected." width="768"></p>
Clearly, the two functions are <strong>not</strong> the same and thus
<em>HCx</em> values derived from each will nearly always be different
(as indicated by the positions of the vertical red and green dashed
lines in the Figure above corresponding to the 2 values of the
<em>HC20</em>). (Note: The two curves do cross over at a concentration
of about 1.12 corresponding to the 90<sup>th</sup> percentile, but in
the region of ecotoxicological interest, there is no such cross-over and
so the two approaches will <strong>always</strong> yield different
<em>HCx</em> values with this difference → 0 as x → 0).
<p>
</p>
<p>We next discuss the use of a model-averaged SSD to obtain the
<em>correct</em> model-averaged <em>HCx</em>.</p>
</div>
<div class="section level2">
<h2 id="computing-a-model-averaged-hcx">Computing a model-averaged <em>HCx</em><a class="anchor" aria-label="anchor" href="#computing-a-model-averaged-hcx"></a>
</h2>
A proper <em>HCx</em> needs to satisfy what David Fox refers to as
<strong>the inversion principle</strong>.
<p>
More formally, the inversion principle states that an <em>HCx</em>
(denoted as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>φ</mi><mi>x</mi></msub><annotation encoding="application/x-tex">{\varphi _x}</annotation></semantics></math>)
<u><i>must</i></u> satisfy the following:
</p>
<p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>φ</mi><mi>x</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>x</mi><mspace width="1.0em"></mspace><mspace width="1.0em"></mspace><mi>a</mi><mi>n</mi><mi>d</mi><mspace width="1.0em"></mspace><mspace width="1.0em"></mspace><mi>q</mi><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>φ</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">df\left( {{\varphi _x}} \right) = x\quad \quad and\quad \quad qf\left( x \right) = {\varphi _x}</annotation></semantics></math></p>
<p>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">df\left(  \cdot  \right)</annotation></semantics></math>
is a model-averaged <em>distribution function</em> (i.e. SSD) and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">qf\left(  \cdot  \right)</annotation></semantics></math>
is a model-averaged <em>quantile function</em>. For this equality to
hold, it is necessary that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>d</mi><msup><mi>f</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">qf\left( p \right) = d{f^{ - 1}}\left( p \right)</annotation></semantics></math>.
</p>
<br>So, in our example above, the green curve was taken to be
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">qf\left( x \right)</annotation></semantics></math>
and this was used to derive
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>φ</mi><mi>x</mi></msub><annotation encoding="application/x-tex">{\varphi _x}</annotation></semantics></math>
but the <em>fraction affected</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">{</mo><mo>=</mo><mi>d</mi><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>φ</mi><mi>x</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\left\{ { = df\left( {{\varphi _x}} \right)} \right\}</annotation></semantics></math>
at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>φ</mi><mi>x</mi></msub><annotation encoding="application/x-tex">{\varphi _x}</annotation></semantics></math>
is computed using the red curve.
<p>
In <code>ssdtools</code> the following is a check that the inversion
principle holds:
</p>
<p><br></p>
<pre><code><span><span class="co"># Obtain a model-averaged HCx using the ssd_hc() function</span></span>
<span><span class="va">hcp</span><span class="op">&lt;-</span><span class="fu"><a href="../reference/ssd_hc.html">ssd_hc</a></span><span class="op">(</span><span class="va">x</span>, p <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="co"># Check that the inversion principle holds</span></span>
<span><span class="fu"><a href="../reference/ssd_hp.html">ssd_hp</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">hcp</span>, est_method <span class="op">=</span> <span class="st">"multi"</span><span class="op">)</span> <span class="op">==</span> <span class="va">p</span>   <span class="co"># this should result in logical `TRUE`</span></span></code></pre>
<p><em>Note: if the <code>multi_est</code> argument is set to
<code>FALSE</code> the test will fail</em>. <br></p>
<p>
</p>
<p>The <em>inversion principle</em> ensures that we only use a
<strong>single</strong> distribution function to compute both the
<em>HCx</em> <em>and</em> the fraction affected. Referring to the figure
below, the <em>HCx</em> is obtained from the MA-SSD (red curve) by
following the → arrows while the fraction affected is obtained by
following the ← arrows.</p>
<p><img src="images/Figure2.jpg" style="width:100.0%" align="center" alt="The weighted average of the two lognormal distributions, as fitted to the example data, plotted as a line for the correct weighting method only. Highlighted is the corresponding fraction affected at a concentration of 0.292, which is at 20 percent for the correct weighting method, and confirms this method meets the inversion principle."><br></p>
<p>
Finally, we’ll briefly discuss how the <em>HCx</em> is computed in
<code>R</code> using the same method as has been implemented in
<code>ssdtools</code>.
</p>
<div class="section level3">
<h3 id="computing-the-hcx-in-rssdtools">Computing the <em>HCx</em> in
<code>R</code>/<code>ssdtools</code><a class="anchor" aria-label="anchor" href="#computing-the-hcx-in-rssdtools"></a>
</h3>
Recall, our MA-SSD was given as
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>w</mi><mi>i</mi></msub><msub><mi>F</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">G\left( x \right) = \sum\limits_{i = 1}^k {{w_i}} {F_i}\left( x \right)</annotation></semantics></math>
and an <em>HCx</em> is obtained from the MA-SSD by essentially working
‘in reverse’ by starting at a value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
on the <strong>vertical</strong> scale in the Figure above and following
the → arrows and reading off the corresponding value on the horizontal
scale.
<p>
Obviously, we need to be able to ‘codify’ this process in <code>R</code>
(or any other computer language).<br>Mathematically this is equivalent
to seeking a solution to the following
equation:<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>:</mo><mi>G</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">{x:G\left( x \right) = p}</annotation></semantics></math>
or,
equivalently:<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>:</mo><mi>G</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>p</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x:G\left( x \right) - p = 0</annotation></semantics></math>
for some fraction affected,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>.
</p>
<p>
</p>
<p>Finding the solution to this last equation is referred to as
<em>finding the root(s)</em> of the function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">G\left( x \right)</annotation></semantics></math>
or, as is made clear in the figure below, <em>finding the
zero-crossing</em> of the function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">G\left( x \right)</annotation></semantics></math>
for the case
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>0.2</mn></mrow><annotation encoding="application/x-tex">p=0.2</annotation></semantics></math>.</p>
<p><img src="images/uniroot.jpg" style="width:100.0%" align="center" alt="The weighted average of the two lognormal distributions, as fitted to the example data, plotted as a line for the correct weighting method only, demonstrating finding the zero crossing on the function."><br></p>
<br><p>
In <code>R</code> finding the roots of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>:</mo><mi>G</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>p</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x:G\left( x \right) - p = 0</annotation></semantics></math>
is achieved using the <code><a href="https://rdrr.io/r/stats/uniroot.html" class="external-link">uniroot()</a></code> function.
</p>
<p>Help on the <code>uniroot</code> function can be found <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/uniroot.html" class="external-link">here</a></p>
</div>
</div>
<div class="section level2">
<h2 id="where-do-the-model-averaged-weights-come-from">Where do the model-averaged weights come from?<a class="anchor" aria-label="anchor" href="#where-do-the-model-averaged-weights-come-from"></a>
</h2>
<p>This is a little more complex, although we’ll try to provide a
non-mathematical explanation. For those interested in going deeper, a
more comprehensive treatment can be found in <span class="citation">(Burnham and Anderson 2002)</span> and <span class="citation">(Fletcher 2018)</span>.</p>
<p>
</p>
<p>This time, we’ll look at fitting a gamma, lognormal, and pareto
distribution to our sample data:</p>
<pre><code><span><span class="co">#&gt;  [1] 1.73 0.57 0.33 0.28 0.30 0.29 2.15 0.80 0.76 0.54 0.42 0.83 0.21 0.18 0.59</span></span></code></pre>
<p><br>The adequacy (or otherwise) of a fitted model can be assessed
using a variety of numerical measures known as
<strong>goodness-of-fit</strong> or GoF statistics. These are invariably
based on a measure of discrepancy between the emprical data and the
hypothesized model. Common GoF statistics used to test whether the
hypothesis of some specified theoretical probability distribution is
plausible for a given data set include: <em>Kolmogorov-Smirnov test;
Anderson-Darling test; Shapiro-Wilk test;and Cramer-von Mises test</em>.
<a href="https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93von_Mises_criterion" class="external-link">The
Cramer-von Mises</a> test is a good choice and is readily performed
using the <code><a href="https://rdrr.io/pkg/goftest/man/cvm.test.html" class="external-link">cvm.test()</a></code> function in the <code>goftest</code>
package in <code>R</code> as follows:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Conc <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1.73</span>, <span class="fl">0.57</span>, <span class="fl">0.33</span>, <span class="fl">0.28</span>, <span class="fl">0.3</span>, <span class="fl">0.29</span>, <span class="fl">2.15</span>, <span class="fl">0.8</span>, <span class="fl">0.76</span>, <span class="fl">0.54</span>, <span class="fl">0.42</span>, <span class="fl">0.83</span>, <span class="fl">0.21</span>, <span class="fl">0.18</span>, <span class="fl">0.59</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/baddstats/goftest" class="external-link">goftest</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/alexkowa/EnvStats" class="external-link">EnvStats</a></span><span class="op">)</span> <span class="co"># this is required for the Pareto cdf (ppareto)</span></span>
<span></span>
<span><span class="co"># Examine the fit for the gamma distribution (NB: parameters estimated from the data)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/goftest/man/cvm.test.html" class="external-link">cvm.test</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Conc</span>, null <span class="op">=</span> <span class="st">"pgamma"</span>, shape <span class="op">=</span> <span class="fl">2.0591977</span>, scale <span class="op">=</span> <span class="fl">0.3231032</span>, estimated <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Examine the fit for the lognormal distribution (NB: parameters estimated from the data)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/goftest/man/cvm.test.html" class="external-link">cvm.test</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Conc</span>, null <span class="op">=</span> <span class="st">"plnorm"</span>, meanlog <span class="op">=</span> <span class="op">-</span><span class="fl">0.6695120</span>, sd <span class="op">=</span> <span class="fl">0.7199573</span>, estimated <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Examine the fit for the Pareto distribution (NB: parameters estimated from the data)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/goftest/man/cvm.test.html" class="external-link">cvm.test</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Conc</span>, null <span class="op">=</span> <span class="st">"ppareto"</span>, location <span class="op">=</span> <span class="fl">0.1800000</span>, shape <span class="op">=</span> <span class="fl">0.9566756</span>, estimated <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code>    Cramer-von Mises test of goodness-of-fit
    Braun's adjustment using 4 groups
    Null hypothesis: Gamma distribution
    with parameters shape = 2.0591977, scale = 0.3231032
    Parameters assumed to have been estimated from data

data:  dat$Conc
omega2max = 0.34389, p-value = 0.3404


    Cramer-von Mises test of goodness-of-fit
    Braun's adjustment using 4 groups
    Null hypothesis: log-normal distribution
    with parameter meanlog = -0.669512
    Parameters assumed to have been estimated from data

data:  dat$Conc
omega2max = 0.32845, p-value = 0.3719


    Cramer-von Mises test of goodness-of-fit
    Braun's adjustment using 4 groups
    Null hypothesis: distribution ‘ppareto’
    with parameters location = 0.18, shape = 0.9566756
    Parameters assumed to have been estimated from data

data:  dat$Conc
omega2max = 0.31391, p-value = 0.4015</code></pre>
<p>From this output and using a level of significance of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">p = 0.05</annotation></semantics></math>,
we see that none of the distributions is implausible. However, if
<em>forced</em> to choose just one distribution, we would choose the
<em>Pareto</em> distribution (smaller values of the
<code>omega2max</code> statistic are better). However, this does not
mean that the gamma and lognormal distributions are of no value in
describing the data. We can see from the plot below, that in fact both
the gamma and lognormal distributions do a reasonable job over the range
of toxicity values. The use of the Pareto may be a questionable choice
given it is truncated at 0.18 (which is the minimum value of our
toxicity data). <br></p>
<div class="figure">
<img src="model-averaging_files/figure-html/unnamed-chunk-13-1.png" class="r-plt" alt="The example empirical cdf showing how the lognormal, gamma and Pareeto distributions fit these data." width="672"><p class="caption">
Empirical cdf (black); lognormal (green); gamma (blue); and Pareto (red)
</p>
</div>

<p>
<br>As in the earlier example, we might expect to find a better fitting
distribution by combining <em>all three distributions</em> using a
<em>weighted SSD</em>. The issue we face now is <em>how do we choose the
weights</em> to reflect the relative fits of the three distributions?
Like all tests of statistical significance, a <em>p-value</em> is
computed from the value of the relevant <em>test statistic</em> - in
this case, the value of the <code>omega2max</code> test statistic. For
this particular test, it’s a case of the <u>smaller</u> the better. From
the output above we see that the <code>omega2max</code> values are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0.344</mn><annotation encoding="application/x-tex">0.344</annotation></semantics></math>
for the gamma distribution,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0.328</mn><annotation encoding="application/x-tex">0.328</annotation></semantics></math>
for the lognormal distribution, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0.314</mn><annotation encoding="application/x-tex">0.314</annotation></semantics></math>
for the Pareto distribution.
</p>
<p>
We might somewhat naively compute the relative weights as:<br><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>=</mo><mfrac><msup><mn>0.344</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mn>0.344</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><msup><mn>0.328</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><msup><mn>0.314</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mfrac><mo>=</mo><mn>0.318</mn></mrow><annotation encoding="application/x-tex">{w_1} = \frac{{{{0.344}^{ - 1}}}}{{\left( {{{0.344}^{ - 1}} + {{0.328}^{ - 1}} + {{0.314}^{ - 1}}} \right)}} = 0.318</annotation></semantics></math>
       
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub><mo>=</mo><mfrac><msup><mn>0.328</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mn>0.344</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><msup><mn>0.328</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><msup><mn>0.314</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mfrac><mo>=</mo><mn>0.333</mn></mrow><annotation encoding="application/x-tex">{w_2} = \frac{{{{0.328}^{ - 1}}}}{{\left( {{{0.344}^{ - 1}} + {{0.328}^{ - 1}} + {{0.314}^{ - 1}}} \right)}} = 0.333</annotation></semantics></math>
    and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>3</mn></msub><mo>=</mo><mfrac><msup><mn>0.314</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mn>0.344</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><msup><mn>0.328</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><msup><mn>0.314</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mfrac><mo>=</mo><mn>0.349</mn></mrow><annotation encoding="application/x-tex">{w_3} = \frac{{{{0.314}^{ - 1}}}}{{\left( {{{0.344}^{ - 1}} + {{0.328}^{ - 1}} + {{0.314}^{ - 1}}} \right)}} = 0.349</annotation></semantics></math><br>    (we use <em>reciprocals</em> since smaller values of
<code>omega2max</code> represent better fits). As will be seen shortly -
these are incorrect.
</p>
<p>
However, being based on a simplistic measure of discrepancy between the
<em>observed</em> and <em>hypothesized</em> distributions, the
<code>omega2max</code> statistic is a fairly ‘blunt instrument’ and has
no grounding in information theory which <em>is</em> the basis for
determining the weights that we seek.
</p>
<br>A discussion of <em>information theoretic</em> methods for assessing
goodness-of-fit is beyond the scope of this vignette. Interested readers
should consult <span class="citation">(Burnham and Anderson
2002)</span>. A commonly used metric to determine the model-average
weights is the <strong>Akaike Information Criterion</strong> or <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion" class="external-link">AIC</a>.
The formula for the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>I</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">AIC</annotation></semantics></math>
is:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>I</mi><mi>C</mi><mo>=</mo><mn>2</mn><mi>k</mi><mo>−</mo><mn>2</mn><mo>ln</mo><mrow><mo stretchy="true" form="prefix">(</mo><mo>ℓ</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">AIC = 2k - 2\ln \left( \ell  \right)</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
is the number of model parameters and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mo>ℓ</mo><annotation encoding="application/x-tex">\ell</annotation></semantics></math>
is the <em>likelihood</em> for that model. Again, a full discussion of
statistical likelihood is beyond the present scope. A relatively gentle
introduction can be found <a href="https://ep-news.web.cern.ch/what-likelihood-function-and-how-it-used-particle-physics" class="external-link">here</a>.
<p>
</p>
<p>The likelihood for our three distributions can be computed in
<code>R</code> as follows:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html" class="external-link">dgamma</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Conc</span>, shape <span class="op">=</span> <span class="fl">2.0591977</span>, scale <span class="op">=</span> <span class="fl">0.3231032</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] -7.020597</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Lognormal.html" class="external-link">dlnorm</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Conc</span>, meanlog <span class="op">=</span> <span class="op">-</span><span class="fl">0.6695120</span>, sdlog <span class="op">=</span> <span class="fl">0.7199573</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] -5.812947</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu">EnvStats</span><span class="fu">::</span><span class="fu"><a href="https://alexkowa.github.io/EnvStats/reference/Pareto.html" class="external-link">dpareto</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Conc</span>, location <span class="op">=</span> <span class="fl">0.1800000</span>, shape <span class="op">=</span> <span class="fl">0.9566756</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] -5.621683</span></span></code></pre></div>
<p>From which the <em>AIC</em> values readily follow:</p>
<pre><code><span><span class="co">#&gt; AIC for gamma distribution = 18.04119</span></span>
<span><span class="co">#&gt; AIC for lognormal distribution = 15.62589</span></span>
<span><span class="co">#&gt; AIC for Pareto distribution = 15.24337</span></span></code></pre>

<p>
</p>
<p>As with the <code>omega2max</code> statistic,
<strong>smaller</strong> values of <em>AIC</em> are better. Thus, a
comparison of the AIC values above gives the ranking of distributional
fits (best to worst) as: <em>Pareto &gt; lognormal &gt; gamma</em></p>

<div class="section level3">
<h3 id="computing-model-weights-from-the-aic">Computing model weights from the <code>AIC</code><a class="anchor" aria-label="anchor" href="#computing-model-weights-from-the-aic"></a>
</h3>
<p>We will simply provide a formula for computing the model weights from
the <code>AIC</code> values. More detailed information can be found <a href="https://training.visionanalytix.com/ssd-model-averaging/" class="external-link">here</a>.</p>
<p>The <em>AIC</em> for the <em>i<sup>th</sup></em> distribution fitted
to the data is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>I</mi><msub><mi>C</mi><mi>i</mi></msub><mo>=</mo><mn>2</mn><msub><mi>k</mi><mi>i</mi></msub><mo>−</mo><mn>2</mn><mo>ln</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>L</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">AI{C_i} = 2{k_i} - 2\ln \left( {{L_i}} \right)</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>i</mi></msub><annotation encoding="application/x-tex">{L_i}</annotation></semantics></math>
is the <em>i<sup>th</sup> likelihood</em> and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>k</mi><mi>i</mi></msub><annotation encoding="application/x-tex">{k_i}</annotation></semantics></math>
is the <em>number of parameters</em> for the <em>i<sup>th</sup>
distribution</em>. Next, we form the differences:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Δ</mi><mi>i</mi></msub><mo>=</mo><mi>A</mi><mi>I</mi><msub><mi>C</mi><mi>i</mi></msub><mo>−</mo><mi>A</mi><mi>I</mi><msub><mi>C</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">{\Delta _i} = AI{C_i} - AI{C_0}</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>I</mi><msub><mi>C</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">AI{C_0}</annotation></semantics></math>
is the <em>AIC</em> for the <strong>best-fitting</strong> model
(i.e.<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>I</mi><msub><mi>C</mi><mn>0</mn></msub><mo>=</mo><munder><mo>min</mo><mi>i</mi></munder><mrow><mo stretchy="true" form="prefix">{</mo><mi>A</mi><mi>I</mi><msub><mi>C</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">}</mo></mrow></mrow><annotation encoding="application/x-tex">AI{C_0} = \mathop {\min }\limits_i \left\{ {AI{C_i}} \right\}</annotation></semantics></math>
). The <em>model-averaged weights</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mi>i</mi></msub><annotation encoding="application/x-tex">{w_i}</annotation></semantics></math>
are then computed as</p>
<div style="text-align: center; font-size: 1.2em; color: black; border: 1px solid black; padding: 10px; border-radius: 5px;">
<p><b><u>AIC Model Averaging Weights</u></b></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mo>exp</mo><mrow><mo stretchy="true" form="prefix">{</mo><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msub><mi>Δ</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">}</mo></mrow></mrow><mrow><mo>∑</mo><mrow><mo>exp</mo><mrow><mo stretchy="true" form="prefix">{</mo><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msub><mi>Δ</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">}</mo></mrow></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">{w}_{i} = \frac{\exp \left\{ -\frac{1}{2}{{\Delta }_{i}} \right\}}{\sum{\exp \left\{ -\frac{1}{2}{{\Delta }_{i}} \right\}}}</annotation></semantics></math></p>
</div>
<p><br></p>
<p>
</p>
<p>The model-averaged weights for the gamma, lognormal, and Pareto
distributions used in the previous example can be computed ‘manually’ in
<code>R</code> as follows:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1.73</span>, <span class="fl">0.57</span>, <span class="fl">0.33</span>, <span class="fl">0.28</span>, <span class="fl">0.3</span>, <span class="fl">0.29</span>, <span class="fl">2.15</span>, <span class="fl">0.8</span>, <span class="fl">0.76</span>, <span class="fl">0.54</span>, <span class="fl">0.42</span>, <span class="fl">0.83</span>, <span class="fl">0.21</span>, <span class="fl">0.18</span>, <span class="fl">0.59</span><span class="op">)</span></span>
<span><span class="va">aic</span> <span class="op">&lt;-</span> <span class="cn">NULL</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="co"># number of parameters for each of the distributions</span></span>
<span></span>
<span></span>
<span><span class="va">aic</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">k</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html" class="external-link">dgamma</a></span><span class="op">(</span><span class="va">dat</span>, shape <span class="op">=</span> <span class="fl">2.0591977</span>, scale <span class="op">=</span> <span class="fl">0.3231032</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="co"># Gamma distribution</span></span>
<span></span>
<span><span class="va">aic</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">k</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Lognormal.html" class="external-link">dlnorm</a></span><span class="op">(</span><span class="va">dat</span>, meanlog <span class="op">=</span> <span class="op">-</span><span class="fl">0.6695120</span>, sdlog <span class="op">=</span> <span class="fl">0.7199573</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="co"># lognormal distribution</span></span>
<span></span>
<span><span class="va">aic</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">k</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu">EnvStats</span><span class="fu">::</span><span class="fu"><a href="https://alexkowa.github.io/EnvStats/reference/Pareto.html" class="external-link">dpareto</a></span><span class="op">(</span><span class="va">dat</span>, location <span class="op">=</span> <span class="fl">0.1800000</span>, shape <span class="op">=</span> <span class="fl">0.9566756</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="co"># Pareto distribution</span></span>
<span></span>
<span><span class="va">delta</span> <span class="op">&lt;-</span> <span class="va">aic</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">aic</span><span class="op">)</span> <span class="co">#  compute the delta values</span></span>
<span></span>
<span><span class="va">aic.w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> <span class="va">delta</span><span class="op">)</span></span>
<span><span class="va">aic.w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">aic.w</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">aic.w</span><span class="op">)</span>, <span class="fl">4</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span></span>
<span>  <span class="st">" AIC weight for gamma distribution ="</span>, <span class="va">aic.w</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="st">"\n"</span>,</span>
<span>  <span class="st">"AIC weight for lognormal distribution ="</span>, <span class="va">aic.w</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="st">"\n"</span>,</span>
<span>  <span class="st">"AIC weight for pareto distribution ="</span>, <span class="va">aic.w</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span>, <span class="st">"\n"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code> AIC weight for gamma distribution = 0.1191 
 AIC weight for lognormal distribution = 0.3985 
 AIC weight for pareto distribution = 0.4824 </code></pre>

<p>Finally, let’s look at the fitted <em>model-averaged SSD</em>:</p>
<div class="figure">
<img src="model-averaging_files/figure-html/unnamed-chunk-17-1.png" class="r-plt" alt="The example empirical cdf showing how the model average of the lognormal, Gamma and pareto distributions fit these data." width="768"><p class="caption">
Empirical cdf (black) and model-averaged fit (magenta)
</p>
</div>
<p>As can be seen from the figure above, the model-averaged fit provides
a very good fit to the empirical data.</p>
</div>
<div class="section level3">
<h3 id="correcting-for-distributions-having-differing-numbers-of-parameters">Correcting for distributions having differing numbers of
parameters<a class="anchor" aria-label="anchor" href="#correcting-for-distributions-having-differing-numbers-of-parameters"></a>
</h3>
<p>In deriving the AIC, Akaike had to make certain, strong assumptions.
In addition, the bias factor (the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>k</mi></mrow><annotation encoding="application/x-tex">2k</annotation></semantics></math>
term) was derived from theoretical considerations (such as mathematical
<em>expectation</em>) that relate to <em>infinite</em> sample sizes. For
small sample sizes, the AIC is likely to select models having too many
parameters (i.e models which <em>over-fit</em>). In 1978, Sugiura
proposed a modification to the AIC to address this problem, although it
too relied on a number of assumptions. This ‘correction’ to the AIC for
small samples (referred to as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>I</mi><msub><mi>C</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">AI{{C}_{c}}</annotation></semantics></math>)
is</p>
<div style="text-align: center; font-size: 1.2em; color: black; border: 1px solid black; padding: 10px; border-radius: 5px;">
<p><b><u>Corrected Akaike Information Criterion (AICc)</u></b></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi>A</mi><mi>I</mi><mi>C</mi></mrow><mi>c</mi></msub><mo>=</mo><mi>A</mi><mi>I</mi><mi>C</mi><mo>+</mo><mfrac><mrow><mn>2</mn><msup><mi>k</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><mi>k</mi></mrow><mrow><mi>n</mi><mo>−</mo><mi>k</mi><mo>−</mo><mn>1</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">{AIC}_{c} = AIC + \frac{2k^2 + 2k}{n - k - 1}</annotation></semantics></math></p>
<p>where <em>n</em> is the sample size and <em>k</em> is the number of
parameters.</p>
</div>
<p><br></p>
<p>It is clear from the formula for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>I</mi><msub><mi>C</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">AI{{C}_{c}}</annotation></semantics></math>
that for  
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>≫</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n\gg k</annotation></semantics></math>,
  
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>I</mi><msub><mi>C</mi><mi>c</mi></msub><mo>≃</mo><mi>A</mi><mi>I</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">AI{{C}_{c}}\simeq AIC</annotation></semantics></math>.
The issue of sample size is ubiquitous in statistics, but even more so
in ecotoxicology where logistical and practical limitations invariably
mean we are dealing with (pathologically) small sample sizes. There are
no hard and fast rules as to what constitutes an <em>appropriate</em>
sample size for SSD modelling. However, Professor David Fox’s personal
rule of thumb which works quite well is:</p>
<div style="text-align: center; font-size: 1.2em; color: black; border: 1px solid black; padding: 10px; border-radius: 5px;">
<p><b><u>Sample Size Rule-of-Thumb for SSD Modelling</u></b></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>≥</mo><mn>5</mn><mi>k</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">{n \geq 5k + 1}</annotation></semantics></math></p>
<p>where <em>n</em> is the sample size and <em>k</em> is the number of
parameters.</p>
</div>
<p><br></p>
<p>Since most of the common SSD models are 2-parameter, we should be
aiming to have a sample size of at least 11. For 3-parameter models
(like the Burr III), the minimum sample size is 16 and if we wanted to
fit a mixture of two, 2-parameter models (eg.
<em>logNormal-logNormal</em> or <em>logLogistic-logLogistic</em>) the
sample size should be <em>at least</em> 26. Sadly, this is rarely the
case in practice! Jurisdictional guidance material may specify minimum
sample size requirements, and should be adhered to where available and
relevant.</p>
</div>
<div class="section level3">
<h3 id="model-averaging-in-ssdtools">Model-Averaging in <code>ssdtools</code><a class="anchor" aria-label="anchor" href="#model-averaging-in-ssdtools"></a>
</h3>
<p>Please see the <a href="https://bcgov.github.io/ssdtools/articles/ssdtools.html">Getting
started with ssdtools</a> vignette for examples of obtaining
model-averaged <em>HCx</em> values and predictions using
<code>ssdtools</code>.</p>
</div>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-model_averaging" class="csl-entry">
Burnham, Kenneth, and David Anderson. 2002. <em>Model Selection and
Multimodel Inference - a Practical Information-Theoretic Approach</em>.
Springer. <a href="https://link.springer.com/book/10.1007/b97636" class="external-link">https://link.springer.com/book/10.1007/b97636</a>.
</div>
<div id="ref-chapman_2007" class="csl-entry">
Chapman, PF RM, A Hart, W Roelofs, T Aldenberg, K Solomon, J LM
Tarazona, P Byrne, et al. 2007. <span>“Methods of Uncertainty
Analysis.”</span> <em>In: A H (Ed) EUFRAM Concerted Action to Develop a
European Framework for Probabilistic Risk Assessment of the
Environmental Impacts of Pesticides, Vol 2, Detailed Reports on Role,
Methods, Reporting and Validation</em>.
</div>
<div id="ref-fletcher" class="csl-entry">
Fletcher, David. 2018. <em>Model Averaging</em>. Springer. <a href="https://link.springer.com/book/10.1007/978-3-662-58541-2" class="external-link">https://link.springer.com/book/10.1007/978-3-662-58541-2</a>.
</div>
<div id="ref-fox_recent_2021" class="csl-entry">
Fox, D. R., R. A. Dam, R. Fisher, G. E. Batley, A. R. Tillmanns, J.
Thorley, C. J. Schwarz, D. J. Spry, and K. McTavish. 2021. <span>“Recent
<span>Developments</span> in <span>Species</span>
<span>Sensitivity</span> <span>Distribution</span>
<span>Modeling</span>.”</span> <em>Environmental Toxicology and
Chemistry</em> 40 (2): 293–308. <a href="https://doi.org/10.1002/etc.4925" class="external-link">https://doi.org/10.1002/etc.4925</a>.
</div>
<div id="ref-fox_2016" class="csl-entry">
Fox, David R. 2016. <span>“Contemporary Methods for Statistical Design
and Analysis.”</span> <em>In: Blasco J, Chapman PM, Campana O, Hampel M
(Eds) Marine Ecotoxicology.</em>, August. <a href="https://shop.elsevier.com/books/marine-ecotoxicology/blasco/978-0-12-803371-5" class="external-link">https://shop.elsevier.com/books/marine-ecotoxicology/blasco/978-0-12-803371-5</a>.
</div>
<div id="ref-fox_methodologies_2022" class="csl-entry">
Fox, DR, R Fisher, JL Thorley, and C Schwarz. 2022. <span>“Joint
Investigation into <span class="nocase">statistical</span> <span class="nocase">methodologies</span> Underpinning the <span class="nocase">derivation</span> of <span class="nocase">toxicant</span>
<span class="nocase">guideline</span> <span class="nocase">values</span>
in <span>Australia</span> and <span>New Zealand</span>.”</span>
Environmetrics Australia; Australian Institute of Marine Science. <a href="https://doi.org/10.25845/fm9b-7n28" class="external-link">https://doi.org/10.25845/fm9b-7n28</a>.
</div>
<div id="ref-newman_2000" class="csl-entry">
Newman, Michael C., David R. Ownby, Laurent C. A. Mézin, David C.
Powell, Tyler R. L. Christensen, Scott B. Lerberg, and Britt-Anne
Anderson. 2000. <span>“Applying <span class="nocase">species-sensitivity
distributions</span> in <span class="nocase">ecological</span> <span class="nocase">risk assessment</span>: Assumptions of <span class="nocase">distribution type</span> and Sufficient <span class="nocase">numbers of species</span>.”</span> <em>Environmental
Toxicology and Chemistry</em> 19 (February): 508–15. <a href="https://doi.org/10.1002/etc.5620190233" class="external-link">https://doi.org/10.1002/etc.5620190233</a>.
</div>
<div id="ref-Zajdlik_2005" class="csl-entry">
Zajdlik, B. 2005. <span>“Statistical Analysis of the SSD Approach for
Development of Canadian Water Quality Guidelines.”</span> CCME Project
354‐200/5. Zajdlik; Associates.
</div>
</div>
</div>
<div class="section level2">
<h2 id="licensing">Licensing<a class="anchor" aria-label="anchor" href="#licensing"></a>
</h2>
<p>Copyright 2015-2023 Province of British Columbia<br>
Copyright 2021 Environment and Climate Change Canada<br>
Copyright 2023-2025 Australian Government Department of Climate Change,
Energy, the Environment and Water</p>
<p>The documentation is released under the <a href="https://creativecommons.org/licenses/by/4.0/" class="external-link">CC BY 4.0
License</a></p>
<p>The code is released under the <a href="https://www.apache.org/licenses/LICENSE-2.0" class="external-link">Apache License
2.0</a></p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://github.com/joethorley" class="external-link">Joe Thorley</a>, <a href="https://www.aims.gov.au/about/our-people/dr-rebecca-fisher" class="external-link">Rebecca Fisher</a>, <a href="https://training.ecotox.science/who-we-are/" class="external-link">David Fox</a>, <a href="https://www.sfu.ca/stat-actsci/department/profiles/carl-schwarz.html" class="external-link">Carl Schwarz</a>, <a href="https://www2.gov.bc.ca/" class="external-link">Province of British Columbia</a>, <a href="https://www.canada.ca/en/environment-climate-change.html" class="external-link">Environment and Climate Change Canada</a>, <a href="https://www.dcceew.gov.au/" class="external-link">Australian Government Department of Climate Change, Energy, the Environment and Water</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
