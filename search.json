[{"path":[]},{"path":"/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement .github/. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"/CONTRIBUTING.html","id":"how-to-contribute","dir":"","previous_headings":"","what":"How to contribute","title":"NA","text":"Government employees, public members private sector encouraged contribute repository forking submitting pull request. (new GitHub, might start basic tutorial check detailed guide pull requests.) Pull requests evaluated repository guardians schedule deemed beneficial committed master. contributors retain original copyright stuff, contributing project, grant world-wide, royalty-free, perpetual, irrevocable, non-exclusive, transferable license users terms license project distributed. track copyright, please use following: New code file: top file, please ensure copyright attributed collaborator assign Apache 2.0 license Major addition code file: “Copyright Province British Columbia” Apache 2.0 remains header either second collaborator added changes throughout code copyright listed specific lines code. read: Copyright Province British Columbia Copyright Collaborator Apache 2.0 License Copyright Province British Columbia Lines 200-500 Copyright Collaborator Apache 2.0 License Minor changes: small changes code throughout file may easiest keep files Copyright Province British Columbia. However, contribution tracked GitHub.","code":""},{"path":"/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with ssdtools","title":"Getting help with ssdtools","text":"Thanks using ssdtools! filing issue, places explore pieces put together make process smooth possible.","code":""},{"path":"/SUPPORT.html","id":"make-sure-its-new","dir":"","previous_headings":"","what":"Make sure its new","title":"Getting help with ssdtools","text":"opening new issue, sure search issues pull requests make sure bug hasn’t reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers (e.g. :pr, :closed) needed. example, ’d simply remove :open search issues repo, open closed.","code":""},{"path":"/SUPPORT.html","id":"make-a-reprex","dir":"","previous_headings":"","what":"Make a reprex","title":"Getting help with ssdtools","text":"Start making minimal reproducible example using reprex package. haven’t heard used reprex , ’re treat! Seriously, reprex make R-question-asking endeavors easier (pretty insane ROI five ten minutes ’ll take learn ’s ). additional reprex pointers, check Get help! section tidyverse site.","code":""},{"path":"/articles/A_model_averaging.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Model Averaged SSDs","text":"“Many authors noted guiding theory ecotoxicology justify particular distributional form SSD domain restricted positive real line (Newman et al. 2000), (Zajdlik 2005), (Chapman et al. 2007), (Fox 2016). Indeed, (Chapman et al. 2007) described identification suitable probability model one important difficult choices use SSDs. Compounding lack clarity functional form SSD omnipresent, equally vexatious issue small sample size, meaning plausible candidate model unlikely rejected (Fox et al. 2021a). ssdtools R package uses model averaging procedure avoid need -priori select candidate distribution instead uses measure ‘fit’ model compute weights applied initial set candidate distributions. method, applied SSD context described detail (Fox et al. 2021a), potentially provides level flexibility parsimony difficult achieve single SSD distribution”.         (Fox et al. 2021b)","code":""},{"path":"/articles/A_model_averaging.html","id":"preliminaries","dir":"Articles","previous_headings":"","what":"Preliminaries","title":"Model Averaged SSDs","text":"’re familiar process averaging. Indeed, averages pervasive everyday life - talk average income; mean sea level; average global temperature; average height, weight, age etc. etc. ’s obsession averaging? ’s simple really - ’s statisticians call data reduction just fancy name describe process summarising lot raw data using small number (hopefully) representative summary statistics mean standard deviation. Clearly, ’s lot easier work just single mean individual data values. ’s upside. downside process data reduction decimates original data - lose information process. Nevertheless, benefits tend outweigh information loss. Indeed, much ‘conventional’ statistical theory practice focused mean. Examples include T-tests, ANOVA, regression, clustering. talk ‘average’ usually referring simple, arithmetic mean:\\[\\bar{X}=\\frac{1}{n}\\sum\\limits_{=1}^{n}{{{X}_{}}}\\] although recognize types mean including geometric mean, harmonic mean weighted mean. last particularly pertinent model averaging.","code":""},{"path":"/articles/A_model_averaging.html","id":"weighted-averages","dir":"Articles","previous_headings":"Preliminaries The pros and cons of averaging","what":"Weighted Averages","title":"Model Averaged SSDs","text":"simple arithmetic mean, individual values receive weighting - contribute \\(\\frac{1}{n}\\) summation. appropriate many cases, ’s useful components contribute varying degrees. example familiar ecotoxicologists time-varying concentration shown figure .  figure see 5 concentrations going left right: \\(\\left\\{ 0.25,0.95,0.25,0.12,0.5 \\right\\}\\). take simple arithmetic mean concentrations get \\(\\bar{X}=0.414\\). ignores different durations 5 concentrations. 170 hours, 63 concentration 0.25, 25 concentration 0.95, 23 concentration 0.25, 23 concentration 0.12, 36 concentration 0.50. weight concentrations time :\\[{{{\\bar{X}}}_{TW}}=\\frac{\\left( 63\\cdot 0.25+25\\cdot 0.95+23\\cdot 0.25+23\\cdot 0.12+36\\cdot 0.50 \\right)}{\\left( 63+25+23+23+36 \\right)}=\\frac{56.01}{170}=0.33\\], formula weighted average :\\[\\bar{X}=\\sum\\limits_{=1}^{n}{{{w}_{}}{{X}_{}}}\\] \\(0\\le {{w}_{}}\\le 1\\) \\(\\sum\\limits_{=1}^{n}{{{w}_{}}=1}\\).Note, simple arithmetic mean just special case weighted mean \\(\\sum\\limits_{=1}^{n}{{{w}_{}}=\\frac{1}{n}}\\) ; \\(\\forall =1,\\ldots ,n\\)","code":""},{"path":"/articles/A_model_averaging.html","id":"model-averaging","dir":"Articles","previous_headings":"","what":"Model Averaging","title":"Model Averaged SSDs","text":"weighted average acknowledges elements computation equal ‘importance’. example , importance based proportion time concentration particular level. Bayesians well-versed concept - elicitation prior distributions model parameters provides mechanism weighting degree analysis informed existing knowledge versus using purely data-driven approach. Model averaging usually used context estimating model parameters quantities derived fitted model - example EC50 derived C-R model. Let’s motivate discussion using following small dataset toxicity estimates chemical. Now, suppose two possibilities fitting SSD - lognormal distributions. Model 1 LN(-1.067,0.414) distribution Model 2 LN(-0.387,0.617) distribution. plot empirical cdf Models 1 2 shown . Emprirical cdf (black); Model 1(green); Model 2 (blue) see Model 1 fits well lower, left region poorly upper region, reverse true Model 2. using either Model 1 Model 2 going result poor fit overall. However, obvious thing combine models. just try using 50% Model 1 50% Model 2, may sub-optimal. turns best fit obtained using 44% Model 1 56% Model 2. Redrawing plot adding weighted average Models 1 2 shown . Empirical cdf (black); Model 1(green); Model 2 (blue); averaged Model (red) Clearly strategy worked - now excellent fitting SSD.estimation HC20? ’s simple matter work individual HC20 values Models 1&2 using appropriate qlnorm() function R. Thus : averaged distribution? intuitively appealing approach apply weights individual HC20 values applied respective models. 0.44*0.2428209 + 0.56*0.4040243 = 0.33. model-averaged HC20 estimate 0.33. check, can determine fraction affected concentration = 0.33 - course 20%. Let’s take look plot.  Something’s wrong - fraction affected concentration 0.33 30% - required 20%. issue taken next section","code":"#>  [1] 1.73 0.57 0.33 0.28 0.30 0.29 2.15 0.80 0.76 0.54 0.42 0.83 0.21 0.18 0.59 # Model 1 HC20 cat(\"Model 1 HC20 =\",qlnorm(0.2,-1.067,0.414)) #> Model 1 HC20 = 0.2428209  # Model 2 HC20 cat(\"Model 2 HC20 =\",qlnorm(0.2,-0.387,0.617)) #> Model 2 HC20 = 0.4040243"},{"path":"/articles/A_model_averaging.html","id":"model-averaged-ssds","dir":"Articles","previous_headings":"","what":"Model Averaged SSDs","title":"Model Averaged SSDs","text":"correct expression model-averaged SSD : \\[G\\left( x \\right) = \\sum\\limits_{= 1}^k {{w_i}} {F_i}\\left( x \\right)\\] \\({F_i}\\left(  \\cdot  \\right)\\) ith component SSD (.e. cdf) wi weight assigned \\({F_i}\\left(  \\cdot  \\right)\\). Notice function \\(G\\left( x \\right)\\) proper cumulative distribution function (cdf) means given quantile, x, \\(G\\left( x \\right)\\) returns cumulative probability: \\[P\\left[ {X \\leqslant x} \\right]\\] Now, incorrect approach takes weighted sum component inverse cdf’s, : Now, correct method determining HCx work proper model-averaged cdf \\(G\\left( x \\right)\\). means finding inverse function \\({G^{ - 1}}\\left( p \\right)\\). ’ll address moment. example, consider two complex numbers \\[{\\text{= }}\\frac{{\\left( {5 - } \\right)}}{2}{\\text{       }}b =  - 1.683 - 1.915i\\] can shown \\[\\frac{1}{{+ b}} = \\frac{1}{} + \\frac{1}{b} = 0.126 + 0.372i\\] Back issue hand, since ’re dealing complex numbers, ’s safe say:\\[{G^{ - 1}}\\left( p \\right) \\ne H\\left( p \\right)\\] need visual demonstration, can plot \\(G\\left( x \\right)\\) inverse \\(H\\left( p \\right)\\) functions x (quantile) two-component lognormal distribution .   next discuss use model-averaged SSD obtain correct model-averaged HCx.","code":""},{"path":"/articles/A_model_averaging.html","id":"computing-a-model-averaged-hcx","dir":"Articles","previous_headings":"","what":"Computing a model-averaged HCx","title":"Model Averaged SSDs","text":"formally, inversion principle states HCx (denoted \\({\\varphi _x}\\)) must satisfy following: \\[df\\left( {{\\varphi _x}} \\right) = x\\quad \\quad \\quad \\quad qf\\left( x \\right) = {\\varphi _x}\\] \\(df\\left(  \\cdot  \\right)\\) model-averaged distribution function (.e. SSD) \\(qf\\left(  \\cdot  \\right)\\) model-averaged quantile function. equality hold, necessary \\(qf\\left( p \\right) = d{f^{ - 1}}\\left( p \\right)\\). ssdtools following check inversion principle holds:  Note: multi_est argument set FALSE test fail.  inversion principle ensures use single distribution function compute HCx fraction affected. Referring figure , HCx obtained MA-SSD (red curve) following → arrows fraction affected obtained following ← arrows.  Finally, ’ll briefly discuss HCx computed R using method implemented ssdtools.","code":"# Obtain a model-averaged HCx using the ssd_hc() function hcp<-ssd_hc(x, p = p) # Check that the inversion principle holds ssd_hp(x, hcp, multi_est = TRUE) == p   # this should result in logical `TRUE`"},{"path":"/articles/A_model_averaging.html","id":"computing-the-hcx-in-rssdtools","dir":"Articles","previous_headings":"Computing a model-averaged HCx","what":"Computing the HCx in R/ssdtools","title":"Model Averaged SSDs","text":"Obviously, need able ‘codify’ process R (computer language).Mathematically equivalent seeking solution following equation:\\[{x:G\\left( x \\right) = p}\\] , equivalently:\\[x:G\\left( x \\right) - p = 0\\] fraction affected, \\(p\\).  Finding solution last equation referred finding root(s) function \\(G\\left( x \\right)\\) , made clear figure , finding zero-crossing function \\(G\\left( x \\right)\\) case \\(p=0.2\\).  R finding roots \\(x:G\\left( x \\right) - p = 0\\) achieved using uniroot() function. Help uniroot function can found ","code":""},{"path":"/articles/A_model_averaging.html","id":"where-do-the-model-averaged-weights-come-from","dir":"Articles","previous_headings":"","what":"Where do the model-averaged weights come from?","title":"Model Averaged SSDs","text":"little complex, although ’ll try provide non-mathematical explanation. interested going deeper, comprehensive treatment can found (Burnham Anderson 2002) (Fletcher 2018) well -line course .  time, ’ll look fitting gamma, lognormal, pareto distribution sample data: adequacy (otherwise) fitted model can assessed using variety numerical measures known goodness--fit GoF statistics. invariably based measure discrepancy emprical data hypothesized model. Common GoF statistics used test whether hypothesis specified theoretical probability distribution plausible given data set include: Kolmogorov-Smirnov test; Anderson-Darling test; Shapiro-Wilk test;Cramer-von Mises test. Cramer-von Mises test good choice readily performed using cvm.test() function goftest package R follows: output using level significance \\(p = 0.05\\), see none distributions implausible. However, forced choose just one distribution, choose Pareto distribution (smaller values omega2max statistic better). However, mean gamma lognormal distributions value describing data. can see plot , fact gamma lognormal distributions reasonable job range toxicity values. use Pareto may questionable choice given truncated 0.18 (minimum value toxicity data). Emprirical cdf (black); lognormal (green); gamma (blue); Pareeto (red) earlier example, might expect find better fitting distribution combining three distributions using weighted SSD. issue face now choose weights reflect relative fits three distributions? Like tests statistical significance, p-value computed value relevant test statistic - case, value omega2max test statistic. particular test, ’s case smaller better. output see omega2max values \\(0.344\\) gamma distribution, \\(0.328\\) lognormal distribution, \\(0.0.314\\) Pareto distribution. might somewhat naively compute relative weights :\\({w_1} = \\frac{{{{0.344}^{ - 1}}}}{{\\left( {{{0.344}^{ - 1}} + {{0.328}^{ - 1}} + {{0.314}^{ - 1}}} \\right)}} = 0.318\\)         \\({w_2} = \\frac{{{{0.328}^{ - 1}}}}{{\\left( {{{0.344}^{ - 1}} + {{0.328}^{ - 1}} + {{0.314}^{ - 1}}} \\right)}} = 0.333\\)     \\({w_3} = \\frac{{{{0.314}^{ - 1}}}}{{\\left( {{{0.344}^{ - 1}} + {{0.328}^{ - 1}} + {{0.314}^{ - 1}}} \\right)}} = 0.349\\)     (use reciprocals since smaller values omega2max represent better fits). seen shortly - incorrect. However, based simplistic measure discrepancy observed hypothesized distributions, omega2max statistic fairly ‘blunt instrument’ grounding information theory basis determining weights seek. discussion information theoretic methods assessing goodness--fit beyond scope vignette. Interested readers consult (Burnham Anderson 2002) -line course. commonly used metric determine model-average weights Akaike Information Criterion AIC. formula \\(AIC\\) : \\[AIC = 2k - 2\\ln \\left( \\ell  \\right)\\]  likelihood three distributions can computed R follows: AIC values readily follow:  omega2max statistic, smaller values AIC better. Thus, comparison AIC values gives ranking distributional fits (best worst) : Pareto > lognormal > gamma","code":"#>  [1] 1.73 0.57 0.33 0.28 0.30 0.29 2.15 0.80 0.76 0.54 0.42 0.83 0.21 0.18 0.59 dat<-data.frame(Conc=c(1.73,0.57,0.33,0.28,0.3,0.29,2.15,0.8,0.76,0.54,0.42,0.83,0.21,0.18,0.59)) library(goftest) library(EnvStats)  # this is required for the Pareto cdf (ppareto)  # Examine the fit for the gamma distribution (NB: parameters estimated from the data) cvm.test(dat$Conc,null = \"pgamma\",shape = 2.0591977,scale = 0.3231032,estimated = TRUE)  # Examine the fit for the lognormal distribution (NB: parameters estimated from the data) cvm.test(dat$Conc,null = \"plnorm\",meanlog=-0.6695120,sd=0.7199573,estimated = TRUE)  # Examine the fit for the Pareto distribution (NB: parameters estimated from the data) cvm.test(dat$Conc,null = \"ppareto\",location = 0.1800000,shape    = 0.9566756,estimated = TRUE) Cramer-von Mises test of goodness-of-fit     Braun's adjustment using 4 groups     Null hypothesis: Gamma distribution     with parameters shape = 2.0591977, scale = 0.3231032     Parameters assumed to have been estimated from data  data:  dat$Conc omega2max = 0.34389, p-value = 0.3404       Cramer-von Mises test of goodness-of-fit     Braun's adjustment using 4 groups     Null hypothesis: log-normal distribution     with parameter meanlog = -0.669512     Parameters assumed to have been estimated from data  data:  dat$Conc omega2max = 0.32845, p-value = 0.3719       Cramer-von Mises test of goodness-of-fit     Braun's adjustment using 4 groups     Null hypothesis: distribution ‘ppareto’     with parameters location = 0.18, shape = 0.9566756     Parameters assumed to have been estimated from data  data:  dat$Conc omega2max = 0.31391, p-value = 0.4015 sum(log(EnvStats::dpareto(dat$Conc,location = 0.1800000, shape=0.9566756)))  #> [1] -5.621683 sum(log(dgamma(dat$Conc,shape = 2.0591977,scale = 0.3231032)))  #> [1] -7.020597 sum(log(dlnorm(dat$Conc, meanlog = -0.6695120,sdlog   =  0.7199573)))  #> [1] -5.812947 #> AIC for gamma distribution = 18.04119 #> AIC for lognormal distribution = 15.62589 #> AIC for Pareto distribution = 15.24337"},{"path":"/articles/A_model_averaging.html","id":"computing-model-weights-from-the-aic","dir":"Articles","previous_headings":"Where do the model-averaged weights come from?","what":"Computing model weights from the AIC","title":"Model Averaged SSDs","text":"simply provide formula computing model weights AIC values. detailed information can found . AIC ith distribution fitted data \\[AI{C_i} = 2{k_i} - 2\\ln \\left( {{L_i}} \\right)  \\] \\({L_i}\\) ith likelihood \\({k_i}\\) number parameters ith distribution. Next, form differences:\\[{\\Delta _i} = AI{C_i} - AI{C_0}\\] \\(AI{C_0}\\) AIC best-fitting model (.e.\\(AI{C_0} = \\mathop {\\min }\\limits_i \\left\\{ {AI{C_i}} \\right\\}\\) ). model-averaged weights \\({w_i}\\) computed :  model-averaged weights gamma, lognormal, Pareto distributions used previous example can computed ‘manually’ R follows: Finally, let’s look fitted model-averaged SSD: Empirical cdf (black) model-averaged fit (magenta) can seen figure , model-averaged fit provides good fit empirical data.","code":"dat<-c(1.73,0.57,0.33,0.28,0.3,0.29,2.15,0.8,0.76,0.54,0.42,0.83,0.21,0.18,0.59) aic<-NULL k<-2  # number of parameters for each of the distributions   aic[1]<-2*k-2*sum(log(dgamma(dat,shape = 2.0591977,scale = 0.3231032))) # Gamma distribution  aic[2]<-2*k-2*sum(log(dlnorm(dat, meanlog = -0.6695120,sdlog   =  0.7199573)))  # lognormal distribution  aic[3]<-2*k-2*sum(log(EnvStats::dpareto(dat,location = 0.1800000, shape=0.9566756))) # Pareto distribution  delta<-aic-min(aic)  #  compute the delta values  aic.w<-exp(-0.5*delta); aic.w<-round(aic.w/sum(aic.w),4)  cat(\" AIC weight for gamma distribution =\",aic.w[1],\"\\n\",     \"AIC weight for lognormal distribution =\",aic.w[2],\"\\n\",     \"AIC weight for pareto distribution =\",aic.w[3],\"\\n\") AIC weight for gamma distribution = 0.1191   AIC weight for lognormal distribution = 0.3985   AIC weight for pareto distribution = 0.4824"},{"path":"/articles/A_model_averaging.html","id":"correcting-for-distributions-having-differing-numbers-of-parameters","dir":"Articles","previous_headings":"Where do the model-averaged weights come from?","what":"Correcting for distributions having differing numbers of parameters","title":"Model Averaged SSDs","text":"deriving AIC, Akaike make certain, strong assumptions. addition, bias factor (\\(2k\\) term) derived theoretical considerations (mathematical expectation) relate infinite sample sizes. small sample sizes, AIC likely select models many parameters (.e models -fit) 1978, Sugiura proposed modification AIC address problem, although relied number assumptions. ‘correction’ AIC small samples (referred \\(AI{{C}_{c}}\\)) : clear formula \\(AI{{C}_{c}}\\)   \\(n\\gg k\\),    \\(AI{{C}_{c}}\\simeq AIC\\). issue sample size ubiquitous statistics, even ecotoxicology logistical practical limitations invariably mean dealing (pathologically) small sample sizes. hard fast rules constitutes appropriate sample size SSD modelling. However, Professor David Fox’s personal rule thumb works quite well : Since common SSD models 2-parameter, aiming sample size least 11. 3-parameter models (like Burr III), minimum sample size 16 wanted fit mixture two, 2-parameter models (eg. logNormal-logNormal logLogistic-logLogistic) sample size least 26. Sadly, rarely case practice!","code":""},{"path":"/articles/A_model_averaging.html","id":"model-averaging-in-ssdtools","dir":"Articles","previous_headings":"Where do the model-averaged weights come from?","what":"Model-Averaging in ssdtools","title":"Model Averaged SSDs","text":"Please see Getting started ssdtools vignette examples obtaining model-averaged HCx values predictions using ssdtools.","code":""},{"path":[]},{"path":"/articles/A_model_averaging.html","id":"licensing","dir":"Articles","previous_headings":"","what":"Licensing","title":"Model Averaged SSDs","text":"Copyright 2024 Province British Columbia, Environment Climate Change Canada, Australian Government Department Climate Change, Energy, Environment Water documentation released CC 4.0 License code released Apache License 2.0","code":""},{"path":"/articles/B_distributions.html","id":"distributions-for-ssd-modelling","dir":"Articles","previous_headings":"","what":"Distributions for SSD modelling","title":"Distributions in ssdtools","text":"Many authors noted guiding theory ecotoxicology justify particular distributional form SSD domain restricted positive real line (Newman et al. 2000; Zajdlik 2005; Fox 2016). Distributions selected use model averaging SSDs must bounded zero given effect concentrations negative. must also continuous, generally unbounded right. Furthermore, selected distributions within candidate model set provide variety shapes capture diversity shapes empirical species sensitivity distributions. wide range distributions implemented ssdtools, although distributions appear default set. provide detailed account distributions available ssdtools, guidance use.","code":""},{"path":"/articles/B_distributions.html","id":"original-ssdtools-distributions","dir":"Articles","previous_headings":"Distributions for SSD modelling","what":"Original ssdtools distributions","title":"Distributions in ssdtools","text":"log-normal, log-logistic Gamma distributions widely used SSD modelling, part original distribution set early releases ssdtools developed Thorley Schwarz 2018. adopted default set three distributions early updates ssdtools associated ShinyApp (Dalgarno 2021). three distributions show good convergence properties retained part default model set version 2.0 ssdtools. addition log-normal, log-logistic Gamma distributions, original version ssdtools developed Thorley Schwarz 2018 also included three additional distributions candidate model set, including log-gumbel, Gompertz Weibull distributions. , log-Gumbel (otherwise known inverse Weibull, see ) shows relatively good convergence (see Figure 32, Fox et al. 2021b), also one limiting distributions Burrr Type 3 distribution implemented ssdtools, retained default model set. Gompertz Weibull distributions, however can exhibit unstable behaviour, sometimes showing poor convergence, therefore excluded default set (see Figure 32, Fox et al. 2021b)","code":""},{"path":"/articles/B_distributions.html","id":"burr-iii-distribution","dir":"Articles","previous_headings":"Distributions for SSD modelling","what":"Burr III distribution","title":"Distributions in ssdtools","text":"history Burrlioz primary distributions used recently summmarized Fox et al. (2021a). “2000, Australia New Zealand (Australian New Zealand Environment Conservation Council/Agriculture Resource Management Council Australia New Zealand 2000) adopted SSD‐based method deriving WQBs, following critical review multiple WQB derivation methods (Warne 1998). distinct feature method use 3‐parameter Burr distribution model empirical SSD, implemented Burrlioz software tool (Campbell et al. 2000). represented generalization methods previously employed Aldenberg Slob (1993) log–logistic distribution shown speciﬁc case Burr family (Tadikamalla 1980). Recent revision derivation method recognized using 3‐parameter Burr distributions small sample sizes (<8 species) created additional uncertainty estimating parameters justiﬁed, essentially overﬁtting data (Batley et al. 2018). Consequently, method, updated software (Burrlioz Ver 2.0), now uses 2‐parameter log–logistic distribution small data sets, whereas Burr type III distribution used data sets 8 species (Batley et al. 2018; Australian New Zealand Guidelines 2018).”         (Fox et al. 2021a) probability density function, \\({f_X}(x;b,c,k)\\) cumulative distribution function, \\({F_X}(x;b,c,k)\\) Burr III distribution :   Burr type III distribution adopted default distribution Burrlioz, well known (e.g., Tadikamalla (1980)) Burr III distribution related several theoretical distributions, exist limiting cases Burr III, .e., one Burr III parameters approaches either zero infinity. Burrlioz software incorporates logic aims identify situations parameter estimates tending towards either large small values. cases, fitting Burr III distribution abandoned one limiting distributions fitted instead. Specifically: c tends infinity Burr III distribution tends inverse (North American) Pareto distribution (see technical details) k tends infinity Burr III distribution tends inverse Weibull (log-Gumbel) distribution (see technical details) practical terms, Burr III distribution fitted k estimated greater 100, estimation procedure carried using inverse Weibull distribution. Similarly, c greater 80 (American) Pareto distribution fitted. necessary ensure numerical stability. Since Burr type III, inverse Pareto inverse Weibull (log Gumbel) distributions used Burrlioz software, implemented ssdtools. However, found stability issues Burr type III, well inverse Pareto distributions, currently precludes inclusion default model set (see Fox et al. (2021b), details).","code":""},{"path":"/articles/B_distributions.html","id":"bimodal-distributions","dir":"Articles","previous_headings":"Distributions for SSD modelling","what":"Bimodal distributions","title":"Distributions in ssdtools","text":"use statistical mixture-models promoted Fox convenient realistic way modelling bimodal toxicity data (Fisher et al. 2019). Although parameter heavy, statistical mixture models provide better conceptual match inherent underlying data generating process since directly model bimodality mixture 2 underlying univariate distributions represent, example, different modes action (Fox et al. 2021a). postulated mixture-model selected model-averaging context fit afforded mixture demonstrably better fit afforded single distribution. consequence high penalty AICc associated increased number parameters (p Equation 7 (Fox et al. 2021a)) pronounced relatively small sample sizes. TMB version ssdtools now includes option fitting two mixture distributions, individually part model average set. can fitted using ssdtools supplying strings “llogis_llogis” /“lnorm_lnorm” dists argument ssd_fit_dists call. underlying code mixtures three components: likelihood function required TMB; exported R functions allow usual methods distribution called (p, q r); set supporting R functions (see Fox et al. (2021b) Appendix D details). mixtures five parameters - two parameters component distributions mixing parameter (pmix) defines weighting two distributions ‘mixture.’","code":""},{"path":"/articles/B_distributions.html","id":"sample-lognormal-mixture-distributions","dir":"Articles","previous_headings":"","what":"Distributions in ssdtools","title":"Distributions in ssdtools","text":"can see plot , mixture distributions provide highly flexible means modelling bimodality emprical SSD. happens, example, toxicity data toxicant include animal plant species, different modes action operating. Unfortunately, increased flexibilty comes high penalty model-averaging process. combination small sample sizes high parameter count (typically 5 ) means mixture distributions -weighted - even good job describing data. reason, attempting model bimodal data, suggest looking fit using default set distributions examining fit just one either log-normal mixture log-logistic mixture. Keep mind done sample size pathologically small. guide, Prof. David Fox recommends absolute minimum \\(n \\ge 3k + 1\\) preferably \\(n \\ge 5k + 1\\) \\(k\\) number model parameters.","code":""},{"path":"/articles/B_distributions.html","id":"default-distributions","dir":"Articles","previous_headings":"","what":"Default Distributions","title":"Distributions in ssdtools","text":"variety distributions available ssdtools, inclusion estimating model-averaged SSD recommended. default, ssdtools uses (corrected) Akaike Information Criterion small sample size (AICc) measure relative quality fit different distributions basis calculating model-averaged weights. However, choice distributions used fit model-averaged SSD can profound effect estimated HCx values. Deciding final default set distributions adopt using model averaging approach non-trivial, acknowledge probably definitive ‘solution’ issue. However, default set underpinned guiding principle parsimony, .e., set large necessary cover wide variety distributional shapes contingencies bigger. , default set result model-averaged estimates HCx values : 1) minimise bias; 2) actual coverages confidence intervals close nominal level confidence; 3) estimated HCx confidence intervals HCx robust small changes data; 4) represent positively continuous distribution right left tails. ssdtools development team undertaken extensive simulation studies, well detailed technical examinations various candidate distributions examine issues bias, coverage numerical stability. detailed account findings can found report (Fox et al. 2021b) repeated detail , although issues associated individual distributions outlined .","code":""},{"path":"/articles/B_distributions.html","id":"currently-recommended-default-distributions","dir":"Articles","previous_headings":"Default Distributions","what":"Currently recommended default distributions","title":"Distributions in ssdtools","text":"default list candidate distributions ssdtools comprised following: log-normal; log-logistic; gamma; inverse Weibull (log-Gumbel); Weibull; mixture two log-normal distributions default distributions plotted mean 2 standard deviation 2 (natural) log concentration scale around 7.4 concentration scale.","code":""},{"path":"/articles/B_distributions.html","id":"distributions-currently-implemented-in-ssdtools","dir":"Articles","previous_headings":"","what":"Distributions currently implemented in ssdtools","title":"Distributions in ssdtools","text":"Developed Joe Thorley, Rebecca Fisher, David Fox, Carl Schwarz, Province British Columbia, Environment Climate Change Canada, Australian Government Department Climate Change, Energy, Environment Water. Site built pkgdown 2.0.9.","code":""},{"path":"/articles/B_distributions.html","id":"burr-type-iii-distribution","dir":"Articles","previous_headings":"Distributions currently implemented in ssdtools","what":"Burr Type III distribution","title":"Distributions in ssdtools","text":"Burr Type 3 flexible three parameter distribution can fitted using ssdtools supplying string burrIII3 dists argument ssd_fit_dists call. Burr family distributions central derivation guideline values Australia New Zealand 20 yr (Fox et al. 2021a). offering high degree ﬂexibility, experience distributions time repeatedly highlighted numerical stability convergence issues parameters estimated using maximum likelihood (Fox et al. 2021a). thought due high degree collinearity parameter estimates /relatively ﬂat likelihood proﬁles (Fox et al. 2021a), one motivations behind logic coded Burrlioz revert either two limiting distributions. Burr Type 3 distribution currently one recommended distributionsin default model set. 1) convergence issues associated Burr Type 3 distribution, 2) fact reverting limiting two parameter distribution fit easily within model averaging framework, 3) one two limiting distributions (inverse Pareto, see ) also estimation convergence issues.","code":""},{"path":"/articles/B_distributions.html","id":"log-normal","dir":"Articles","previous_headings":"Distributions currently implemented in ssdtools","what":"Log-normal","title":"Distributions in ssdtools","text":"log-normal distribution commonly used distribution natural sciences - particularly probability model describe right (positive)-skewed pehnomena concentration data. random variable, \\(X\\) lognormally distributed logarithm \\(X\\) normally distributed. pdf \\(X\\) given lognormal distribution selected starting distribution given data effect concentrations. log-normal distribution can fitted using ssdtools supplying string lnorm dists argument ssd_fit_dists call.","code":""},{"path":[]},{"path":[]},{"path":"/articles/B_distributions.html","id":"log-logistic-distribution","dir":"Articles","previous_headings":"Distributions currently implemented in ssdtools","what":"Log-logistic distribution","title":"Distributions in ssdtools","text":"Like lognormal distribution, log-logistic similarly defined, : \\(X\\) log-logistic distribution, \\(Y = \\ln (X)\\) logistic distribution. letting \\(\\mu  = \\ln \\left( \\alpha  \\right)\\) \\(s = \\frac{1}{\\beta }\\) : log-logistic distribution often used candidate SSD primarily analytic tractability (Aldenberg Slob 1993). included wider tails log-normal specific case general Burr family distributions Burr (1942). log-logistic distribution can fitted using ssdtools supplying string lnorm dists argument ssd_fit_dists call.","code":""},{"path":"/articles/B_distributions.html","id":"gamma-distribution","dir":"Articles","previous_headings":"Distributions currently implemented in ssdtools","what":"Gamma distribution","title":"Distributions in ssdtools","text":"two-parameter gamma distribution following pdf cdf. \\(\\Gamma \\left(  \\cdot  \\right)\\) gamma function (R simply gamma(x)) \\(\\gamma \\left(  \\cdot  \\right)\\) (lower) incomplete gamma function \\[\\gamma \\left( {x,} \\right) = \\int\\limits_0^x {{t^{- 1}}} \\,{e^{ - t}}\\,dt\\] (can computed using gammainc function pracma package R). use modeling species sensitivity data, gamma distribution two key features provide additional flexibility relative log-normal distribution: 1) asymmetrical logarithmic scale; 2) wider tails. gamma distribution can fitted using ssdtools supplying string “gamma” dists argument ssd_fit_dists call.","code":""},{"path":[]},{"path":[]},{"path":"/articles/B_distributions.html","id":"log-gumbel-inverse-weibull-distribution","dir":"Articles","previous_headings":"Distributions currently implemented in ssdtools","what":"Log-gumbel (inverse Weibull) distribution","title":"Distributions in ssdtools","text":"log-gumbel distribution two-parameter distribution commonly used model extreme values. log-gumbel distribution can fitted using ssdtools supplying string lgumbel dists argument ssd_fit_dists call. two-parameter log-gumbel distribution following pdf cdf:","code":""},{"path":"/articles/B_distributions.html","id":"gompertz-distribution","dir":"Articles","previous_headings":"Distributions currently implemented in ssdtools","what":"Gompertz distribution","title":"Distributions in ssdtools","text":"Gompertz distribution flexible distribution exhibits positive negative skewness. Gompertz distribution can fitted using ssdtools supplying string gompertz dists argument ssd_fit_dists call. condiser two parameterisations Gompertz distribution.first, given Wikipedia also used ssdtools [Gompertz] following pdf cdf: second parameterisation product \\(b\\eta\\) formulae replaced parameter \\(\\) giving:   Gompertz distribution available ssdtools, however parameter estimation can somewhat unstable (Fox et al. 2021b), reason currently included default set.","code":""},{"path":"/articles/B_distributions.html","id":"weibull-distribution","dir":"Articles","previous_headings":"Distributions currently implemented in ssdtools","what":"Weibull distribution","title":"Distributions in ssdtools","text":"inclusion Weibull distribution inverse Pareto distribution (see next) ssdtools primarily necessitated need maintain consistency calculations undertaken Burrlioz. mentioned earlier, Weibull inverse Pareto distributions arise limiting distributions Burr parameters \\(c\\) \\(k\\) tend either zero /infinity specific ways. two-parameter Weibull distribution following pdf cdf: Weibull distribution can fitted ssdtools supplying string weibull dists argument ssd_fit_dists call.","code":""},{"path":"/articles/B_distributions.html","id":"inverse-pareto-distribution","dir":"Articles","previous_headings":"Distributions currently implemented in ssdtools","what":"Inverse Pareto distribution","title":"Distributions in ssdtools","text":"inverse Pareto distribution can fitted using ssdtools supplying string invpareto dists argument ssd_fit_dists call. inverse Pareto distribution implemented Burrlioz 2.0 software, important understand done one limiting Burr distributions (see technical details). inverse Pareto offered stand-alone option Burrlioz 2.0 software. spent considerable time effort exploring properties inverse Pareto distribution, including deriving bias correction equations alternative methods deriving confidence intervals (Fox et al. 2021b). work substantial value improving current Burrlioz 2.0 method, bias corrections adopted deriving HCx estimates inverse Pareto parameters estimated using maximum likelihood. case Burrlioz 2.0 software, decided include inverse Pareto distribution default candidate set ssdtools although offered ass user-selectable distribution use model-fitting process. many statistical distributions, different ‘variants’ exist. ‘variants’ much different distributions simple re-parameterisations. example, many distributions scale parameter, \\(\\beta\\) authors texts use \\(\\beta\\) others use \\(\\frac{1}{\\beta }\\). example re-paramterisation given Gompertz distribution. choice mathematical representation may purely preferential, sometimes done mathematical convenience. example, Parameterisation Gompertz distribution obtained letting \\(= b\\eta\\) Parameterisation II. re-expression involving parameters \\(b\\) \\(\\eta\\) particularly useful trying fit distribution one \\(\\left\\{ {b,\\,\\eta } \\right\\}\\) small large. already noted particular parameterisation (Inverse)Pareto distribution used Burrlioz 2.0 ssdtools matter preference, rather dictated mathematical considerations demonstrated convergence Burr distribution one specific version (Inverse)Pareto distribution. mathematics provides elegant solution otherwise problematic situation, version (Inverse)Pareto distribution particularly use stand-alone distribution fitting SSD (special, limiting case Burr distribution). two versions (Inverse)Pareto distribution known European North American versions. pdfs cdfs given . Importantly, see North American versions distributions bounded Pareto distribution bounded \\(\\beta\\) inverse Pareto distribution bounded \\(\\frac{1}{\\beta }\\).aside, mle \\(\\beta\\) Pareto distribution \\[\\hat \\beta  = \\min \\left\\{ {{X_1}, \\ldots ,{X_n}} \\right\\}\\] mle \\(\\frac{1}{\\beta }\\) inverse Pareto \\[\\begin{array}{*{20}{l}} {\\tilde \\beta  = \\max \\left\\{ {{Y_1}, \\ldots ,{Y_n}} \\right\\}}\\\\ {\\quad  = \\max \\left\\{ {\\frac{1}{{{X_1}}}, \\ldots ,\\frac{1}{{{X_n}}}} \\right\\} = \\frac{1}{{\\min \\left\\{ {{X_1}, \\ldots ,{X_n}} \\right\\}}}}\\\\ {\\quad  = \\frac{1}{{\\hat \\beta }}} \\end{array}\\]. mle \\(\\alpha\\) : \\[\\hat \\alpha  = {\\left[ {\\ln \\left( {\\frac{g}{{\\hat \\beta }}} \\right)} \\right]^{ - 1}}\\] \\(g\\) geometric mean: \\[g = {\\left[ {\\prod\\limits_{= 1}^n {{X_i}} } \\right]^{\\frac{1}{n}}}\\] Thus, doesn’t matter whether ’re fitting Pareto inverse Pareto distribution data - parameter estimates . bounded, North American version (Inverse)Pareto distribution useful stand-alone SSD - inverse Pareto distribution since bounded .  see pdf plots  alternative, European version inverse Pareto distribution realistic candidate. note passing versions Pareto inverse Pareto distrbutions availabale R. example, Rpackage extraDistr North American versions, actuar package European versions.","code":""},{"path":"/articles/B_distributions.html","id":"inverse-weibull-distribution-see-log-gumbel-above","dir":"Articles","previous_headings":"Distributions currently implemented in ssdtools","what":"Inverse Weibull distribution (see log-Gumbel, above)","title":"Distributions in ssdtools","text":"inverse Weibull mathematically equivalent log-Gumbel distribution described . also limiting distribution Burr Type 3, distribution show instability issues, unbounded right. therefore represents valid SSD distribution included default model set distribution right. inverse Weibull (log-Gumbel) distribution can fitted ssdtools supplying string lgumbel dists argument ssd_fit_dists call.","code":""},{"path":"/articles/B_distributions.html","id":"relationships-among-distributions-in-ssdtools","dir":"Articles","previous_headings":"","what":"Relationships among distributions in ssdtools","title":"Distributions in ssdtools","text":"diagram , \\(X\\) denotes random variable box beginning arrow expression beside arrow indicates mathematical transformation \\(X\\) resultant transformed data distribution identified box end arrow. Reciprocal transformations (\\(\\frac{1}{X}\\)) bi-directional (\\(\\leftrightarrow\\)). Although negative exponential distribution explicitly included ssdtools, special case gamma distribution \\(c=1\\). included figure related distributions included ssdtools. European versions Pareto inverse Pareto distributions unbounded; North American versions bounded.","code":""},{"path":[]},{"path":"/articles/B_distributions.html","id":"licensing","dir":"Articles","previous_headings":"","what":"Licensing","title":"Distributions in ssdtools","text":"Copyright 2024 Province British Columbia, Environment Climate Change Canada, Australian Government Department Climate Change, Energy, Environment Water documentation released CC 4.0 License code released Apache License 2.0","code":""},{"path":"/articles/C_confidence_intervals.html","id":"bootstrap-confidence-intervals","dir":"Articles","previous_headings":"","what":"Bootstrap confidence intervals","title":"Obtaining Confidence Intervals","text":"Bootstrapping resampling technique used obtain estimates summary statistics. team explored use alternative methods obtaining confidence interval HCx estimates. included using closed-form expression variance-covariance matrix parameters Burr III distribution, coupled delta-method, well alternative bootstrap method inverse Pareto distribution based statistical properties parameters (Fox et al. 2021). cases, appeared methods can give results similar traditional bootstrapping approaches much less time, therefore potentially worth investigation. However, implementation methods across distributions now available ssdtools substantial undertaking. revised version ssdtools retains computationally intensive bootstrapping method obtain confidence intervals estimate standard errors. recommend minimum bootstrap sample 1,000 (current default - see argument nboot ?ssd_hc()). However, reliable results can obtained using samples 5,000 10,000. recommend larger bootstrap samples final reporting.","code":""},{"path":"/articles/C_confidence_intervals.html","id":"parametric-versus-non-parametric-bootstrapping","dir":"Articles","previous_headings":"","what":"Parametric versus non-parametric bootstrapping","title":"Obtaining Confidence Intervals","text":"Burrlioz 2.0 uses non-parametric bootstrap method obtain confidence intervals HCx estimate. Non-parametric bootstrapping carried repeatedly resampling raw data replacement, refitting distribution many times. 95% confidence limits obtained calculating lower 0.025th upper 0.975th quantiles resulting HCx estimates across all56 bootstrap samples (typically >1000). type bootstrap takes account uncertainty distribution fit based uncertainty data. ssdtools package default uses parametric bootstrap. Instead resampling data, parametric bootstrapping draws random set new data (sample size original) fitted distribution repeatedly refit distribution. Upper lower 95% bounds calculated lower 0.025th upper 0.975th quantiles resulting HCx estimates across bootstrap samples (, typically >1000). capture possible uncertainty may occur sample size given distribution, assumes uncertainty original fit, accounting uncertainty input data. new TMB version ssdtools capacity bootstrapping either using Burrlioz non-parametric method, original parametric method ssdtools (based fitdistrplus (Delignette-Muller Dutang 2015)). Using simulation studies ssdtools team examined bias compared resulting coverage parametric non-parametric bootstrapping methods (Fox et al. 2021). found coverage better using parametric bootstrapping method, retained default bootstrapping method update ssdtools.","code":""},{"path":"/articles/C_confidence_intervals.html","id":"bootstrapping-model-averaged-ssds","dir":"Articles","previous_headings":"","what":"Bootstrapping model-averaged SSDs","title":"Obtaining Confidence Intervals","text":"Bootstrapping obtain confidence intervals individual fitted distributions relatively straightforward. However, obtaining bootstrap confidence intervals model-averaged SSDs requires careful consideration, procedure subject pitfalls evident obtaining model-averaged HCx estimates. Model Average SSDs vignette contains detailed explanation fallacy using summed weighting individual HCx values (weighted arithmetic average), can lead spurious results. Model-averaged estimates /confidence intervals (including standard error) can calculated treating distributions constituting single mixture distribution versus ‘taking mean’. calculating model-averaged estimates treating distributions constituting single mixture distribution ensures ssd_hc() inverse ssd_hp(), applies model-averaged confidence intervals. revised version ssdtools supports three weighting methods obtaining bootstrap confidence intervals estimate standard error, discussed detail .","code":""},{"path":"/articles/C_confidence_intervals.html","id":"weighted-arithmetic-mean","dir":"Articles","previous_headings":"Bootstrapping model-averaged SSDs","what":"Weighted arithmetic mean","title":"Obtaining Confidence Intervals","text":"early versions ssdtools provided model-averaged confidence intervals (cis) standard errors (se) calculated weighted arithmetic means upper lower cis se values obtained via bootstrap simulation individual candidate distributions independently. method incorrect may lead spurious results (described ) shown via simulations studies result confidence intervals low coverage. current version ssdtools retains functionality reproduce original behavior ssdtools. Use method obtaining ci se values recommended retained legacy comparison purposes. technically incorrect, computationally inefficient.","code":"fit <- ssd_fit_dists(data = ssddata::ccme_silver) set.seed = 99  # Using the original ssdtools weighted arithmetic mean hc1 <- ssd_hc(fit, ci = TRUE, multi_est = FALSE, multi_ci = FALSE, weighted = FALSE) hc1 #> # A tibble: 1 × 11 #>   dist    proportion   est    se    lcl   ucl    wt method   nboot pboot samples #>   <chr>        <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <chr>    <dbl> <dbl> <I<lis> #> 1 average       0.05 0.192 0.216 0.0679 0.861     1 paramet…  1000 0.998 <dbl>"},{"path":"/articles/C_confidence_intervals.html","id":"weighted-mixture-distribution","dir":"Articles","previous_headings":"Bootstrapping model-averaged SSDs","what":"Weighted mixture distribution","title":"Obtaining Confidence Intervals","text":"theoretically correct way obtaining ci se values consider model average set mixture distribution (see , Model Average SSDs vignette). consider model set mixture distribution, bootstrapping achieved resampling model set according AICc based model weights. method sampling mixture distributions implemented ssdtools, via function ssd_rmulti(), generate random samples mixture combination distributions currently implemented ssdtools. Setting “multi_ci = TRUE” ssd_hc() call ensure bootstrap samples drawn mixture distribution, instead individual candidate distributions. bootstrapping mixture distribution, question arises whether model weights re-estimated every bootstrap sample, fixed values estimated models fitted original sample toxicity data? interesting question may warrant investigation, however current view fixed nominal values way component distributions used bootstrapping informed fit sample toxicity data. Using simulation studies explored coverage bias ci values obtained without without fixing distribution weights, results indicate little difference. treating distributions single mixture distribution calculating model average confidence intervals (.e. “multi_ci = TRUE”), setting “weighted = FALSE” specifies use original model weights. Setting “weighted = TRUE” result bootstrapping re-estimate weights bootstrap sample. following code can used obtain confidence intervals HCx estimates via bootstrapping weighted mixture distribution (using ssd_rmutli()), without fixed weight values respectively. Use method (without without fixed weights) theoretically correct, computationally inefficient.","code":"# Using the rmulti boostrapping method with fixed weights hc2 <- ssd_hc(fit, ci = TRUE, multi_est = TRUE, multi_ci = TRUE, weighted = FALSE) hc2 #> # A tibble: 1 × 11 #>   dist    proportion   est    se    lcl   ucl    wt method   nboot pboot samples #>   <chr>        <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <chr>    <dbl> <dbl> <I<lis> #> 1 average       0.05 0.190 0.212 0.0216 0.878     1 paramet…  1000     1 <dbl> # Using the rmulti boostrapping method with fixed weights hc3 <- ssd_hc(fit, ci = TRUE, multi_est = TRUE, multi_ci = TRUE, weighted = TRUE) hc3 #> # A tibble: 1 × 11 #>   dist    proportion   est    se    lcl   ucl    wt method   nboot pboot samples #>   <chr>        <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <chr>    <dbl> <dbl> <I<lis> #> 1 average       0.05 0.190 0.208 0.0216 0.813     1 paramet…  1000     1 <dbl>"},{"path":"/articles/C_confidence_intervals.html","id":"weighted-bootstrap-sample","dir":"Articles","previous_headings":"Bootstrapping model-averaged SSDs","what":"Weighted bootstrap sample","title":"Obtaining Confidence Intervals","text":"developers ssdtools investigated third method obtaining confidence intervals model-averaged SSD. method bootstraps distributions individually, taking weighted sample , combining pooled bootstrap sample estimation te ci se values. Psuedo code method follows: distribution fitdists object, proportional number bootstrap samples draw (nboot_vals) found using round(nboot * weight), nboot total number bootstrap samples weight AICc based model weights distribution based original ssd_fitdist fit. nboot_vals distribution, random sample size N drawn (total number original data points included original SSD fit) based estimated parameters original data distribution. random sample re-fitting using distribution. HCx estimated re-fitted bootstrap fit. HCx estimates nboot_vals distribution pooled across distributions, quantile() used determine lower upper confidence bounds pooled weighted bootstrap sample HCx values. method draw random samples mixture distribution using ssd_rmulti (thus “multi_ci = FALSE”). mathematically method shares properties obtaining HCx estimates via summing weighted values (weighted arithmetic mean), simulation studies shown , method obtaining confidence intervals, pooled weighted sample method yields similar ci values coverage ssd_rmulti() method, computationally much faster. method currently default method ssdtools, can implemented setting “multi_ci = FALSE” “weighted = TRUE” ssd_hc() call. , argument “weighted = TRUE” specifies take bootstrap samples distribution proportional weight (sum nboot).","code":"# Using a weighted pooled bootstrap sample hc4 <- ssd_hc(fit, ci = TRUE, multi_est = FALSE, multi_ci = FALSE, weighted = TRUE) hc4 #> # A tibble: 1 × 11 #>   dist    proportion   est    se    lcl   ucl    wt method   nboot pboot samples #>   <chr>        <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <chr>    <dbl> <dbl> <I<lis> #> 1 average       0.05 0.192 0.214 0.0181 0.816     1 paramet…  1000 0.999 <dbl>"},{"path":"/articles/C_confidence_intervals.html","id":"comparing-bootrapping-methods","dir":"Articles","previous_headings":"","what":"Comparing bootrapping methods","title":"Obtaining Confidence Intervals","text":"undertaken extensive simulation studies comparing implemented methods, results reported elsewhere. illustrative purposes, compare upper lower confidence intervals using single example data set, Silver data set Canadian Council Ministers Environment (ccme). Using default settings ssdtools, compared upper lower confidence intervals four bootstrapping methods described . Estimate upper confidence limits relatively similar among four methods. However, lower confidence interval obtained using weighted arithmetic mean (method implemented earlier versions ssdtools) much higher three methods, potentially accounting relatively poor coverage method simulation studies.  Given similarity upper lower confidence intervals weighted bootstrap sample method compared potentially theoretically correct, computationally intensive weighted mixture method (via ssd_rmulti()), also compared time taken undertake bootstrapping across methods. Using default 1,000 bootstrap samples, elapsed time undertake bootstrapping mixture method 29.07 seconds, compared 2.66 seconds weighted bootstrap sample. means weighted bootstrap method ~ 11 times faster, representing considerable computational saving across many SSDs. reason, method currently set default method confidence interval estimation ssdtools.","code":"library(ggplot2) library(ggpubr) p1 <- ggplot(compare_dat, aes(method, ucl, fill = method)) +     geom_bar(stat=\"identity\", position=position_dodge()) +   theme_classic() +   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) p2 <- ggplot(compare_dat, aes(method, lcl, fill = method)) +     geom_bar(stat=\"identity\", position=position_dodge()) +   theme_classic() +   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))  ggarrange(p1, p2,common.legend = TRUE) p3 <- ggplot(compare_dat, aes(method, time, fill = method)) +     geom_bar(stat=\"identity\", position=position_dodge()) +     ylab(\"Elapsed time (seconds)\") +     theme_classic() +     theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) p3"},{"path":[]},{"path":"/articles/C_confidence_intervals.html","id":"licensing","dir":"Articles","previous_headings":"","what":"Licensing","title":"Obtaining Confidence Intervals","text":"Copyright 2024 Province British Columbia, Environment Climate Change Canada, Australian Government Department Climate Change, Energy, Environment Water documentation released CC 4.0 License code released Apache License 2.0","code":""},{"path":"/articles/D_embelishing-plots.html","id":"plotting-the-cumulative-distribution","dir":"Articles","previous_headings":"","what":"Plotting the cumulative distribution","title":"Customising Plots","text":"ssdtools package produces plot cumulative distribution functions multiple input distributions use ssd_plot_cdf() function. example, consider boron data. can fit, plot cdf using:  graphic ggplot object can saved embellished usual way.","code":"library(ggplot2) library(ssdtools)  fits <- ssd_fit_dists(ssddata::ccme_boron) gp <- ssd_plot_cdf(fits)  print(gp)"},{"path":[]},{"path":"/articles/D_embelishing-plots.html","id":"plot-the-model-averaged-fit-with-individual-fits","dir":"Articles","previous_headings":"Customising the cumulative distribution plot","what":"Plot the model-averaged fit with individual fits","title":"Customising Plots","text":"can add model-averaged cdf first obtaining predicted values, extending default ssdtools ggplot usual way using geom_line:","code":"library(ssddata) library(ssdtools) library(ggplot2)  dist <- ssdtools::ssd_fit_dists(ssddata::ccme_boron) pred <- predict(dist, ci = FALSE) boron_hc5 <- ssd_hc(dist) ssdtools::ssd_plot_cdf(dist) +   geom_line(data = pred, aes(x = est, y = proportion, colour = \"Model average\", lty = \"Model average\"), lwd = 0.75) +   scale_linetype_manual(name = \"Distribution\", breaks = c(\"Model average\", names(dist)), values = 1:7) +   scale_color_manual(name = \"Distribution\", breaks = c(\"Model average\", names(dist)), values = 1:7) +   theme_bw()"},{"path":"/articles/D_embelishing-plots.html","id":"other-customisations","dir":"Articles","previous_headings":"Customising the cumulative distribution plot","what":"Other customisations","title":"Customising Plots","text":"ssdtools package provides four ggplot geoms allow construct plots. first geom_ssdpoint() plots species sensitivity data  second geom_ssdsegments() plots range censored species sensitivity data  third geom_xribbon() plots species sensitivity confidence intervals  fourth geom_hcintersect() plots hazard concentrations  can combined together follows  log x-axis add following code.  recent plot can saved file using ggsave(), also allows user set resolution.","code":"ggplot(ccme_boron) +   geom_ssdpoint(aes(x = Conc)) +   ylab(\"Probability density\") +   xlab(\"Concenration\") ggplot(ccme_boron) +   geom_ssdsegment(aes(x = Conc, xend = Conc * 2)) +   ylab(\"Probability density\") +   xlab(\"Concenration\") ggplot(boron_pred) +   geom_xribbon(aes(xmin = lcl, xmax = ucl, y = proportion)) +   ylab(\"Probability density\") +   xlab(\"Concenration\") ggplot() +   geom_hcintersect(xintercept = c(1, 2, 3), yintercept = c(0.05, 0.1, 0.2)) +   ylab(\"Probability density\") +   xlab(\"Concenration\") gp <- ggplot(boron_pred, aes(x = est)) +   geom_xribbon(aes(xmin = lcl, xmax = ucl, y = proportion), alpha = 0.2) +   geom_line(aes(y = proportion)) +   geom_ssdsegment(data = ccme_boron, aes(x = Conc / 2, xend = Conc * 2)) +   geom_ssdpoint(data = ccme_boron, aes(x = Conc / 2)) +   geom_ssdpoint(data = ccme_boron, aes(x = Conc * 2)) +   scale_y_continuous(\"Species Affected (%)\", labels = scales::percent) +   expand_limits(y = c(0, 1)) +   xlab(\"Concentration (mg/L)\") print(gp + geom_hcintersect(xintercept = boron_hc5$est, yintercept = 5 / 100)) gp <- gp + coord_trans(x = \"log10\") +   scale_x_continuous(     breaks = scales::trans_breaks(\"log10\", function(x) 10^x),     labels = comma_signif   ) print(gp + geom_hcintersect(xintercept = boron_hc5$est, yintercept = 0.05)) ggsave(\"file_name.png\", dpi = 600)"},{"path":"/articles/D_embelishing-plots.html","id":"fitting-and-plotting-distributions-to-multiple-groups-such-taxa-andor-chemicals","dir":"Articles","previous_headings":"","what":"Fitting and plotting distributions to multiple groups such taxa and/or chemicals","title":"Customising Plots","text":"elegant approach using tidyverse packages demonstrated . resultant data predictions can plotted follows.","code":"library(ssddata) library(ssdtools) library(ggplot2) library(dplyr) library(tidyr) library(purrr)  boron_preds <- nest(ccme_boron, data = c(Chemical, Species, Conc, Units)) %>%   mutate(     Fit = map(data, ssd_fit_dists, dists = \"lnorm\"),     Prediction = map(Fit, predict)   ) %>%   unnest(Prediction) library(ssdtools) library(ssddata) ssd_plot(ccme_boron, boron_preds, xlab = \"Concentration (mg/L)\", ci = FALSE) +   facet_wrap(~Group)"},{"path":"/articles/D_embelishing-plots.html","id":"embellishing-plots-with-an-exposure-distribution","dir":"Articles","previous_headings":"","what":"Embellishing Plots with an Exposure Distribution","title":"Customising Plots","text":"example, suppose want superimpose environmental concentration cumulative distribution compute exposure risk outlined Verdonck et al. (2003). Finding suitable probability distribution describe exposure concentration beyond scope document – assume done elsewhere. particular, suppose exposure concentration follows log-normal distribution mean -2.3 standard deviation 1 logarithmic scale. exposure distribution, construct data frame concentration values cumulative probability seeing exposure less environment. Notice care needed ssdtools plot logarithmic base 10 scale natural logarithm base \\(e\\) scale. now add plot  ssdtools package contains function ssd_exposure() computes risk defined Verdonck et al (2003) representing average proportion species risk. risk 0.00624 can also added plot usual way:","code":"ex.cdf <- data.frame(Conc = exp(seq(log(.01), log(10), .1))) # generate a grid of concentrations ex.cdf$ex.cdf <- plnorm(ex.cdf$Conc,   meanlog = ex.mean.log,   sdlog = ex.sd.log ) # generate the cdf gp +   geom_line(data = ex.cdf, aes(x = Conc, y = ex.cdf), color = \"red\", linewidth = 2) +   annotate(\"text\",     label = paste(\"Exposure distribution\"),     x = 1.08 * ex.cdf$Conc[which.max(ex.cdf$ex.cdf > 0.5)], y = 0.5, angle = 75   ) set.seed(99) ex.risk <- ssd_exposure(fits, meanlog = ex.mean.log, sdlog = ex.sd.log) ex.risk ## [1] 0.0062416 gp +   geom_line(dat = ex.cdf, aes(x = Conc, y = ex.cdf), color = \"red\", linewidth = 2) +   annotate(\"text\",     label = paste(\"Exposure distribution\"),     x = 1.08 * ex.cdf$Conc[which.max(ex.cdf$ex.cdf > 0.5)], y = 0.5, angle = 75   ) +   annotate(\"text\",     label = paste(\"Verdonck risk :\", round(ex.risk, 5)),     x = Inf, y = 0, hjust = 1.1, vjust = -.5   )"},{"path":[]},{"path":"/articles/D_embelishing-plots.html","id":"licensing","dir":"Articles","previous_headings":"","what":"Licensing","title":"Customising Plots","text":"Copyright 2024 Province British Columbia, Environment Climate Change Canada, Australian Government Department Climate Change, Energy, Environment Water documentation released CC 4.0 License code released Apache License 2.0","code":""},{"path":"/articles/E_additional-technical-details.html","id":"small-sample-bias","dir":"Articles","previous_headings":"","what":"Small sample bias","title":"Additional technical details","text":"ssdtools package uses method Maximum Likelihood (ML) estimate parameters distribution fit data. Statistical theory says maximum likelihood estimators asymptotically unbiased, guarantee performance small samples. detailed account issue small sample bias estimates can found following pdf.","code":""},{"path":[]},{"path":"/articles/E_additional-technical-details.html","id":"burr-iii-distribution","dir":"Articles","previous_headings":"The inverse Pareto and inverse Weibull as limiting distributions of the Burr Type-III distribution","what":"Burr III distribution","title":"Additional technical details","text":"probability density function, \\({f_X}(x;b,c,k)\\) cumulative distribution function, \\({F_X}(x;b,c,k)\\) Burr III distribution (also known Dagum distribution) used ssdtools :","code":""},{"path":"/articles/E_additional-technical-details.html","id":"inverse-pareto-distribution","dir":"Articles","previous_headings":"The inverse Pareto and inverse Weibull as limiting distributions of the Burr Type-III distribution","what":"Inverse Pareto distribution","title":"Additional technical details","text":"Let \\(X \\sim Burr(b,c,k)\\) pdf given box . well known distribution \\(Y = \\frac{1}{X}\\) inverse Burr distribution (also known SinghMaddala distribution) :\\[\\begin{array}{*{20}{c}} {{f_Y}(y;b,c,k) = \\frac{{c{\\kern 1pt} {\\kern 1pt} k{{\\left( {\\frac{y}{b}} \\right)}^c}}}{{y{\\kern 1pt} {{\\left[ {1 + {{\\left( {\\frac{y}{b}} \\right)}^c}} \\right]}^{k + 1}}}}}&{b,c,k,y > 0} \\end{array}\\] \\[\\begin{array}{*{20}{c}} {{F_Y}(y;b,c,k) = 1 - \\frac{1}{{{{\\left[ {1 + {{\\left( {\\frac{y}{b}} \\right)}^c}} \\right]}^k}}}}&{b,c,k,y > 0} \\end{array}\\] now consider limiting distribution \\(c \\\\infty\\) \\(k \\0\\) way product \\(ck\\) remains constant, .e. \\(ck = \\lambda\\). Now, \\[\\begin{array}{l} \\mathop {\\mathop {\\lim }\\limits_{(c,k) \\(\\infty ,0)} }\\limits_{ck = \\lambda } \\left\\{ {{F_Y}(y;b,c,k)} \\right\\} = 1 - \\mathop {\\mathop {\\lim }\\limits_{(c,k) \\(\\infty ,0)} }\\limits_{ck = \\lambda } \\frac{1}{{{{\\left[ {1 + {{\\left( {\\frac{y}{b}} \\right)}^c}} \\right]}^k}}}\\\\ \\\\ \\\\ \\\\ \\mathop {\\mathop {\\lim }\\limits_{(c,k) \\(\\infty ,0)} }\\limits_{ck = \\lambda } {\\left[ {1 + {{\\left( {\\frac{y}{b}} \\right)}^c}} \\right]^k} = \\mathop {\\mathop {\\lim }\\limits_{(c,k) \\(\\infty ,0)} }\\limits_{ck = \\lambda } \\left\\{ {{{\\left( {\\frac{y}{b}} \\right)}^{ck}}{{\\left[ {1 + {{\\left( {\\frac{b}{y}} \\right)}^c}} \\right]}^k}} \\right\\}\\\\ \\\\ \\\\ \\\\ \\mathop {\\mathop {\\lim }\\limits_{(c,k) \\(\\infty ,0)} }\\limits_{ck = \\lambda } \\left\\{ {{{\\left( {\\frac{y}{b}} \\right)}^{ck}}{{\\left[ {1 + {{\\left( {\\frac{b}{y}} \\right)}^c}} \\right]}^k}} \\right\\} = \\mathop {\\mathop {\\lim }\\limits_{(c,k) \\(\\infty ,0)} }\\limits_{ck = \\lambda } \\left\\{ {{{\\left( {\\frac{y}{b}} \\right)}^{ck}}} \\right\\}\\mathop {\\mathop {\\lim }\\limits_{(c,k) \\(\\infty ,0)} }\\limits_{ck = \\lambda } \\left\\{ {{{\\left[ {1 + {{\\left( {\\frac{b}{y}} \\right)}^c}} \\right]}^k}} \\right\\}\\\\ = \\mathop {\\mathop {\\lim }\\limits_{(c,k) \\(\\infty ,0)} }\\limits_{ck = \\lambda } \\left\\{ {{{\\left( {\\frac{y}{b}} \\right)}^{ck}}} \\right\\}\\; \\cdot \\,1\\\\ = {\\left( {\\frac{y}{b}} \\right)^\\lambda } \\end{array}\\] Therefore, \\[\\begin{array}{*{20}{c}} {\\mathop {\\mathop {\\lim }\\limits_{(c,k) \\(\\infty ,0)} }\\limits_{ck = \\lambda } \\left\\{ {{F_Y}(y;b,c,k)} \\right\\} = 1 - {{\\left( {\\frac{b}{y}} \\right)}^\\lambda }}&{y \\ge b} \\end{array}\\] recognise (American) Pareto distribution. , limiting distribution \\(Y = \\frac{1}{X}\\) Pareto distribution, limiting distribution \\(X = \\frac{1}{Y}\\) (American) inverse Pareto distribution: \\[\\begin{array}{l} {f_X}\\left( {x;\\alpha ,\\beta } \\right) = \\lambda {b^\\lambda }{x^{\\lambda  - 1}};{\\rm{  }}0 \\le x \\le {\\textstyle{1 \\b}};{\\rm{  }}\\lambda {\\rm{,}}b > 0\\\\ {F_X}\\left( {x;\\alpha ,\\beta } \\right) = {\\left( {xb} \\right)^\\lambda };{\\rm{  }}0 \\le x \\le {\\textstyle{1 \\b}};{\\rm{  }}\\lambda {\\rm{,}}b > 0 \\end{array}\\] completeness, MLEs distribution closed-form expressions given : \\[\\begin{array}{l} \\hat \\lambda  = {\\left[ {\\ln \\left( {\\frac{{{g_X}}}{{\\hat b}}} \\right)} \\right]^{ - 1}}\\\\ \\hat b = \\frac{1}{{\\max \\left\\{ {{X_i}} \\right\\}}}{\\rm{ }} \\end{array}\\] \\({\\rm{ }}{g_X}\\)geometric mean data.","code":""},{"path":"/articles/E_additional-technical-details.html","id":"inverse-weibull-distribution","dir":"Articles","previous_headings":"The inverse Pareto and inverse Weibull as limiting distributions of the Burr Type-III distribution","what":"Inverse Weibull distribution","title":"Additional technical details","text":"Let \\(X \\sim Burr(b,c,k)\\) pdf given box . make transformation \\[Y = \\frac{{b{\\kern 1pt} {k^{\\tfrac{1}{c}}}{\\kern 1pt} \\theta }}{X}\\] \\(\\theta\\) parameter (constant). distribution \\(Y\\) also Burr distribution cdf \\[{G_Y}\\left( y \\right) = 1 - \\frac{1}{{{{\\left[ {1 + {{\\left( {\\frac{y}{{{k^{\\tfrac{1}{c}}}{\\kern 1pt} \\theta }}} \\right)}^c}} \\right]}^k}}}\\].interested limiting behaviour Burr distribution \\(k \\\\infty\\). Now,\\[\\mathop {\\lim }\\limits_{k \\\\infty } {G_Y}\\left( y \\right) = 1 - \\mathop {\\lim }\\limits_{k \\\\infty } {\\left[ {1 + {{\\left( {\\frac{y}{{{k^{\\tfrac{1}{c}}}{\\kern 1pt} \\theta }}} \\right)}^c}} \\right]^{ - k}}\\] \\[{ = 1 - \\mathop {\\lim }\\limits_{k \\\\infty } {{\\left[ {1 + \\frac{{{{\\left( {\\frac{y}{\\theta }} \\right)}^c}}}{{k{\\kern 1pt} }}} \\right]}^{ - k}}}\\] \\[\\begin{matrix}    =1-\\exp \\left[ -{{\\left( \\frac{y}{\\theta } \\right)}^{c}} \\right]  \\\\    \\left\\{ \\text{using fact }\\underset{n\\\\infty }{\\mathop{\\lim }}\\,{{\\left( 1+{}^{z}\\!\\!\\diagup\\!\\!{}_{n}\\; \\right)}^{-n}}={{e}^{-z}} \\right\\}  \\\\ \\end{matrix}\\] recognise last expression cdf Weibull distribution parameters \\(c\\) \\(\\theta\\).","code":""},{"path":"/articles/E_additional-technical-details.html","id":"licensing","dir":"Articles","previous_headings":"","what":"Licensing","title":"Additional technical details","text":"Copyright 2024 Province British Columbia, Environment Climate Change Canada, Australian Government Department Climate Change, Energy, Environment Water documentation released CC 4.0 License code released Apache License 2.0","code":""},{"path":"/articles/ssdtools.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting Started with ssdtools","text":"ssdtools R package fit Species Sensitivity Distributions (SSDs) using Maximum Likelihood model averaging. SSDs cumulative probability distributions used estimate percent species affected /protected given concentration chemical. concentration affects 5% species referred 5% Hazard Concentration (HC5). equivalent 95% protection value (PC95). information SSDs reader referred Posthuma et al. (2001). order use ssdtools need install R (see ) use Shiny app. shiny app includes user guide. vignette user manual R package.","code":""},{"path":"/articles/ssdtools.html","id":"philosophy","dir":"Articles","previous_headings":"","what":"Philosophy","title":"Getting Started with ssdtools","text":"ssdtools provides key functionality required fit SSDs using Maximum Likelihood model averaging R. intended used conjunction tidyverse packages readr input data, tidyr dplyr group manipulate data ggplot2 (Wickham 2016) plot data. endeavors fulfill tidyverse manifesto.","code":""},{"path":"/articles/ssdtools.html","id":"installing","dir":"Articles","previous_headings":"","what":"Installing","title":"Getting Started with ssdtools","text":"order install R (R Core Team 2018) appropriate binary users operating system downloaded CRAN installed. R installed, ssdtools package can installed (together tidyverse) executing following code R console ssdtools package (ggplot2 package) can loaded current session using","code":"install.packages(c(\"ssdtools\", \"tidyverse\")) library(ssdtools) library(ggplot2)"},{"path":"/articles/ssdtools.html","id":"getting-help","dir":"Articles","previous_headings":"","what":"Getting Help","title":"Getting Started with ssdtools","text":"get additional information particular function just type ? followed name function R console. example ?ssd_gof brings R documentation ssdtools goodness fit function. information using R reader referred R Data Science (Wickham Grolemund 2016). discover bug ssdtools please file issue reprex (repeatable example) https://github.com/bcgov/ssdtools/issues.","code":""},{"path":"/articles/ssdtools.html","id":"inputting-data","dir":"Articles","previous_headings":"","what":"Inputting Data","title":"Getting Started with ssdtools","text":"ssdtools package loaded next task input data. easy way save concentration data single chemical column called Conc comma separated file (.csv). row sensitivity concentration separate species. species /group information available can saved Species Group columns. .csv file can read R using following purposes manual use CCME dataset boron.","code":"data <- read_csv(file = \"path/to/file.csv\") ccme_boron <- ssddata::ccme_boron print(ccme_boron) #> # A tibble: 28 × 5 #>    Chemical Species                  Conc Group        Units #>    <chr>    <chr>                   <dbl> <fct>        <chr> #>  1 Boron    Oncorhynchus mykiss       2.1 Fish         mg/L  #>  2 Boron    Ictalurus punctatus       2.4 Fish         mg/L  #>  3 Boron    Micropterus salmoides     4.1 Fish         mg/L  #>  4 Boron    Brachydanio rerio        10   Fish         mg/L  #>  5 Boron    Carassius auratus        15.6 Fish         mg/L  #>  6 Boron    Pimephales promelas      18.3 Fish         mg/L  #>  7 Boron    Daphnia magna             6   Invertebrate mg/L  #>  8 Boron    Opercularia bimarginata  10   Invertebrate mg/L  #>  9 Boron    Ceriodaphnia dubia       13.4 Invertebrate mg/L  #> 10 Boron    Entosiphon sulcatum      15   Invertebrate mg/L  #> # ℹ 18 more rows"},{"path":"/articles/ssdtools.html","id":"fitting-distributions","dir":"Articles","previous_headings":"","what":"Fitting Distributions","title":"Getting Started with ssdtools","text":"function ssd_fit_dists() inputs data frame fits one distributions. user can specify subset following 10 distributions. Please see Distributions Model averaging vignettes information appropriate use distributions use model-averaged SSDs. using dists argument.","code":"ssd_dists_all() #>  [1] \"burrIII3\"      \"gamma\"         \"gompertz\"      \"invpareto\"     #>  [5] \"lgumbel\"       \"llogis\"        \"llogis_llogis\" \"lnorm\"         #>  [9] \"lnorm_lnorm\"   \"weibull\" fits <- ssd_fit_dists(ccme_boron, dists = c(\"llogis\", \"lnorm\", \"gamma\"))"},{"path":"/articles/ssdtools.html","id":"coefficients","dir":"Articles","previous_headings":"","what":"Coefficients","title":"Getting Started with ssdtools","text":"estimates various terms can extracted using tidyverse generic tidy function (base R generic coef function).","code":"tidy(fits) #> # A tibble: 6 × 4 #>   dist   term           est    se #>   <chr>  <chr>        <dbl> <dbl> #> 1 llogis locationlog  2.63  0.248 #> 2 llogis scalelog     0.740 0.114 #> 3 lnorm  meanlog      2.56  0.235 #> 4 lnorm  sdlog        1.24  0.166 #> 5 gamma  scale       25.1   7.64  #> 6 gamma  shape        0.950 0.223"},{"path":"/articles/ssdtools.html","id":"plots","dir":"Articles","previous_headings":"","what":"Plots","title":"Getting Started with ssdtools","text":"generally informative plot fits using autoplot generic function (wrapper ssd_plot_cdf()). autoplot returns ggplot object can modified prior plotting.","code":"theme_set(theme_bw()) # set plot theme  autoplot(fits) +   ggtitle(\"Species Sensitivity Distributions for Boron\") +   scale_colour_ssd()"},{"path":"/articles/ssdtools.html","id":"selecting-one-distribution","dir":"Articles","previous_headings":"","what":"Selecting One Distribution","title":"Getting Started with ssdtools","text":"Given multiple distributions user faced choosing “best” distribution (discussed averaging results weighted fit). ssd_gof() function returns three test statistics can used evaluate fit various distributions data. Anderson-Darling (ad) statistic, Kolmogorov-Smirnov (ks) statistic Cramer-von Mises (cvm) statistic three information criteria Akaike’s Information Criterion (AIC), Akaike’s Information Criterion corrected sample size (AICc) Bayesian Information Criterion (BIC) Note ssd_gof() called pvalue = TRUE p-values rather statistics returned ad, ks cvm tests. Following Burnham Anderson (2002) recommend AICc model selection. best predictive model lowest AICc (indicated model delta value 0.000 goodness fit table). current example best predictive model gamma distribution lnorm distribution support. information advantages information theoretic approach context selecting SSDs reader referred Fox et al. (2021).","code":"ssd_gof(fits) #> # A tibble: 3 × 9 #>   dist      ad     ks    cvm   aic  aicc   bic delta weight #>   <chr>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl> #> 1 llogis 0.487 0.0994 0.0595  241.  241.  244.  3.38  0.11  #> 2 lnorm  0.507 0.107  0.0703  239.  240.  242.  1.40  0.296 #> 3 gamma  0.440 0.117  0.0554  238.  238.  240.  0     0.595"},{"path":"/articles/ssdtools.html","id":"averaging-multiple-distributions","dir":"Articles","previous_headings":"","what":"Averaging Multiple Distributions","title":"Getting Started with ssdtools","text":"Often distributions fit data almost well best distribution evidenced delta values < 2 (Burnham Anderson 2002). situation recommended approach estimate average fit based relative weights distributions (Burnham Anderson 2002). AICc based weights indicated weight column goodness fit table. current example, gamma log-normal distributions delta values < 2. detailed introduction model averaging can found Model averaging vignette. discussion recommended set default distributions can found Distributions vignette.","code":""},{"path":"/articles/ssdtools.html","id":"estimating-the-fit","dir":"Articles","previous_headings":"","what":"Estimating the Fit","title":"Getting Started with ssdtools","text":"predict function can used generate model-averaged (average = FALSE individual) estimates parametric bootstrapping. Model averaging based AICc unless data censored case AICc undefined. situation model averaging possible distributions number parameters. Parametric bootstrapping computationally intensive. bootstrap distribution parallel register future back-end select evaluation strategy. resultant object data frame estimated concentration (est) standard error (se) lower (lcl) upper (ucl) 95% confidence limits (CLs) percent species affected (percent). object includes number bootstraps (nboot) data sets generated well proportion data sets successfully fitted (pboot). requirement bootstrap samples converge. data frame estimates can plotted together original data using ssd_plot() function summarize analysis. returned object ggplot object can customized prior plotting.  plot model-averaged 95% confidence interval indicated shaded band model-averaged 5%/95% Hazard/Protection Concentration (HC5/ PC95) dotted line. Hazard/Protection concentrations discussed .","code":"doFuture::registerDoFuture() future::plan(future::multisession)  set.seed(99) boron_pred <- predict(fits, ci = TRUE) boron_pred #> # A tibble: 99 × 11 #>    dist    proportion   est    se    lcl   ucl    wt method  nboot pboot samples #>    <chr>        <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <chr>   <dbl> <dbl> <I<lis> #>  1 average       0.01 0.267 0.401 0.0418  1.53     1 parame…  1000 0.999 <dbl>   #>  2 average       0.02 0.531 0.517 0.110   2.03     1 parame…  1000 0.999 <dbl>   #>  3 average       0.03 0.783 0.614 0.198   2.50     1 parame…  1000 0.999 <dbl>   #>  4 average       0.04 1.02  0.700 0.300   2.90     1 parame…  1000 0.999 <dbl>   #>  5 average       0.05 1.26  0.781 0.407   3.29     1 parame…  1000 0.999 <dbl>   #>  6 average       0.06 1.48  0.859 0.520   3.72     1 parame…  1000 0.999 <dbl>   #>  7 average       0.07 1.71  0.933 0.645   4.16     1 parame…  1000 0.999 <dbl>   #>  8 average       0.08 1.93  1.01  0.768   4.58     1 parame…  1000 0.999 <dbl>   #>  9 average       0.09 2.16  1.08  0.896   4.95     1 parame…  1000 0.999 <dbl>   #> 10 average       0.1  2.38  1.15  1.03    5.39     1 parame…  1000 0.999 <dbl>   #> # ℹ 89 more rows ssd_plot(ccme_boron, boron_pred,   color = \"Group\", label = \"Species\",   xlab = \"Concentration (mg/L)\", ribbon = TRUE ) +   expand_limits(x = 5000) + # to ensure the species labels fit   ggtitle(\"Species Sensitivity for Boron\") +   scale_colour_ssd()"},{"path":"/articles/ssdtools.html","id":"hazardprotection-concentrations","dir":"Articles","previous_headings":"","what":"Hazard/Protection Concentrations","title":"Getting Started with ssdtools","text":"5% hazard concentration (HC5) concentration affects 5% species tested. equivalent 95% protection concentration protects 95% species (PC95). hazard protection concentrations directly interchangeable, terminology depends simply user preference. hazard/protection concentrations can obtained using ssd_hc function, can used obtain desired percentage value. fitted SSD can also used determine percentage species protected given concentration using ssd_hp.","code":"set.seed(99) boron_hc5 <- ssd_hc(fits, proportion =  0.05, ci = TRUE) print(boron_hc5) #> # A tibble: 1 × 11 #>   dist    proportion   est    se   lcl   ucl    wt method    nboot pboot samples #>   <chr>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>     <dbl> <dbl> <I<lis> #> 1 average       0.05  1.32 0.849 0.370  3.67     1 parametr…  1000     1 <dbl> boron_pc <- ssd_hp(fits, conc = boron_hc5$est, ci = TRUE) print(boron_pc) #> # A tibble: 1 × 11 #>   dist     conc   est    se   lcl   ucl    wt method     nboot pboot samples   #>   <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>      <dbl> <dbl> <I<list>> #> 1 average  1.32     5  3.23 0.586  12.8     1 parametric  1000     1 <dbl [0]>"},{"path":"/articles/ssdtools.html","id":"censored-data","dir":"Articles","previous_headings":"Hazard/Protection Concentrations","what":"Censored Data","title":"Getting Started with ssdtools","text":"Censored data lower /upper limit known particular species. right argument ssd_fit_dists() different left argument data considered censored. Let’s make example censored data. less goodness--fit statistics available fits censored data (currently just AIC BIC). delta values calculated using AIC`. sample size n undefined censored data, AICc calculated. However, models number parameters, AIC delta values identical AICc. reason, ssdtools permits analysis censored data using two-parameter models. can call default two parameter models using ssd_dists_bcanz(n = 2). model-averaged predictions (hazard concentrations complete 95% confidence limits) can calculated using AIC results plotted complete arrows indicating censorship.  Note ssdtools doesn’t currently support right censored data:","code":"example_dat <- ssddata::ccme_boron |>    dplyr::mutate(left=Conc, right=Conc)  left_censored_example <- example_dat  left_censored_example$left[c(3,6,8)] <- NA left_censored_dists <- ssd_fit_dists(left_censored_example,                                       dists = ssd_dists_bcanz(n = 2),                                      left = \"left\", right = \"right\") ssd_hc(left_censored_dists, average = FALSE) #> # A tibble: 5 × 11 #>   dist    proportion   est    se   lcl   ucl     wt method   nboot pboot samples #>   <chr>        <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl> <chr>    <int> <dbl> <I<lis> #> 1 gamma         0.05 0.674    NA    NA    NA 0.376  paramet…     0    NA <dbl>   #> 2 lgumbel       0.05 1.51     NA    NA    NA 0.0221 paramet…     0    NA <dbl>   #> 3 llogis        0.05 1.15     NA    NA    NA 0.0590 paramet…     0    NA <dbl>   #> 4 lnorm         0.05 1.32     NA    NA    NA 0.176  paramet…     0    NA <dbl>   #> 5 weibull       0.05 0.752    NA    NA    NA 0.367  paramet…     0    NA <dbl> ssd_hc(left_censored_dists) #> # A tibble: 1 × 11 #>   dist    proportion   est    se   lcl   ucl    wt method    nboot pboot samples #>   <chr>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>     <int> <dbl> <I<lis> #> 1 average       0.05 0.859    NA    NA    NA     1 parametr…     0   NaN <dbl> ssd_gof(left_censored_dists) #> # A tibble: 5 × 9 #>   dist       ad    ks   cvm   aic  aicc   bic delta weight #>   <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl> #> 1 gamma      NA    NA    NA  222.    NA    NA 0      0.376 #> 2 lgumbel    NA    NA    NA  228.    NA    NA 5.67   0.022 #> 3 llogis     NA    NA    NA  226.    NA    NA 3.70   0.059 #> 4 lnorm      NA    NA    NA  224.    NA    NA 1.52   0.176 #> 5 weibull    NA    NA    NA  222.    NA    NA 0.046  0.367 set.seed(99) left_censored_pred <- predict(left_censored_dists, ci = TRUE)  ssd_plot(left_censored_example, left_censored_pred,   left = \"left\", right = \"right\",   xlab = \"Concentration (mg/L)\" ) right_censored_example <- example_dat  right_censored_example$right[c(3,6,8)] <- NA right_censored_dists <- try(ssd_fit_dists(right_censored_example,                                            dists = ssd_dists_bcanz(n = 2),                                           left = \"left\", right = \"right\")) #> Error in eval(expr, envir, enclos) :  #>   Distributions cannot currently be fitted to right censored data."},{"path":[]},{"path":"/articles/ssdtools.html","id":"licensing","dir":"Articles","previous_headings":"","what":"Licensing","title":"Getting Started with ssdtools","text":"Copyright 2024 Province British Columbia, Environment Climate Change Canada, Australian Government Department Climate Change, Energy, Environment Water documentation released CC 4.0 License code released Apache License 2.0","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Joe Thorley. Author, maintainer. Rebecca Fisher. Author. David Fox. Author. Carl Schwarz. Author. Angeline Tillmanns. Contributor. Seb Dalgarno. Contributor. Kathleen McTavish. Contributor. Heather Thompson. Contributor. Doug Spry. Contributor. Rick van Dam. Contributor. Graham Batley. Contributor. Yulia Cuthbertson. Contributor. Tony Bigwood. Contributor. Michael Antenucci. Contributor. Ali Azizishirazi. Contributor. Nadine Hussein. Contributor. Sarah Lyons. Contributor. Stephanie Hazlitt. Contributor. Hadley Wickham. Contributor. Sergio Ibarra Espinosa. Contributor. Andy Teucher. Contributor. Emilie Doussantousse. Contributor. Nan-Hung Hsieh. Contributor. Province British Columbia. Funder, copyright holder. Environment Climate Change Canada. Funder, copyright holder. Australian Government Department Climate Change, Energy, Environment Water. Funder, copyright holder.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Thorley J, Fisher R, Fox D, Schwarz C (2024). ssdtools: Species Sensitivity Distributions. R package version 1.0.6.9015, https://bcgov.github.io/ssdtools/, https://github.com/bcgov/ssdtools.","code":"@Manual{,   title = {ssdtools: Species Sensitivity Distributions},   author = {Joe Thorley and Rebecca Fisher and David Fox and Carl Schwarz},   year = {2024},   note = {R package version 1.0.6.9015, https://bcgov.github.io/ssdtools/},   url = {https://github.com/bcgov/ssdtools}, }"},{"path":"/index.html","id":"ssdtools-","dir":"","previous_headings":"","what":"Species Sensitivity Distributions","title":"Species Sensitivity Distributions","text":"ssdtools R package fit plot Species Sensitivity Distributions (SSD). SSDs cumulative probability distributions fitted toxicity concentrations different species described Posthuma et al. (2001). ssdtools package uses Maximum Likelihood fit distributions log-normal, log-logistic, log-Gumbel (also known inverse Weibull), gamma, Weibull log-normal log-normal mixture. Multiple distributions can averaged using Akaike Information Criteria. Confidence intervals hazard concentrations proportions produced bootstrapping.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Species Sensitivity Distributions","text":"install latest version CRAN install latest development version GitHub","code":"install.packages(\"ssdtools\") # install.packages(\"remotes\") remotes::install_github(\"bcgov/ssdtools\")"},{"path":"/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Species Sensitivity Distributions","text":"dependency ssddata provides example data sets several chemicals including Boron. six default distributions fit using ssd_fit_dists() can quickly plotted using autoplot  goodness fit can assessed using ssd_gof model-averaged 5% hazard concentration estimated bootstrapping using ssd_hc. bootstrap parallel set future::plan(). example: Model-averaged predictions complete confidence intervals can also estimated parametric bootstrapping using stats generic predict. perform bootstrapping distribution parallel register future backend select evaluation strategy. predictions can plotted together original data using ssd_plot.","code":"library(ssdtools) ssddata::ccme_boron #> # A tibble: 28 × 5 #>    Chemical Species                  Conc Group        Units #>    <chr>    <chr>                   <dbl> <fct>        <chr> #>  1 Boron    Oncorhynchus mykiss       2.1 Fish         mg/L  #>  2 Boron    Ictalurus punctatus       2.4 Fish         mg/L  #>  3 Boron    Micropterus salmoides     4.1 Fish         mg/L  #>  4 Boron    Brachydanio rerio        10   Fish         mg/L  #>  5 Boron    Carassius auratus        15.6 Fish         mg/L  #>  6 Boron    Pimephales promelas      18.3 Fish         mg/L  #>  7 Boron    Daphnia magna             6   Invertebrate mg/L  #>  8 Boron    Opercularia bimarginata  10   Invertebrate mg/L  #>  9 Boron    Ceriodaphnia dubia       13.4 Invertebrate mg/L  #> 10 Boron    Entosiphon sulcatum      15   Invertebrate mg/L  #> # ℹ 18 more rows fits <- ssd_fit_dists(ssddata::ccme_boron) autoplot(fits) ssd_gof(fits) #> # A tibble: 6 × 9 #>   dist           ad     ks    cvm   aic  aicc   bic delta weight #>   <chr>       <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl> #> 1 gamma       0.440 0.117  0.0554  238.  238.  240. 0.005  0.357 #> 2 lgumbel     0.829 0.158  0.134   244.  245.  247. 6.56   0.013 #> 3 llogis      0.487 0.0994 0.0595  241.  241.  244. 3.39   0.066 #> 4 lnorm       0.507 0.107  0.0703  239.  240.  242. 1.40   0.177 #> 5 lnorm_lnorm 0.320 0.116  0.0414  240.  243.  247. 4.98   0.03  #> 6 weibull     0.434 0.117  0.0542  238.  238.  240. 0      0.357 set.seed(99) hc5 <- ssd_hc(fits, ci = TRUE) print(hc5) #> # A tibble: 1 × 11 #>   dist    proportion   est    se   lcl   ucl    wt method    nboot pboot samples #>   <chr>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>     <dbl> <dbl> <I<lis> #> 1 average       0.05  1.26 0.781 0.407  3.29     1 parametr…  1000 0.999 <dbl> future::multisession(workers = 2) hc5 <- ssd_hc(fits, ci = TRUE) doFuture::registerDoFuture() future::plan(future::multisession)  set.seed(99) boron_pred <- predict(fits, ci = TRUE) library(ggplot2)  theme_set(theme_bw())  ssd_plot(ssddata::ccme_boron, boron_pred,   shape = \"Group\", color = \"Group\", label = \"Species\",   xlab = \"Concentration (mg/L)\", ribbon = TRUE ) +   expand_limits(x = 3000) +   scale_colour_ssd()"},{"path":"/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Species Sensitivity Distributions","text":"Posthuma, L., Suter II, G.W., Traas, T.P. 2001. Species Sensitivity Distributions Ecotoxicology. CRC Press.","code":""},{"path":"/index.html","id":"information","dir":"","previous_headings":"","what":"Information","title":"Species Sensitivity Distributions","text":"Get started ssdtools https://bcgov.github.io/ssdtools/articles/ssdtools.html. shiny app allow non-R users interface ssdtools available https://github.com/bcgov/shinyssdtools. latest changes visit NEWS. citation shiny app: Dalgarno, S. 2021. shinyssdtools: web application fitting Species Sensitivity Distributions (SSDs). JOSS 6(57): 2848. https://joss.theoj.org/papers/10.21105/joss.02848. ssdtools package developed result earlier drafts : Schwarz, C., Tillmanns, . 2019. Improving Statistical Methods Modeling Species Sensitivity Distributions. Province British Columbia, Victoria, BC. recent developments SSD modeling including review existing software see: Fox, D.R., et al. 2021. Recent Developments Species Sensitivity Distribution Modeling. Environ Toxicol Chem 40(2): 293–308. https://doi.org/10.1002/etc.4925. CCME data.csv data file derived factsheet prepared Canadian Council Ministers Environment. See data-raw folder information.","code":""},{"path":"/index.html","id":"getting-help-or-reporting-an-issue","dir":"","previous_headings":"","what":"Getting Help or Reporting an Issue","title":"Species Sensitivity Distributions","text":"report bugs/issues/feature requests, please file issue.","code":""},{"path":"/index.html","id":"how-to-contribute","dir":"","previous_headings":"","what":"How to Contribute","title":"Species Sensitivity Distributions","text":"like contribute package, please see CONTRIBUTING guidelines.","code":""},{"path":"/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Species Sensitivity Distributions","text":"Please note ssdtools project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"/index.html","id":"licensing","dir":"","previous_headings":"","what":"Licensing","title":"Species Sensitivity Distributions","text":"Copyright 2024 Province British Columbia, Environment Climate Change Canada, Australian Government Department Climate Change, Energy, Environment Water documentation released CC 4.0 License code released Apache License 2.0","code":""},{"path":"/reference/augment.fitdists.html","id":null,"dir":"Reference","previous_headings":"","what":"Augmented Data from fitdists Object — augment.fitdists","title":"Augmented Data from fitdists Object — augment.fitdists","text":"Get tibble original data augmentation.","code":""},{"path":"/reference/augment.fitdists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Augmented Data from fitdists Object — augment.fitdists","text":"","code":"# S3 method for fitdists augment(x, ...)"},{"path":"/reference/augment.fitdists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augmented Data from fitdists Object — augment.fitdists","text":"x object. ... Unused.","code":""},{"path":"/reference/augment.fitdists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augmented Data from fitdists Object — augment.fitdists","text":"tibble agumented data.","code":""},{"path":[]},{"path":"/reference/augment.fitdists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Augmented Data from fitdists Object — augment.fitdists","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) augment(fits) #> # A tibble: 28 × 5 #>    Chemical Species                  Conc Group        Units #>    <chr>    <chr>                   <dbl> <fct>        <chr> #>  1 Boron    Oncorhynchus mykiss       2.1 Fish         mg/L  #>  2 Boron    Ictalurus punctatus       2.4 Fish         mg/L  #>  3 Boron    Micropterus salmoides     4.1 Fish         mg/L  #>  4 Boron    Brachydanio rerio        10   Fish         mg/L  #>  5 Boron    Carassius auratus        15.6 Fish         mg/L  #>  6 Boron    Pimephales promelas      18.3 Fish         mg/L  #>  7 Boron    Daphnia magna             6   Invertebrate mg/L  #>  8 Boron    Opercularia bimarginata  10   Invertebrate mg/L  #>  9 Boron    Ceriodaphnia dubia       13.4 Invertebrate mg/L  #> 10 Boron    Entosiphon sulcatum      15   Invertebrate mg/L  #> # ℹ 18 more rows"},{"path":"/reference/autoplot.fitdists.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a fitdists Object — autoplot.fitdists","title":"Plot a fitdists Object — autoplot.fitdists","text":"wrapper ssd_plot_cdf().","code":""},{"path":"/reference/autoplot.fitdists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a fitdists Object — autoplot.fitdists","text":"","code":"# S3 method for fitdists autoplot(object, ...)"},{"path":"/reference/autoplot.fitdists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a fitdists Object — autoplot.fitdists","text":"object object. ... Unused.","code":""},{"path":"/reference/autoplot.fitdists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a fitdists Object — autoplot.fitdists","text":"ggplot object.","code":""},{"path":[]},{"path":"/reference/autoplot.fitdists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a fitdists Object — autoplot.fitdists","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) autoplot(fits)"},{"path":"/reference/boron_pred.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Averaged Predictions for CCME Boron Data — boron_pred","title":"Model Averaged Predictions for CCME Boron Data — boron_pred","text":"data frame predictions based 1,000 bootstrap iterations.","code":""},{"path":"/reference/boron_pred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Averaged Predictions for CCME Boron Data — boron_pred","text":"","code":"boron_pred"},{"path":"/reference/boron_pred.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Model Averaged Predictions for CCME Boron Data — boron_pred","text":"object class tbl_df (inherits tbl, data.frame) 99 rows 11 columns.","code":""},{"path":"/reference/boron_pred.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model Averaged Predictions for CCME Boron Data — boron_pred","text":"proportion proportion species affected (int). est estimated concentration (dbl). se standard error estimate (dbl). lcl lower confidence limit (dbl). se upper confidence limit (dbl). dist distribution (chr).","code":""},{"path":"/reference/boron_pred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model Averaged Predictions for CCME Boron Data — boron_pred","text":"","code":"head(boron_pred) #> # A tibble: 6 × 11 #>   dist    proportion   est    se    lcl   ucl    wt method   nboot pboot samples #>   <chr>        <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <chr>    <dbl> <dbl> <I<lis> #> 1 average       0.01 0.267 0.401 0.0418  1.53     1 paramet…  1000 0.999 <dbl>   #> 2 average       0.02 0.531 0.517 0.110   2.03     1 paramet…  1000 0.999 <dbl>   #> 3 average       0.03 0.783 0.614 0.198   2.50     1 paramet…  1000 0.999 <dbl>   #> 4 average       0.04 1.02  0.700 0.300   2.90     1 paramet…  1000 0.999 <dbl>   #> 5 average       0.05 1.26  0.781 0.407   3.29     1 paramet…  1000 0.999 <dbl>   #> 6 average       0.06 1.48  0.859 0.520   3.72     1 paramet…  1000 0.999 <dbl>"},{"path":"/reference/coef.fitdists.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn a fitdists Object into a Tidy Tibble — coef.fitdists","title":"Turn a fitdists Object into a Tidy Tibble — coef.fitdists","text":"wrapper tidy.fitdists().","code":""},{"path":"/reference/coef.fitdists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn a fitdists Object into a Tidy Tibble — coef.fitdists","text":"","code":"# S3 method for fitdists coef(object, ...)"},{"path":"/reference/coef.fitdists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn a fitdists Object into a Tidy Tibble — coef.fitdists","text":"object object. ... Unused.","code":""},{"path":[]},{"path":"/reference/coef.fitdists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Turn a fitdists Object into a Tidy Tibble — coef.fitdists","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) coef(fits) #> # A tibble: 15 × 4 #>    dist        term           est    se #>    <chr>       <chr>        <dbl> <dbl> #>  1 gamma       scale       25.1   7.64  #>  2 gamma       shape        0.950 0.223 #>  3 lgumbel     locationlog  1.92  0.247 #>  4 lgumbel     scalelog     1.23  0.173 #>  5 llogis      locationlog  2.63  0.248 #>  6 llogis      scalelog     0.740 0.114 #>  7 lnorm       meanlog      2.56  0.235 #>  8 lnorm       sdlog        1.24  0.166 #>  9 lnorm_lnorm meanlog1     0.949 0.318 #> 10 lnorm_lnorm meanlog2     3.20  0.253 #> 11 lnorm_lnorm pmix         0.284 0.123 #> 12 lnorm_lnorm sdlog1       0.555 0.212 #> 13 lnorm_lnorm sdlog2       0.769 0.194 #> 14 weibull     scale       23.5   4.86  #> 15 weibull     shape        0.966 0.145"},{"path":"/reference/comma_signif.html","id":null,"dir":"Reference","previous_headings":"","what":"Comma and Significance Formatter — comma_signif","title":"Comma and Significance Formatter — comma_signif","text":"default numeric vectors first rounded three significant figures. scales::comma applied values greater equal 1000 ensure labels permitted different numbers decimal places.","code":""},{"path":"/reference/comma_signif.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Comma and Significance Formatter — comma_signif","text":"","code":"comma_signif(x, digits = 3, ...)"},{"path":"/reference/comma_signif.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Comma and Significance Formatter — comma_signif","text":"x numeric vector format. digits whole number specifying number significant figures. ... Additional arguments passed scales::comma.","code":""},{"path":"/reference/comma_signif.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Comma and Significance Formatter — comma_signif","text":"character vector.","code":""},{"path":"/reference/comma_signif.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Comma and Significance Formatter — comma_signif","text":"","code":"comma_signif(c(0.1, 1, 10, 1000)) #> [1] \"0.1\"   \"1\"     \"10\"    \"1,000\" scales::comma(c(0.1, 1, 10, 1000)) #> [1] \"0.1\"     \"1.0\"     \"10.0\"    \"1,000.0\""},{"path":"/reference/dgompertz.html","id":null,"dir":"Reference","previous_headings":"","what":"Gompertz Probability Density  — dgompertz","title":"Gompertz Probability Density  — dgompertz","text":"Gompertz Probability Density","code":""},{"path":"/reference/dgompertz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gompertz Probability Density  — dgompertz","text":"","code":"dgompertz(x, llocation = 0, lshape = 0, log = FALSE)"},{"path":"/reference/dgompertz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gompertz Probability Density  — dgompertz","text":"x numeric vector values. llocation location parameter log scale. lshape shape parameter log scale. log logical; TRUE, probabilities p given log(p).","code":""},{"path":"/reference/dgompertz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gompertz Probability Density  — dgompertz","text":"numeric vector.","code":""},{"path":"/reference/dist_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Distribution Data — dist_data","title":"Distribution Data — dist_data","text":"data frame information implemented distributions.","code":""},{"path":"/reference/dist_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distribution Data — dist_data","text":"","code":"dist_data"},{"path":"/reference/dist_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Distribution Data — dist_data","text":"object class tbl_df (inherits tbl, data.frame) 10 rows 4 columns.","code":""},{"path":"/reference/dist_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Distribution Data — dist_data","text":"dist distribution (chr). npars number parameters (int). tails Whether distribution tails (flag). stable Whether distribution numerically stable (flag). bcanz Whether distribution belongs set distributions approved BC, Canada, Australia New Zealand official guidelines (flag).","code":""},{"path":[]},{"path":"/reference/dist_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Distribution Data — dist_data","text":"","code":"dist #> function (x, method = \"euclidean\", diag = FALSE, upper = FALSE,  #>     p = 2)  #> { #>     if (!is.na(pmatch(method, \"euclidian\")))  #>         method <- \"euclidean\" #>     METHODS <- c(\"euclidean\", \"maximum\", \"manhattan\", \"canberra\",  #>         \"binary\", \"minkowski\") #>     method <- pmatch(method, METHODS) #>     if (is.na(method))  #>         stop(\"invalid distance method\") #>     if (method == -1)  #>         stop(\"ambiguous distance method\") #>     x <- as.matrix(x) #>     N <- nrow(x) #>     attrs <- if (method == 6L)  #>         list(Size = N, Labels = dimnames(x)[[1L]], Diag = diag,  #>             Upper = upper, method = METHODS[method], p = p, call = match.call(),  #>             class = \"dist\") #>     else list(Size = N, Labels = dimnames(x)[[1L]], Diag = diag,  #>         Upper = upper, method = METHODS[method], call = match.call(),  #>         class = \"dist\") #>     .Call(C_Cdist, x, method, attrs, p) #> } #> <bytecode: 0x55952391b698> #> <environment: namespace:stats>"},{"path":"/reference/dlgumbel.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-Gumbel (Inverse Weibull) Probability Density  — dlgumbel","title":"Log-Gumbel (Inverse Weibull) Probability Density  — dlgumbel","text":"Log-Gumbel (Inverse Weibull) Probability Density","code":""},{"path":"/reference/dlgumbel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-Gumbel (Inverse Weibull) Probability Density  — dlgumbel","text":"","code":"dlgumbel(x, locationlog = 0, scalelog = 1, log = FALSE)"},{"path":"/reference/dlgumbel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-Gumbel (Inverse Weibull) Probability Density  — dlgumbel","text":"x numeric vector values. locationlog location log scale parameter. scalelog scale log scale parameter. log logical; TRUE, probabilities p given log(p).","code":""},{"path":"/reference/dlgumbel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-Gumbel (Inverse Weibull) Probability Density  — dlgumbel","text":"numeric vector.","code":""},{"path":"/reference/estimates.fitdists.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimates for fitdists Object — estimates.fitdists","title":"Estimates for fitdists Object — estimates.fitdists","text":"Gets named list estimated weights parameters.","code":""},{"path":"/reference/estimates.fitdists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimates for fitdists Object — estimates.fitdists","text":"","code":"# S3 method for fitdists estimates(x, all_estimates = FALSE, ...)"},{"path":"/reference/estimates.fitdists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimates for fitdists Object — estimates.fitdists","text":"x object. all_estimates flag specifying whether calculate estimates implemented distributions. ... Unused.","code":""},{"path":"/reference/estimates.fitdists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimates for fitdists Object — estimates.fitdists","text":"named list estimates.","code":""},{"path":[]},{"path":"/reference/estimates.fitdists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimates for fitdists Object — estimates.fitdists","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) estimates(fits) #> $gamma.weight #> [1] 0.3565737 #>  #> $gamma.scale #> [1] 25.12683 #>  #> $gamma.shape #> [1] 0.9501795 #>  #> $lgumbel.weight #> [1] 0.01344657 #>  #> $lgumbel.locationlog #> [1] 1.922631 #>  #> $lgumbel.scalelog #> [1] 1.232239 #>  #> $llogis.weight #> [1] 0.06564519 #>  #> $llogis.locationlog #> [1] 2.626276 #>  #> $llogis.scalelog #> [1] 0.7404264 #>  #> $lnorm.weight #> [1] 0.1772362 #>  #> $lnorm.meanlog #> [1] 2.561645 #>  #> $lnorm.sdlog #> [1] 1.241539 #>  #> $lnorm_lnorm.weight #> [1] 0.02962678 #>  #> $lnorm_lnorm.meanlog1 #> [1] 0.9494874 #>  #> $lnorm_lnorm.meanlog2 #> [1] 3.201082 #>  #> $lnorm_lnorm.pmix #> [1] 0.2839941 #>  #> $lnorm_lnorm.sdlog1 #> [1] 0.5545143 #>  #> $lnorm_lnorm.sdlog2 #> [1] 0.7688237 #>  #> $weibull.weight #> [1] 0.3574716 #>  #> $weibull.scale #> [1] 23.51397 #>  #> $weibull.shape #> [1] 0.9660997 #>"},{"path":"/reference/geom_hcintersect.html","id":null,"dir":"Reference","previous_headings":"","what":"Species Sensitivity Hazard Concentration Intersection — geom_hcintersect","title":"Species Sensitivity Hazard Concentration Intersection — geom_hcintersect","text":"Plots intersection xintercept yintercept value.","code":""},{"path":"/reference/geom_hcintersect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Species Sensitivity Hazard Concentration Intersection — geom_hcintersect","text":"","code":"geom_hcintersect(   mapping = NULL,   data = NULL,   ...,   xintercept,   yintercept,   na.rm = FALSE,   show.legend = NA )"},{"path":"/reference/geom_hcintersect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Species Sensitivity Hazard Concentration Intersection — geom_hcintersect","text":"mapping Set aesthetic mappings created aes(). specified inherit.aes = TRUE (default), combined default mapping top level plot. must supply mapping plot mapping. data data displayed layer. three options: NULL, default, data inherited plot data specified call ggplot(). data.frame, object, override plot data. objects fortified produce data frame. See fortify() variables created. function called single argument, plot data. return value must data.frame, used layer data. function can created formula (e.g. ~ head(.x, 10)). ... arguments passed layer()'s params argument. arguments broadly fall one 4 categories . Notably, arguments position argument, aesthetics required can passed .... Unknown arguments part 4 categories ignored. Static aesthetics mapped scale, fixed value apply layer whole. example, colour = \"red\" linewidth = 3. geom's documentation Aesthetics section lists available options. 'required' aesthetics passed params. Please note passing unmapped aesthetics vectors technically possible, order required length guaranteed parallel input data. constructing layer using stat_*() function, ... argument can used pass parameters geom part layer. example stat_density(geom = \"area\", outline.type = \"\"). geom's documentation lists parameters can accept. Inversely, constructing layer using geom_*() function, ... argument can used pass parameters stat part layer. example geom_area(stat = \"density\", adjust = 0.5). stat's documentation lists parameters can accept. key_glyph argument layer() may also passed .... can one functions described key glyphs, change display layer legend. xintercept x-value intersect yintercept y-value intersect. na.rm FALSE, default, missing values removed warning. TRUE, missing values silently removed. show.legend logical. layer included legends? NA, default, includes aesthetics mapped. FALSE never includes, TRUE always includes. can also named logical vector finely select aesthetics display.","code":""},{"path":[]},{"path":"/reference/geom_hcintersect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Species Sensitivity Hazard Concentration Intersection — geom_hcintersect","text":"","code":"ggplot2::ggplot(ssddata::ccme_boron, ggplot2::aes(x = Conc)) +   geom_ssdpoint() +   geom_hcintersect(xintercept = 1.5, yintercept = 0.05)"},{"path":"/reference/geom_ssd.html","id":null,"dir":"Reference","previous_headings":"","what":"Species Sensitivity Data Points  — geom_ssd","title":"Species Sensitivity Data Points  — geom_ssd","text":"geom_ssd() deprecated geom_ssdpoint().","code":""},{"path":"/reference/geom_ssd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Species Sensitivity Data Points  — geom_ssd","text":"","code":"geom_ssd(   mapping = NULL,   data = NULL,   stat = \"ssdpoint\",   position = \"identity\",   ...,   na.rm = FALSE,   show.legend = NA,   inherit.aes = TRUE )"},{"path":"/reference/geom_ssd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Species Sensitivity Data Points  — geom_ssd","text":"mapping Set aesthetic mappings created aes(). specified inherit.aes = TRUE (default), combined default mapping top level plot. must supply mapping plot mapping. data data displayed layer. three options: NULL, default, data inherited plot data specified call ggplot(). data.frame, object, override plot data. objects fortified produce data frame. See fortify() variables created. function called single argument, plot data. return value must data.frame, used layer data. function can created formula (e.g. ~ head(.x, 10)). stat statistical transformation use data layer. using geom_*() function construct layer, stat argument can used override default coupling geoms stats. stat argument accepts following: Stat ggproto subclass, example StatCount. string naming stat. give stat string, strip function name stat_ prefix. example, use stat_count(), give stat \"count\". information ways specify stat, see layer stat documentation. position position adjustment use data layer. can used various ways, including prevent overplotting improving display. position argument accepts following: result calling position function, position_jitter(). method allows passing extra arguments position. string naming position adjustment. give position string, strip function name position_ prefix. example, use position_jitter(), give position \"jitter\". information ways specify position, see layer position documentation. ... arguments passed layer()'s params argument. arguments broadly fall one 4 categories . Notably, arguments position argument, aesthetics required can passed .... Unknown arguments part 4 categories ignored. Static aesthetics mapped scale, fixed value apply layer whole. example, colour = \"red\" linewidth = 3. geom's documentation Aesthetics section lists available options. 'required' aesthetics passed params. Please note passing unmapped aesthetics vectors technically possible, order required length guaranteed parallel input data. constructing layer using stat_*() function, ... argument can used pass parameters geom part layer. example stat_density(geom = \"area\", outline.type = \"\"). geom's documentation lists parameters can accept. Inversely, constructing layer using geom_*() function, ... argument can used pass parameters stat part layer. example geom_area(stat = \"density\", adjust = 0.5). stat's documentation lists parameters can accept. key_glyph argument layer() may also passed .... can one functions described key glyphs, change display layer legend. na.rm FALSE, default, missing values removed warning. TRUE, missing values silently removed. show.legend logical. layer included legends? NA, default, includes aesthetics mapped. FALSE never includes, TRUE always includes. can also named logical vector finely select aesthetics display. inherit.aes FALSE, overrides default aesthetics, rather combining . useful helper functions define data aesthetics inherit behaviour default plot specification, e.g. borders().","code":""},{"path":"/reference/geom_ssd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Species Sensitivity Data Points  — geom_ssd","text":"","code":"if (FALSE) { ggplot2::ggplot(ssddata::ccme_boron, ggplot2::aes(x = Conc)) +   geom_ssd() }"},{"path":"/reference/geom_ssdpoint.html","id":null,"dir":"Reference","previous_headings":"","what":"Species Sensitivity Data Points — geom_ssdpoint","title":"Species Sensitivity Data Points — geom_ssdpoint","text":"Uses empirical cumulative distribution create scatterplot points x.","code":""},{"path":"/reference/geom_ssdpoint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Species Sensitivity Data Points — geom_ssdpoint","text":"","code":"geom_ssdpoint(   mapping = NULL,   data = NULL,   stat = \"ssdpoint\",   position = \"identity\",   ...,   na.rm = FALSE,   show.legend = NA,   inherit.aes = TRUE )"},{"path":"/reference/geom_ssdpoint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Species Sensitivity Data Points — geom_ssdpoint","text":"mapping Set aesthetic mappings created aes(). specified inherit.aes = TRUE (default), combined default mapping top level plot. must supply mapping plot mapping. data data displayed layer. three options: NULL, default, data inherited plot data specified call ggplot(). data.frame, object, override plot data. objects fortified produce data frame. See fortify() variables created. function called single argument, plot data. return value must data.frame, used layer data. function can created formula (e.g. ~ head(.x, 10)). stat statistical transformation use data layer. using geom_*() function construct layer, stat argument can used override default coupling geoms stats. stat argument accepts following: Stat ggproto subclass, example StatCount. string naming stat. give stat string, strip function name stat_ prefix. example, use stat_count(), give stat \"count\". information ways specify stat, see layer stat documentation. position position adjustment use data layer. can used various ways, including prevent overplotting improving display. position argument accepts following: result calling position function, position_jitter(). method allows passing extra arguments position. string naming position adjustment. give position string, strip function name position_ prefix. example, use position_jitter(), give position \"jitter\". information ways specify position, see layer position documentation. ... arguments passed layer()'s params argument. arguments broadly fall one 4 categories . Notably, arguments position argument, aesthetics required can passed .... Unknown arguments part 4 categories ignored. Static aesthetics mapped scale, fixed value apply layer whole. example, colour = \"red\" linewidth = 3. geom's documentation Aesthetics section lists available options. 'required' aesthetics passed params. Please note passing unmapped aesthetics vectors technically possible, order required length guaranteed parallel input data. constructing layer using stat_*() function, ... argument can used pass parameters geom part layer. example stat_density(geom = \"area\", outline.type = \"\"). geom's documentation lists parameters can accept. Inversely, constructing layer using geom_*() function, ... argument can used pass parameters stat part layer. example geom_area(stat = \"density\", adjust = 0.5). stat's documentation lists parameters can accept. key_glyph argument layer() may also passed .... can one functions described key glyphs, change display layer legend. na.rm FALSE, default, missing values removed warning. TRUE, missing values silently removed. show.legend logical. layer included legends? NA, default, includes aesthetics mapped. FALSE never includes, TRUE always includes. can also named logical vector finely select aesthetics display. inherit.aes FALSE, overrides default aesthetics, rather combining . useful helper functions define data aesthetics inherit behaviour default plot specification, e.g. borders().","code":""},{"path":[]},{"path":"/reference/geom_ssdpoint.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Species Sensitivity Data Points — geom_ssdpoint","text":"","code":"ggplot2::ggplot(ssddata::ccme_boron, ggplot2::aes(x = Conc)) +   geom_ssdpoint()"},{"path":"/reference/geom_ssdsegment.html","id":null,"dir":"Reference","previous_headings":"","what":"Species Sensitivity Censored Segments — geom_ssdsegment","title":"Species Sensitivity Censored Segments — geom_ssdsegment","text":"Uses empirical cumulative distribution draw lines points x xend.","code":""},{"path":"/reference/geom_ssdsegment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Species Sensitivity Censored Segments — geom_ssdsegment","text":"","code":"geom_ssdsegment(   mapping = NULL,   data = NULL,   stat = \"ssdsegment\",   position = \"identity\",   ...,   arrow = NULL,   arrow.fill = NULL,   lineend = \"butt\",   linejoin = \"round\",   na.rm = FALSE,   show.legend = NA,   inherit.aes = TRUE )"},{"path":"/reference/geom_ssdsegment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Species Sensitivity Censored Segments — geom_ssdsegment","text":"mapping Set aesthetic mappings created aes(). specified inherit.aes = TRUE (default), combined default mapping top level plot. must supply mapping plot mapping. data data displayed layer. three options: NULL, default, data inherited plot data specified call ggplot(). data.frame, object, override plot data. objects fortified produce data frame. See fortify() variables created. function called single argument, plot data. return value must data.frame, used layer data. function can created formula (e.g. ~ head(.x, 10)). stat statistical transformation use data layer. using geom_*() function construct layer, stat argument can used override default coupling geoms stats. stat argument accepts following: Stat ggproto subclass, example StatCount. string naming stat. give stat string, strip function name stat_ prefix. example, use stat_count(), give stat \"count\". information ways specify stat, see layer stat documentation. position position adjustment use data layer. can used various ways, including prevent overplotting improving display. position argument accepts following: result calling position function, position_jitter(). method allows passing extra arguments position. string naming position adjustment. give position string, strip function name position_ prefix. example, use position_jitter(), give position \"jitter\". information ways specify position, see layer position documentation. ... arguments passed layer()'s params argument. arguments broadly fall one 4 categories . Notably, arguments position argument, aesthetics required can passed .... Unknown arguments part 4 categories ignored. Static aesthetics mapped scale, fixed value apply layer whole. example, colour = \"red\" linewidth = 3. geom's documentation Aesthetics section lists available options. 'required' aesthetics passed params. Please note passing unmapped aesthetics vectors technically possible, order required length guaranteed parallel input data. constructing layer using stat_*() function, ... argument can used pass parameters geom part layer. example stat_density(geom = \"area\", outline.type = \"\"). geom's documentation lists parameters can accept. Inversely, constructing layer using geom_*() function, ... argument can used pass parameters stat part layer. example geom_area(stat = \"density\", adjust = 0.5). stat's documentation lists parameters can accept. key_glyph argument layer() may also passed .... can one functions described key glyphs, change display layer legend. arrow specification arrow heads, created grid::arrow(). arrow.fill fill colour use arrow head (closed). NULL means use colour aesthetic. lineend Line end style (round, butt, square). linejoin Line join style (round, mitre, bevel). na.rm FALSE, default, missing values removed warning. TRUE, missing values silently removed. show.legend logical. layer included legends? NA, default, includes aesthetics mapped. FALSE never includes, TRUE always includes. can also named logical vector finely select aesthetics display. inherit.aes FALSE, overrides default aesthetics, rather combining . useful helper functions define data aesthetics inherit behaviour default plot specification, e.g. borders().","code":""},{"path":[]},{"path":"/reference/geom_ssdsegment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Species Sensitivity Censored Segments — geom_ssdsegment","text":"","code":"ggplot2::ggplot(ssddata::ccme_boron, ggplot2::aes(x = Conc, xend = Conc * 2)) +   geom_ssdsegment()"},{"path":"/reference/geom_xribbon.html","id":null,"dir":"Reference","previous_headings":"","what":"Ribbon on X-Axis — geom_xribbon","title":"Ribbon on X-Axis — geom_xribbon","text":"Plots x interval defined xmin xmax.","code":""},{"path":"/reference/geom_xribbon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ribbon on X-Axis — geom_xribbon","text":"","code":"geom_xribbon(   mapping = NULL,   data = NULL,   stat = \"identity\",   position = \"identity\",   ...,   na.rm = FALSE,   show.legend = NA,   inherit.aes = TRUE )"},{"path":"/reference/geom_xribbon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ribbon on X-Axis — geom_xribbon","text":"mapping Set aesthetic mappings created aes(). specified inherit.aes = TRUE (default), combined default mapping top level plot. must supply mapping plot mapping. data data displayed layer. three options: NULL, default, data inherited plot data specified call ggplot(). data.frame, object, override plot data. objects fortified produce data frame. See fortify() variables created. function called single argument, plot data. return value must data.frame, used layer data. function can created formula (e.g. ~ head(.x, 10)). stat statistical transformation use data layer. using geom_*() function construct layer, stat argument can used override default coupling geoms stats. stat argument accepts following: Stat ggproto subclass, example StatCount. string naming stat. give stat string, strip function name stat_ prefix. example, use stat_count(), give stat \"count\". information ways specify stat, see layer stat documentation. position position adjustment use data layer. can used various ways, including prevent overplotting improving display. position argument accepts following: result calling position function, position_jitter(). method allows passing extra arguments position. string naming position adjustment. give position string, strip function name position_ prefix. example, use position_jitter(), give position \"jitter\". information ways specify position, see layer position documentation. ... arguments passed layer()'s params argument. arguments broadly fall one 4 categories . Notably, arguments position argument, aesthetics required can passed .... Unknown arguments part 4 categories ignored. Static aesthetics mapped scale, fixed value apply layer whole. example, colour = \"red\" linewidth = 3. geom's documentation Aesthetics section lists available options. 'required' aesthetics passed params. Please note passing unmapped aesthetics vectors technically possible, order required length guaranteed parallel input data. constructing layer using stat_*() function, ... argument can used pass parameters geom part layer. example stat_density(geom = \"area\", outline.type = \"\"). geom's documentation lists parameters can accept. Inversely, constructing layer using geom_*() function, ... argument can used pass parameters stat part layer. example geom_area(stat = \"density\", adjust = 0.5). stat's documentation lists parameters can accept. key_glyph argument layer() may also passed .... can one functions described key glyphs, change display layer legend. na.rm FALSE, default, missing values removed warning. TRUE, missing values silently removed. show.legend logical. layer included legends? NA, default, includes aesthetics mapped. FALSE never includes, TRUE always includes. can also named logical vector finely select aesthetics display. inherit.aes FALSE, overrides default aesthetics, rather combining . useful helper functions define data aesthetics inherit behaviour default plot specification, e.g. borders().","code":""},{"path":[]},{"path":"/reference/geom_xribbon.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ribbon on X-Axis — geom_xribbon","text":"","code":"gp <- ggplot2::ggplot(boron_pred) +   geom_xribbon(ggplot2::aes(xmin = lcl, xmax = ucl, y = proportion))"},{"path":"/reference/glance.fitdists.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a tibble summarizing each distribution — glance.fitdists","title":"Get a tibble summarizing each distribution — glance.fitdists","text":"Gets tibble single row distribution.","code":""},{"path":"/reference/glance.fitdists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a tibble summarizing each distribution — glance.fitdists","text":"","code":"# S3 method for fitdists glance(x, ...)"},{"path":"/reference/glance.fitdists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a tibble summarizing each distribution — glance.fitdists","text":"x object. ... Unused.","code":""},{"path":"/reference/glance.fitdists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a tibble summarizing each distribution — glance.fitdists","text":"tidy tibble distributions.","code":""},{"path":[]},{"path":"/reference/glance.fitdists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a tibble summarizing each distribution — glance.fitdists","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) glance(fits) #> # A tibble: 6 × 8 #>   dist        npars  nobs log_lik   aic  aicc   delta weight #>   <chr>       <int> <int>   <dbl> <dbl> <dbl>   <dbl>  <dbl> #> 1 gamma           2    28   -117.  238.  238. 0.00503 0.357  #> 2 lgumbel         2    28   -120.  244.  245. 6.56    0.0134 #> 3 llogis          2    28   -119.  241.  241. 3.39    0.0656 #> 4 lnorm           2    28   -118.  239.  240. 1.40    0.177  #> 5 lnorm_lnorm     5    28   -115.  240.  243. 4.98    0.0296 #> 6 weibull         2    28   -117.  238.  238. 0       0.357"},{"path":"/reference/is.fitdists.html","id":null,"dir":"Reference","previous_headings":"","what":"Is fitdists Object — is.fitdists","title":"Is fitdists Object — is.fitdists","text":"Tests whether x fitdists Object.","code":""},{"path":"/reference/is.fitdists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is fitdists Object — is.fitdists","text":"","code":"is.fitdists(x)"},{"path":"/reference/is.fitdists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Is fitdists Object — is.fitdists","text":"x object.","code":""},{"path":"/reference/is.fitdists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Is fitdists Object — is.fitdists","text":"flag specifying whether x fitdists Object.","code":""},{"path":"/reference/is.fitdists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Is fitdists Object — is.fitdists","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) is.fitdists(fits) #> [1] TRUE"},{"path":"/reference/is_censored.html","id":null,"dir":"Reference","previous_headings":"","what":"Is Censored  — is_censored","title":"Is Censored  — is_censored","text":"Deprecated ssd_is_censored().","code":""},{"path":"/reference/is_censored.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is Censored  — is_censored","text":"","code":"is_censored(x)"},{"path":"/reference/is_censored.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Is Censored  — is_censored","text":"x fitdists object.","code":""},{"path":"/reference/is_censored.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Is Censored  — is_censored","text":"flag indicating data censored.","code":""},{"path":[]},{"path":"/reference/is_censored.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Is Censored  — is_censored","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) is_censored(fits) #> Warning: `is_censored()` was deprecated in ssdtools 0.3.7. #> ℹ Please use `ssd_is_censored()` instead. #> [1] FALSE"},{"path":"/reference/licensing_md.html","id":null,"dir":"Reference","previous_headings":"","what":"Licensing Markdown — licensing_md","title":"Licensing Markdown — licensing_md","text":"string markdown code indicating licensing code documentation","code":""},{"path":"/reference/licensing_md.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Licensing Markdown — licensing_md","text":"","code":"licensing_md()"},{"path":"/reference/licensing_md.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Licensing Markdown — licensing_md","text":"","code":"licensing_md() #> [1] \"## Licensing\\n  \\n  Copyright 2024 Province of British Columbia,\\n   Environment and Climate Change Canada, and \\n   Australian Government Department of \\n   Climate Change, Energy, the Environment and Water\\n  \\n  The documentation is released under the\\n  [CC BY 4.0 License](https://creativecommons.org/licenses/by/4.0/)\\n  \\n  The code is released under the\\n  [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0)\\n\""},{"path":"/reference/params.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter Descriptions for ssdtools Functions — params","title":"Parameter Descriptions for ssdtools Functions — params","text":"Parameter Descriptions ssdtools Functions","code":""},{"path":"/reference/params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter Descriptions for ssdtools Functions — params","text":"add_x value add label x values (multiplying shift_x). flag specifying whether also return transformed parameters. all_dists flag specifying whether named distributions must fit successfully. at_boundary_ok flag specifying whether model one parameters boundary considered converged (default = FALSE). average flag specifying whether provide model averaged values opposed value distribution. bcanz flag NULL specifying whether include distributions set approved BC, Canada, Australia New Zealand official guidelines. breaks character vector bounds named non-negative numeric vector left right bounds uncensored missing (0 Inf) data terms orders magnitude relative extremes non-missing values. chk flag specifying whether check arguments. ci flag specifying whether estimate confidence intervals (bootstrapping). color string column data color aesthetic. computable flag specifying whether return fits numerically computable standard errors. conc numeric vector concentrations calculate hazard proportions . control list control parameters passed stats::optim(). data data frame. delta non-negative number specifying maximum absolute AIC difference cutoff. Distributions absolute AIC difference greater delta excluded calculations. digits whole number specifying number significant figures. dists character vector distribution names. hc value 0 1 indicating proportion hazard concentration (NULL). label string column data labels. left string column data concentrations. level number 0 1 confidence level interval. linecolor string column pred use line color. linetype string column pred use linetype. llocation location parameter log scale. location location parameter. locationlog location log scale parameter. locationlog1 locationlog1 parameter. locationlog2 locationlog2 parameter. log logical; TRUE, probabilities p given log(p). log.p logical; TRUE, probabilities p given log(p). lscale scale parameter log scale. lshape shape parameter log scale. lshape1 shape1 parameter log scale. lshape2 shape2 parameter log scale. lower.tail logical; TRUE (default), probabilities P[X <= x], otherwise, P[X > x]. meanlog mean log scale parameter. meanlog1 mean log scale parameter. meanlog2 mean log scale parameter. min_pboot number 0 1 minimum proportion bootstrap samples must successfully fit (return likelihood) report confidence intervals. min_pmix number 0 0.5 specifying minimum proportion mixture models. npars whole numeric vector specifying distributions include based number parameters. all_estimates flag specifying whether calculate estimates implemented distributions. ci_method string specifying method use estimating bootstrap values. Possible values \"multi_free\" \"multi_fixed\" treat distributions constituting single distribution differ whether model weights fixed \"weighted_samples\" \"weighted_arithmetic\" take bootstrap samples distribution proportional weight versus calculating weighted arithmetic means lower upper confidence limits. multi_est flag specifying whether treat distributions constituting single distribution (opposed taking mean) calculating model averaged estimates. na.rm flag specifying whether silently remove missing values remove warning. n positive number observations. nboot count number bootstrap samples use estimate confidence limits. value 10,000 recommended official guidelines. nrow positive whole number minimum number non-missing rows. nsim positive whole number number simulations generate. object object. parametric flag specifying whether perform parametric bootstrapping opposed non-parametrically resampling original data replacement. p vector probabilities. percent numeric vector percent values estimate hazard concentrations . Soft-deprecated proportion = 0.05. pmix Proportion mixture parameter. proportion numeric vector proportion values estimate hazard concentrations . pvalue flag specifying whether return p-values statistics (default) various tests. pred data frame predictions. q vector quantiles. range_shape1 numeric vector length two lower upper bounds shape1 parameter. range_shape2 shape2 parameter. reweight flag specifying whether reweight weights dividing largest weight. rescale flag specifying whether rescale concentration values dividing geometric mean minimum maximum positive finite values. ribbon flag indicating whether plot confidence interval grey ribbon opposed green solid lines. right string column data right concentration values. save_to NULL string specifying directory save bootstrap datasets parameter estimates (successfully converged) . samples flag specfying whether include numeric vector bootstrap samples list column output. scale scale parameter. scalelog1 scalelog1 parameter. scalelog2 scalelog2 parameter. scalelog scale log scale parameter. sdlog standard deviation log scale parameter. sdlog1 standard deviation log scale parameter. sdlog2 standard deviation log scale parameter. select character vector distributions select. shape shape parameter. shape1 shape1 parameter. shape2 shape2 parameter. shift_x value multiply label x values (adding add_x). silent flag indicating whether fits fail silently. size number size labels. tails flag NULL specifying whether include distributions tails. trans string transformation use default \"log10\". weight string numeric column data positive weights less equal 1,000 NULL. x object. xbreaks x-axis breaks one : NULL breaks waiver() default breaks numeric vector positions xintercept x-value intersect xlab string x-axis label. yintercept y-value intersect. ylab string x-axis label. burrIII3.weight weight parameter Burr III distribution. burrIII3.shape1 shape1 parameter Burr III distribution. burrIII3.shape2 shape2 parameter Burr III distribution. burrIII3.scale scale parameter Burr III distribution. gamma.weight weight parameter gamma distribution. gamma.shape shape parameter gamma distribution. gamma.scale scale parameter gamma distribution. gompertz.weight weight parameter Gompertz distribution. gompertz.location location parameter Gompertz distribution. gompertz.shape shape parameter Gompertz distribution. invpareto.weight weight parameter inverse Pareto distribution. invpareto.shape shape parameter inverse Pareto distribution. invpareto.scale scale parameter inverse Pareto distribution. lgumbel.weight weight parameter log-Gumbel distribution. lgumbel.locationlog location parameter log-Gumbel distribution. lgumbel.scalelog scale parameter log-Gumbel distribution. llogis.weight weight parameter log-logistic distribution. llogis.locationlog location parameter log-logistic distribution. llogis.scalelog scale parameter log-logistic distribution. llogis_llogis.weight weight parameter log-logistic log-logistic mixture distribution. llogis_llogis.locationlog1 locationlog1 parameter log-logistic log-logistic mixture distribution. llogis_llogis.scalelog1 scalelog1 parameter log-logistic log-logistic mixture distribution. llogis_llogis.locationlog2 locationlog2 parameter log-logistic log-logistic mixture distribution. llogis_llogis.scalelog2 scalelog2 parameter log-logistic log-logistic mixture distribution. llogis_llogis.pmix pmix parameter log-logistic log-logistic mixture distribution. lnorm.weight weight parameter log-normal distribution. lnorm.meanlog meanlog parameter log-normal distribution. lnorm.sdlog sdlog parameter log-normal distribution. lnorm_lnorm.weight weight parameter log-normal log-normal mixture distribution. lnorm_lnorm.meanlog1 meanlog1 parameter log-normal log-normal mixture distribution. lnorm_lnorm.sdlog1 sdlog1 parameter log-normal log-normal mixture distribution. lnorm_lnorm.meanlog2 meanlog2 parameter log-normal log-normal mixture distribution. lnorm_lnorm.sdlog2 sdlog2 parameter log-normal log-normal mixture distribution. lnorm_lnorm.pmix pmix parameter log-normal log-normal mixture distribution. weibull.weight weight parameter Weibull distribution. weibull.shape shape parameter Weibull distribution. weibull.scale scale parameter Weibull distribution. ... Unused.","code":""},{"path":"/reference/pearson1000.html","id":null,"dir":"Reference","previous_headings":"","what":"Pearson 1000 Data — pearson1000","title":"Pearson 1000 Data — pearson1000","text":"example tibble 1000 values simulated using Pearson distribution #FIXME #FIXME #FIXME #FIXME.","code":""},{"path":"/reference/pearson1000.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pearson 1000 Data — pearson1000","text":"","code":"pearson1000"},{"path":"/reference/pearson1000.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Pearson 1000 Data — pearson1000","text":"tbl data frame includes: Conc numeric vector simulate concentrations.","code":""},{"path":"/reference/pearson1000.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pearson 1000 Data — pearson1000","text":"data released $FIXME","code":""},{"path":"/reference/pearson1000.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pearson 1000 Data — pearson1000","text":"","code":"head(pearson1000) #> # A tibble: 6 × 1 #>    Conc #>   <dbl> #> 1  142. #> 2  146. #> 3  146. #> 4  142. #> 5  149. #> 6  136."},{"path":"/reference/pgompertz.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative Distribution Function for Gompertz Distribution  — pgompertz","title":"Cumulative Distribution Function for Gompertz Distribution  — pgompertz","text":"Cumulative Distribution Function Gompertz Distribution","code":""},{"path":"/reference/pgompertz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative Distribution Function for Gompertz Distribution  — pgompertz","text":"","code":"pgompertz(q, llocation = 0, lshape = 0, lower.tail = TRUE, log.p = FALSE)"},{"path":"/reference/pgompertz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative Distribution Function for Gompertz Distribution  — pgompertz","text":"q vector quantiles. llocation location parameter log scale. lshape shape parameter log scale. lower.tail logical; TRUE (default), probabilities P[X <= x], otherwise, P[X > x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"/reference/plgumbel.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative Distribution Function for Log-Gumbel Distribution  — plgumbel","title":"Cumulative Distribution Function for Log-Gumbel Distribution  — plgumbel","text":"Cumulative Distribution Function Log-Gumbel Distribution","code":""},{"path":"/reference/plgumbel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative Distribution Function for Log-Gumbel Distribution  — plgumbel","text":"","code":"plgumbel(q, locationlog = 0, scalelog = 1, lower.tail = TRUE, log.p = FALSE)"},{"path":"/reference/plgumbel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative Distribution Function for Log-Gumbel Distribution  — plgumbel","text":"q vector quantiles. locationlog location log scale parameter. scalelog scale log scale parameter. lower.tail logical; TRUE (default), probabilities P[X <= x], otherwise, P[X > x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"/reference/predict.fitburrlioz.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict Hazard Concentrations of fitburrlioz Object — predict.fitburrlioz","title":"Predict Hazard Concentrations of fitburrlioz Object — predict.fitburrlioz","text":"wrapper ssd_hc() default calculates hazard concentrations 1 99%.","code":""},{"path":"/reference/predict.fitburrlioz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict Hazard Concentrations of fitburrlioz Object — predict.fitburrlioz","text":"","code":"# S3 method for fitburrlioz predict(   object,   percent,   proportion = 1:99/100,   ci = FALSE,   level = 0.95,   nboot = 1000,   min_pboot = 0.95,   parametric = TRUE,   ... )"},{"path":"/reference/predict.fitburrlioz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict Hazard Concentrations of fitburrlioz Object — predict.fitburrlioz","text":"object object. percent numeric vector percent values estimate hazard concentrations . Soft-deprecated proportion = 0.05. proportion numeric vector proportion values estimate hazard concentrations . ci flag specifying whether estimate confidence intervals (bootstrapping). level number 0 1 confidence level interval. nboot count number bootstrap samples use estimate confidence limits. value 10,000 recommended official guidelines. min_pboot number 0 1 minimum proportion bootstrap samples must successfully fit (return likelihood) report confidence intervals. parametric flag specifying whether perform parametric bootstrapping opposed non-parametrically resampling original data replacement. ... Unused.","code":""},{"path":"/reference/predict.fitburrlioz.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict Hazard Concentrations of fitburrlioz Object — predict.fitburrlioz","text":"useful plotting purposes.","code":""},{"path":[]},{"path":"/reference/predict.fitburrlioz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict Hazard Concentrations of fitburrlioz Object — predict.fitburrlioz","text":"","code":"fits <- ssd_fit_burrlioz(ssddata::ccme_boron) predict(fits) #> # A tibble: 99 × 11 #>    dist     proportion    est    se   lcl   ucl    wt method nboot pboot samples #>    <chr>         <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <chr>  <int> <dbl> <I<lis> #>  1 invpare…       0.01 0.0228    NA    NA    NA     1 param…     0    NA <dbl>   #>  2 invpare…       0.02 0.0772    NA    NA    NA     1 param…     0    NA <dbl>   #>  3 invpare…       0.03 0.158     NA    NA    NA     1 param…     0    NA <dbl>   #>  4 invpare…       0.04 0.261     NA    NA    NA     1 param…     0    NA <dbl>   #>  5 invpare…       0.05 0.387     NA    NA    NA     1 param…     0    NA <dbl>   #>  6 invpare…       0.06 0.533     NA    NA    NA     1 param…     0    NA <dbl>   #>  7 invpare…       0.07 0.699     NA    NA    NA     1 param…     0    NA <dbl>   #>  8 invpare…       0.08 0.885     NA    NA    NA     1 param…     0    NA <dbl>   #>  9 invpare…       0.09 1.09      NA    NA    NA     1 param…     0    NA <dbl>   #> 10 invpare…       0.1  1.31      NA    NA    NA     1 param…     0    NA <dbl>   #> # ℹ 89 more rows"},{"path":"/reference/predict.fitdists.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict Hazard Concentrations of fitdists Object — predict.fitdists","title":"Predict Hazard Concentrations of fitdists Object — predict.fitdists","text":"wrapper ssd_hc() default calculates hazard concentrations 1 99%.","code":""},{"path":"/reference/predict.fitdists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict Hazard Concentrations of fitdists Object — predict.fitdists","text":"","code":"# S3 method for fitdists predict(   object,   percent,   proportion = 1:99/100,   average = TRUE,   ci = FALSE,   level = 0.95,   nboot = 1000,   min_pboot = 0.95,   multi_est = TRUE,   ci_method = \"weighted_samples\",   parametric = TRUE,   delta = 9.21,   control = NULL,   ... )"},{"path":"/reference/predict.fitdists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict Hazard Concentrations of fitdists Object — predict.fitdists","text":"object object. percent numeric vector percent values estimate hazard concentrations . Soft-deprecated proportion = 0.05. proportion numeric vector proportion values estimate hazard concentrations . average flag specifying whether provide model averaged values opposed value distribution. ci flag specifying whether estimate confidence intervals (bootstrapping). level number 0 1 confidence level interval. nboot count number bootstrap samples use estimate confidence limits. value 10,000 recommended official guidelines. min_pboot number 0 1 minimum proportion bootstrap samples must successfully fit (return likelihood) report confidence intervals. multi_est flag specifying whether treat distributions constituting single distribution (opposed taking mean) calculating model averaged estimates. ci_method string specifying method use estimating bootstrap values. Possible values \"multi_free\" \"multi_fixed\" treat distributions constituting single distribution differ whether model weights fixed \"weighted_samples\" \"weighted_arithmetic\" take bootstrap samples distribution proportional weight versus calculating weighted arithmetic means lower upper confidence limits. parametric flag specifying whether perform parametric bootstrapping opposed non-parametrically resampling original data replacement. delta non-negative number specifying maximum absolute AIC difference cutoff. Distributions absolute AIC difference greater delta excluded calculations. control list control parameters passed stats::optim(). ... Unused.","code":""},{"path":"/reference/predict.fitdists.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict Hazard Concentrations of fitdists Object — predict.fitdists","text":"useful plotting purposes.","code":""},{"path":[]},{"path":"/reference/predict.fitdists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict Hazard Concentrations of fitdists Object — predict.fitdists","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) predict(fits) #> # A tibble: 99 × 11 #>    dist    proportion   est    se   lcl   ucl    wt method   nboot pboot samples #>    <chr>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>    <int> <dbl> <I<lis> #>  1 average       0.01 0.267    NA    NA    NA     1 paramet…     0   NaN <dbl>   #>  2 average       0.02 0.531    NA    NA    NA     1 paramet…     0   NaN <dbl>   #>  3 average       0.03 0.783    NA    NA    NA     1 paramet…     0   NaN <dbl>   #>  4 average       0.04 1.02     NA    NA    NA     1 paramet…     0   NaN <dbl>   #>  5 average       0.05 1.26     NA    NA    NA     1 paramet…     0   NaN <dbl>   #>  6 average       0.06 1.48     NA    NA    NA     1 paramet…     0   NaN <dbl>   #>  7 average       0.07 1.71     NA    NA    NA     1 paramet…     0   NaN <dbl>   #>  8 average       0.08 1.93     NA    NA    NA     1 paramet…     0   NaN <dbl>   #>  9 average       0.09 2.16     NA    NA    NA     1 paramet…     0   NaN <dbl>   #> 10 average       0.1  2.38     NA    NA    NA     1 paramet…     0   NaN <dbl>   #> # ℹ 89 more rows"},{"path":"/reference/qgompertz.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile Function for Gompertz Distribution  — qgompertz","title":"Quantile Function for Gompertz Distribution  — qgompertz","text":"Quantile Function Gompertz Distribution","code":""},{"path":"/reference/qgompertz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile Function for Gompertz Distribution  — qgompertz","text":"","code":"qgompertz(p, llocation = 0, lshape = 0, lower.tail = TRUE, log.p = FALSE)"},{"path":"/reference/qgompertz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile Function for Gompertz Distribution  — qgompertz","text":"p vector probabilities. llocation location parameter log scale. lshape shape parameter log scale. lower.tail logical; TRUE (default), probabilities P[X <= x], otherwise, P[X > x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"/reference/qlgumbel.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile Function for Log-Gumbel Distribution  — qlgumbel","title":"Quantile Function for Log-Gumbel Distribution  — qlgumbel","text":"Quantile Function Log-Gumbel Distribution","code":""},{"path":"/reference/qlgumbel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile Function for Log-Gumbel Distribution  — qlgumbel","text":"","code":"qlgumbel(p, locationlog = 0, scalelog = 1, lower.tail = TRUE, log.p = FALSE)"},{"path":"/reference/qlgumbel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile Function for Log-Gumbel Distribution  — qlgumbel","text":"p vector probabilities. locationlog location log scale parameter. scalelog scale log scale parameter. lower.tail logical; TRUE (default), probabilities P[X <= x], otherwise, P[X > x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics augment, glance, tidy ggplot2 autoplot, waiver graphics plot stats coef, logLik, nobs, predict universals estimates, npars","code":""},{"path":"/reference/rgompertz.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Generation for Gompertz Distribution  — rgompertz","title":"Random Generation for Gompertz Distribution  — rgompertz","text":"Random Generation Gompertz Distribution","code":""},{"path":"/reference/rgompertz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Generation for Gompertz Distribution  — rgompertz","text":"","code":"rgompertz(n, llocation = 0, lshape = 0)"},{"path":"/reference/rgompertz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Generation for Gompertz Distribution  — rgompertz","text":"n positive number observations. llocation location parameter log scale. lshape shape parameter log scale.","code":""},{"path":"/reference/rlgumbel.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Generation for log-Gumbel Distribution  — rlgumbel","title":"Random Generation for log-Gumbel Distribution  — rlgumbel","text":"Random Generation log-Gumbel Distribution","code":""},{"path":"/reference/rlgumbel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Generation for log-Gumbel Distribution  — rlgumbel","text":"","code":"rlgumbel(n, locationlog = 0, scalelog = 1)"},{"path":"/reference/rlgumbel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Generation for log-Gumbel Distribution  — rlgumbel","text":"n positive number observations. locationlog location log scale parameter. scalelog scale log scale parameter.","code":""},{"path":"/reference/scale_colour_ssd.html","id":null,"dir":"Reference","previous_headings":"","what":"Discrete color-blind scale for SSD Plots — scale_colour_ssd","title":"Discrete color-blind scale for SSD Plots — scale_colour_ssd","text":"Discrete color-blind scale SSD Plots","code":""},{"path":"/reference/scale_colour_ssd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Discrete color-blind scale for SSD Plots — scale_colour_ssd","text":"","code":"scale_colour_ssd(...)  scale_color_ssd(...)"},{"path":"/reference/scale_colour_ssd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Discrete color-blind scale for SSD Plots — scale_colour_ssd","text":"... Arguments passed ggplot2::discrete_scale().","code":""},{"path":"/reference/scale_colour_ssd.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Discrete color-blind scale for SSD Plots — scale_colour_ssd","text":"scale_color_ssd(): Discrete color-blind scale SSD Plots","code":""},{"path":[]},{"path":"/reference/scale_colour_ssd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Discrete color-blind scale for SSD Plots — scale_colour_ssd","text":"","code":"ssd_plot(ssddata::ccme_boron, boron_pred, shape = \"Group\") +   scale_colour_ssd()"},{"path":"/reference/ssd_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Data from fitdists Object — ssd_data","title":"Data from fitdists Object — ssd_data","text":"Get tibble original data.","code":""},{"path":"/reference/ssd_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data from fitdists Object — ssd_data","text":"","code":"ssd_data(x)"},{"path":"/reference/ssd_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data from fitdists Object — ssd_data","text":"x object.","code":""},{"path":"/reference/ssd_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data from fitdists Object — ssd_data","text":"tibble original data.","code":""},{"path":[]},{"path":"/reference/ssd_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data from fitdists Object — ssd_data","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) ssd_data(fits) #> # A tibble: 28 × 5 #>    Chemical Species                  Conc Group        Units #>    <chr>    <chr>                   <dbl> <fct>        <chr> #>  1 Boron    Oncorhynchus mykiss       2.1 Fish         mg/L  #>  2 Boron    Ictalurus punctatus       2.4 Fish         mg/L  #>  3 Boron    Micropterus salmoides     4.1 Fish         mg/L  #>  4 Boron    Brachydanio rerio        10   Fish         mg/L  #>  5 Boron    Carassius auratus        15.6 Fish         mg/L  #>  6 Boron    Pimephales promelas      18.3 Fish         mg/L  #>  7 Boron    Daphnia magna             6   Invertebrate mg/L  #>  8 Boron    Opercularia bimarginata  10   Invertebrate mg/L  #>  9 Boron    Ceriodaphnia dubia       13.4 Invertebrate mg/L  #> 10 Boron    Entosiphon sulcatum      15   Invertebrate mg/L  #> # ℹ 18 more rows"},{"path":"/reference/ssd_dists.html","id":null,"dir":"Reference","previous_headings":"","what":"Species Sensitivity Distributions — ssd_dists","title":"Species Sensitivity Distributions — ssd_dists","text":"Gets character vector names available distributions.","code":""},{"path":"/reference/ssd_dists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Species Sensitivity Distributions — ssd_dists","text":"","code":"ssd_dists(bcanz = NULL, tails = NULL, npars = 2:5)"},{"path":"/reference/ssd_dists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Species Sensitivity Distributions — ssd_dists","text":"bcanz flag NULL specifying whether include distributions set approved BC, Canada, Australia New Zealand official guidelines. tails flag NULL specifying whether include distributions tails. npars whole numeric vector specifying distributions include based number parameters.","code":""},{"path":"/reference/ssd_dists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Species Sensitivity Distributions — ssd_dists","text":"unique, sorted character vector distributions.","code":""},{"path":[]},{"path":"/reference/ssd_dists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Species Sensitivity Distributions — ssd_dists","text":"","code":"ssd_dists() #>  [1] \"burrIII3\"      \"gamma\"         \"gompertz\"      \"invpareto\"     #>  [5] \"lgumbel\"       \"llogis\"        \"llogis_llogis\" \"lnorm\"         #>  [9] \"lnorm_lnorm\"   \"weibull\"       ssd_dists(bcanz = TRUE) #> [1] \"gamma\"       \"lgumbel\"     \"llogis\"      \"lnorm\"       \"lnorm_lnorm\" #> [6] \"weibull\"     ssd_dists(tails = FALSE) #> [1] \"invpareto\" ssd_dists(npars = 5) #> [1] \"llogis_llogis\" \"lnorm_lnorm\""},{"path":"/reference/ssd_dists_all.html","id":null,"dir":"Reference","previous_headings":"","what":"All Species Sensitivity Distributions — ssd_dists_all","title":"All Species Sensitivity Distributions — ssd_dists_all","text":"Gets character vector names available distributions.","code":""},{"path":"/reference/ssd_dists_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"All Species Sensitivity Distributions — ssd_dists_all","text":"","code":"ssd_dists_all()"},{"path":"/reference/ssd_dists_all.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"All Species Sensitivity Distributions — ssd_dists_all","text":"unique, sorted character vector distributions.","code":""},{"path":[]},{"path":"/reference/ssd_dists_all.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"All Species Sensitivity Distributions — ssd_dists_all","text":"","code":"ssd_dists_all() #>  [1] \"burrIII3\"      \"gamma\"         \"gompertz\"      \"invpareto\"     #>  [5] \"lgumbel\"       \"llogis\"        \"llogis_llogis\" \"lnorm\"         #>  [9] \"lnorm_lnorm\"   \"weibull\""},{"path":"/reference/ssd_dists_bcanz.html","id":null,"dir":"Reference","previous_headings":"","what":"BCANZ Distributions — ssd_dists_bcanz","title":"BCANZ Distributions — ssd_dists_bcanz","text":"Gets character vector names distributions adopted BC, Canada, Australia New Zealand official guidelines.","code":""},{"path":"/reference/ssd_dists_bcanz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BCANZ Distributions — ssd_dists_bcanz","text":"","code":"ssd_dists_bcanz(npars = c(2L, 5L))"},{"path":"/reference/ssd_dists_bcanz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BCANZ Distributions — ssd_dists_bcanz","text":"npars whole numeric vector specifying distributions include based number parameters.","code":""},{"path":"/reference/ssd_dists_bcanz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BCANZ Distributions — ssd_dists_bcanz","text":"unique, sorted character vector distributions.","code":""},{"path":[]},{"path":"/reference/ssd_dists_bcanz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BCANZ Distributions — ssd_dists_bcanz","text":"","code":"ssd_dists_bcanz() #> [1] \"gamma\"       \"lgumbel\"     \"llogis\"      \"lnorm\"       \"lnorm_lnorm\" #> [6] \"weibull\"     ssd_dists_bcanz(npars = 2) #> [1] \"gamma\"   \"lgumbel\" \"llogis\"  \"lnorm\"   \"weibull\""},{"path":"/reference/ssd_e.html","id":null,"dir":"Reference","previous_headings":"","what":"Default Parameter Estimates — ssd_eburrIII3","title":"Default Parameter Estimates — ssd_eburrIII3","text":"Default Parameter Estimates","code":""},{"path":"/reference/ssd_e.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default Parameter Estimates — ssd_eburrIII3","text":"","code":"ssd_eburrIII3()  ssd_egamma()  ssd_egompertz()  ssd_einvpareto()  ssd_elgumbel()  ssd_elgumbel()  ssd_ellogis_llogis()  ssd_ellogis()  ssd_elnorm_lnorm()  ssd_elnorm()  ssd_emulti()  ssd_eweibull()"},{"path":"/reference/ssd_e.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Default Parameter Estimates — ssd_eburrIII3","text":"ssd_eburrIII3(): Default Parameter Values BurrIII Distribution ssd_egamma(): Default Parameter Values Gamma Distribution ssd_egompertz(): Default Parameter Values Gompertz Distribution ssd_einvpareto(): Default Parameter Values Inverse Pareto Distribution ssd_elgumbel(): Default Parameter Values Log-Gumbel Distribution ssd_elgumbel(): Default Parameter Values log-Gumbel Distribution ssd_ellogis_llogis(): Default Parameter Values Log-Logistic/Log-Logistic Mixture Distribution ssd_ellogis(): Default Parameter Values Log-Logistic Distribution ssd_elnorm_lnorm(): Default Parameter Values Log-Normal/Log-Normal Mixture Distribution ssd_elnorm(): Default Parameter Values Log-Normal Distribution ssd_emulti(): Default Parameter Values Multiple Distributions ssd_eweibull(): Default Parameter Values Log-Normal Distribution","code":""},{"path":[]},{"path":"/reference/ssd_e.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Default Parameter Estimates — ssd_eburrIII3","text":"","code":"ssd_eburrIII3() #> $shape1 #> [1] 1 #>  #> $shape2 #> [1] 1 #>  #> $scale #> [1] 1 #>   ssd_egamma() #> $shape #> [1] 1 #>  #> $scale #> [1] 1 #>   ssd_egompertz() #> $location #> [1] 1 #>  #> $shape #> [1] 1 #>   ssd_einvpareto() #> $shape #> [1] 3 #>  #> $scale #> [1] 1 #>   ssd_einvpareto() #> $shape #> [1] 3 #>  #> $scale #> [1] 1 #>   ssd_elgumbel() #> $locationlog #> [1] 0 #>  #> $scalelog #> [1] 1 #>   ssd_ellogis_llogis() #> $locationlog1 #> [1] 0 #>  #> $scalelog1 #> [1] 1 #>  #> $locationlog2 #> [1] 1 #>  #> $scalelog2 #> [1] 1 #>  #> $pmix #> [1] 0.5 #>   ssd_ellogis() #> $locationlog #> [1] 0 #>  #> $scalelog #> [1] 1 #>   ssd_elnorm_lnorm() #> $meanlog1 #> [1] 0 #>  #> $sdlog1 #> [1] 1 #>  #> $meanlog2 #> [1] 1 #>  #> $sdlog2 #> [1] 1 #>  #> $pmix #> [1] 0.5 #>   ssd_elnorm() #> $meanlog #> [1] 0 #>  #> $sdlog #> [1] 1 #>   ssd_emulti() #> $burrIII3.weight #> [1] 0 #>  #> $burrIII3.shape1 #> [1] 1 #>  #> $burrIII3.shape2 #> [1] 1 #>  #> $burrIII3.scale #> [1] 1 #>  #> $gamma.weight #> [1] 0.1666667 #>  #> $gamma.shape #> [1] 1 #>  #> $gamma.scale #> [1] 1 #>  #> $gompertz.weight #> [1] 0 #>  #> $gompertz.location #> [1] 1 #>  #> $gompertz.shape #> [1] 1 #>  #> $invpareto.weight #> [1] 0 #>  #> $invpareto.shape #> [1] 3 #>  #> $invpareto.scale #> [1] 1 #>  #> $lgumbel.weight #> [1] 0.1666667 #>  #> $lgumbel.locationlog #> [1] 0 #>  #> $lgumbel.scalelog #> [1] 1 #>  #> $llogis.weight #> [1] 0.1666667 #>  #> $llogis.locationlog #> [1] 0 #>  #> $llogis.scalelog #> [1] 1 #>  #> $llogis_llogis.weight #> [1] 0 #>  #> $llogis_llogis.locationlog1 #> [1] 0 #>  #> $llogis_llogis.scalelog1 #> [1] 1 #>  #> $llogis_llogis.locationlog2 #> [1] 1 #>  #> $llogis_llogis.scalelog2 #> [1] 1 #>  #> $llogis_llogis.pmix #> [1] 0.5 #>  #> $lnorm.weight #> [1] 0.1666667 #>  #> $lnorm.meanlog #> [1] 0 #>  #> $lnorm.sdlog #> [1] 1 #>  #> $lnorm_lnorm.weight #> [1] 0.1666667 #>  #> $lnorm_lnorm.meanlog1 #> [1] 0 #>  #> $lnorm_lnorm.sdlog1 #> [1] 1 #>  #> $lnorm_lnorm.meanlog2 #> [1] 1 #>  #> $lnorm_lnorm.sdlog2 #> [1] 1 #>  #> $lnorm_lnorm.pmix #> [1] 0.5 #>  #> $weibull.weight #> [1] 0.1666667 #>  #> $weibull.shape #> [1] 1 #>  #> $weibull.scale #> [1] 1 #>   ssd_eweibull() #> $shape #> [1] 1 #>  #> $scale #> [1] 1 #>"},{"path":"/reference/ssd_ecd.html","id":null,"dir":"Reference","previous_headings":"","what":"Empirical Cumulative Density — ssd_ecd","title":"Empirical Cumulative Density — ssd_ecd","text":"Empirical Cumulative Density","code":""},{"path":"/reference/ssd_ecd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empirical Cumulative Density — ssd_ecd","text":"","code":"ssd_ecd(x, ties.method = \"first\")"},{"path":"/reference/ssd_ecd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Empirical Cumulative Density — ssd_ecd","text":"x numeric, complex, character logical vector. ties.method character string specifying ties treated,     see ‘Details’; can abbreviated.","code":""},{"path":"/reference/ssd_ecd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Empirical Cumulative Density — ssd_ecd","text":"numeric vector empirical cumulative density.","code":""},{"path":"/reference/ssd_ecd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Empirical Cumulative Density — ssd_ecd","text":"","code":"ssd_ecd(1:10) #>  [1] 0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 0.95"},{"path":"/reference/ssd_ecd_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Empirical Cumulative Density for Species Sensitivity Data — ssd_ecd_data","title":"Empirical Cumulative Density for Species Sensitivity Data — ssd_ecd_data","text":"Empirical Cumulative Density Species Sensitivity Data","code":""},{"path":"/reference/ssd_ecd_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empirical Cumulative Density for Species Sensitivity Data — ssd_ecd_data","text":"","code":"ssd_ecd_data(   data,   left = \"Conc\",   right = left,   bounds = c(left = 1, right = 1) )"},{"path":"/reference/ssd_ecd_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Empirical Cumulative Density for Species Sensitivity Data — ssd_ecd_data","text":"data data frame. left string column data concentrations. right string column data right concentration values. bounds named non-negative numeric vector left right bounds uncensored missing (0 Inf) data terms orders magnitude relative extremes non-missing values.","code":""},{"path":"/reference/ssd_ecd_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Empirical Cumulative Density for Species Sensitivity Data — ssd_ecd_data","text":"numeric vector empirical cumulative density rows data.","code":""},{"path":[]},{"path":"/reference/ssd_ecd_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Empirical Cumulative Density for Species Sensitivity Data — ssd_ecd_data","text":"","code":"ssd_ecd_data(ssddata::ccme_boron) #>  [1] 0.12500000 0.16071429 0.23214286 0.33928571 0.51785714 0.55357143 #>  [7] 0.30357143 0.37500000 0.44642857 0.48214286 0.58928571 0.62500000 #> [13] 0.66071429 0.76785714 0.80357143 0.91071429 0.94642857 0.98214286 #> [19] 0.01785714 0.05357143 0.08928571 0.19642857 0.26785714 0.41071429 #> [25] 0.69642857 0.73214286 0.83928571 0.87500000"},{"path":"/reference/ssd_exposure.html","id":null,"dir":"Reference","previous_headings":"","what":"Proportion Exposure — ssd_exposure","title":"Proportion Exposure — ssd_exposure","text":"Calculates average proportion exposed based log-normal distribution concentrations.","code":""},{"path":"/reference/ssd_exposure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Proportion Exposure — ssd_exposure","text":"","code":"ssd_exposure(x, meanlog = 0, sdlog = 1, nboot = 1000)"},{"path":"/reference/ssd_exposure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Proportion Exposure — ssd_exposure","text":"x object. meanlog mean exposure concentrations log scale. sdlog standard deviation exposure concentrations log scale. nboot number samples use calculate exposure.","code":""},{"path":"/reference/ssd_exposure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Proportion Exposure — ssd_exposure","text":"proportion exposed.","code":""},{"path":"/reference/ssd_exposure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Proportion Exposure — ssd_exposure","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron, dists = \"lnorm\") set.seed(10) ssd_exposure(fits) #> [1] 0.05389213 ssd_exposure(fits, meanlog = 1) #> [1] 0.1705357 ssd_exposure(fits, meanlog = 1, sdlog = 1) #> [1] 0.1609466"},{"path":"/reference/ssd_fit_bcanz.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit BCANZ Distributions — ssd_fit_bcanz","title":"Fit BCANZ Distributions — ssd_fit_bcanz","text":"Fits distributions using settings adopted BC, Canada, Australia New Zealand official guidelines.","code":""},{"path":"/reference/ssd_fit_bcanz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit BCANZ Distributions — ssd_fit_bcanz","text":"","code":"ssd_fit_bcanz(data, left = \"Conc\", dists = ssd_dists_bcanz())"},{"path":"/reference/ssd_fit_bcanz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit BCANZ Distributions — ssd_fit_bcanz","text":"data data frame. left string column data concentrations. dists character vector distribution names.","code":""},{"path":"/reference/ssd_fit_bcanz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit BCANZ Distributions — ssd_fit_bcanz","text":"object class fitdists.","code":""},{"path":[]},{"path":"/reference/ssd_fit_bcanz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit BCANZ Distributions — ssd_fit_bcanz","text":"","code":"ssd_fit_bcanz(ssddata::ccme_boron) #> Distribution 'gamma' #>   scale 25.1268 #>   shape 0.950179 #>  #> Distribution 'lgumbel' #>   locationlog 1.92263 #>   scalelog 1.23224 #>  #> Distribution 'llogis' #>   locationlog 2.62628 #>   scalelog 0.740426 #>  #> Distribution 'lnorm' #>   meanlog 2.56165 #>   sdlog 1.24154 #>  #> Distribution 'lnorm_lnorm' #>   meanlog1 0.949487 #>   meanlog2 3.20108 #>   pmix 0.283994 #>   sdlog1 0.554514 #>   sdlog2 0.768824 #>  #> Distribution 'weibull' #>   scale 23.514 #>   shape 0.9661 #>  #> Parameters estimated from 28 rows of data."},{"path":"/reference/ssd_fit_burrlioz.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Burrlioz Distributions — ssd_fit_burrlioz","title":"Fit Burrlioz Distributions — ssd_fit_burrlioz","text":"Fits 'burrIII3' distribution. shape1 parameter boundary returns 'lgumbel' (equivalent inverse Weibull). Else shape2 parameter boundary returns 'invpareto'. Otherwise returns 'burrIII3'","code":""},{"path":"/reference/ssd_fit_burrlioz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Burrlioz Distributions — ssd_fit_burrlioz","text":"","code":"ssd_fit_burrlioz(data, left = \"Conc\", rescale = FALSE, silent = FALSE)"},{"path":"/reference/ssd_fit_burrlioz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Burrlioz Distributions — ssd_fit_burrlioz","text":"data data frame. left string column data concentrations. rescale flag specifying whether rescale concentration values dividing geometric mean minimum maximum positive finite values. silent flag indicating whether fits fail silently.","code":""},{"path":"/reference/ssd_fit_burrlioz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Burrlioz Distributions — ssd_fit_burrlioz","text":"object class fitdists.","code":""},{"path":[]},{"path":"/reference/ssd_fit_burrlioz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Burrlioz Distributions — ssd_fit_burrlioz","text":"","code":"ssd_fit_burrlioz(ssddata::ccme_boron) #> Distribution 'invpareto' #>   scale 75.2608 #>   shape 0.568403 #>  #> Parameters estimated from 28 rows of data."},{"path":"/reference/ssd_fit_dists.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Distributions — ssd_fit_dists","title":"Fit Distributions — ssd_fit_dists","text":"Fits one distributions species sensitivity data.","code":""},{"path":"/reference/ssd_fit_dists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Distributions — ssd_fit_dists","text":"","code":"ssd_fit_dists(   data,   left = \"Conc\",   right = left,   weight = NULL,   dists = ssd_dists_bcanz(),   nrow = 6L,   rescale = FALSE,   reweight = FALSE,   computable = TRUE,   at_boundary_ok = FALSE,   all_dists = FALSE,   min_pmix = 0,   range_shape1 = c(0.05, 20),   range_shape2 = range_shape1,   control = list(),   silent = FALSE )"},{"path":"/reference/ssd_fit_dists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Distributions — ssd_fit_dists","text":"data data frame. left string column data concentrations. right string column data right concentration values. weight string numeric column data positive weights less equal 1,000 NULL. dists character vector distribution names. nrow positive whole number minimum number non-missing rows. rescale flag specifying whether rescale concentration values dividing geometric mean minimum maximum positive finite values. reweight flag specifying whether reweight weights dividing largest weight. computable flag specifying whether return fits numerically computable standard errors. at_boundary_ok flag specifying whether model one parameters boundary considered converged (default = FALSE). all_dists flag specifying whether named distributions must fit successfully. min_pmix number 0 0.5 specifying minimum proportion mixture models. range_shape1 numeric vector length two lower upper bounds shape1 parameter. range_shape2 shape2 parameter. control list control parameters passed stats::optim(). silent flag indicating whether fits fail silently.","code":""},{"path":"/reference/ssd_fit_dists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Distributions — ssd_fit_dists","text":"object class fitdists.","code":""},{"path":"/reference/ssd_fit_dists.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit Distributions — ssd_fit_dists","text":"default 'llogis', 'gamma' 'lnorm' distributions fitted data. complete list implemented distributions see ssd_dists_all(). weight specifies column data frame positive numbers, weighted estimation occurs. However, currently resultant parameter estimates available. right argument different left argument data considered censored.","code":""},{"path":[]},{"path":"/reference/ssd_fit_dists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Distributions — ssd_fit_dists","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) fits #> Distribution 'gamma' #>   scale 25.1268 #>   shape 0.950179 #>  #> Distribution 'lgumbel' #>   locationlog 1.92263 #>   scalelog 1.23224 #>  #> Distribution 'llogis' #>   locationlog 2.62628 #>   scalelog 0.740426 #>  #> Distribution 'lnorm' #>   meanlog 2.56165 #>   sdlog 1.24154 #>  #> Distribution 'lnorm_lnorm' #>   meanlog1 0.949487 #>   meanlog2 3.20108 #>   pmix 0.283994 #>   sdlog1 0.554514 #>   sdlog2 0.768824 #>  #> Distribution 'weibull' #>   scale 23.514 #>   shape 0.9661 #>  #> Parameters estimated from 28 rows of data. ssd_plot_cdf(fits)  ssd_hc(fits) #> # A tibble: 1 × 11 #>   dist    proportion   est    se   lcl   ucl    wt method    nboot pboot samples #>   <chr>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>     <int> <dbl> <I<lis> #> 1 average       0.05  1.26    NA    NA    NA     1 parametr…     0   NaN <dbl>"},{"path":"/reference/ssd_gof.html","id":null,"dir":"Reference","previous_headings":"","what":"Goodness of Fit — ssd_gof","title":"Goodness of Fit — ssd_gof","text":"Returns tbl data frame following columns dist distribution name (chr) aic Akaike's Information Criterion (dbl) bic Bayesian Information Criterion (dbl) data non-censored aicc Akaike's Information Criterion corrected sample size (dbl) 8 samples ad Anderson-Darling statistic (dbl) ks Kolmogorov-Smirnov statistic (dbl) cvm Cramer-von Mises statistic (dbl) case object class fitdists function also returns delta Information Criterion differences (dbl) weight Information Criterion weights (dbl) delta weight based aic censored data aicc non-censored data.","code":""},{"path":"/reference/ssd_gof.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Goodness of Fit — ssd_gof","text":"","code":"ssd_gof(x, ...)  # S3 method for fitdists ssd_gof(x, pvalue = FALSE, ...)"},{"path":"/reference/ssd_gof.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Goodness of Fit — ssd_gof","text":"x object. ... Unused. pvalue flag specifying whether return p-values statistics (default) various tests.","code":""},{"path":"/reference/ssd_gof.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Goodness of Fit — ssd_gof","text":"tbl data frame gof statistics.","code":""},{"path":"/reference/ssd_gof.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Goodness of Fit — ssd_gof","text":"ssd_gof(fitdists): Goodness Fit","code":""},{"path":[]},{"path":"/reference/ssd_gof.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Goodness of Fit — ssd_gof","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) ssd_gof(fits) #> # A tibble: 6 × 9 #>   dist           ad     ks    cvm   aic  aicc   bic delta weight #>   <chr>       <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl> #> 1 gamma       0.440 0.117  0.0554  238.  238.  240. 0.005  0.357 #> 2 lgumbel     0.829 0.158  0.134   244.  245.  247. 6.56   0.013 #> 3 llogis      0.487 0.0994 0.0595  241.  241.  244. 3.39   0.066 #> 4 lnorm       0.507 0.107  0.0703  239.  240.  242. 1.40   0.177 #> 5 lnorm_lnorm 0.320 0.116  0.0414  240.  243.  247. 4.98   0.03  #> 6 weibull     0.434 0.117  0.0542  238.  238.  240. 0      0.357 ssd_gof(fits) #> # A tibble: 6 × 9 #>   dist           ad     ks    cvm   aic  aicc   bic delta weight #>   <chr>       <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl> #> 1 gamma       0.440 0.117  0.0554  238.  238.  240. 0.005  0.357 #> 2 lgumbel     0.829 0.158  0.134   244.  245.  247. 6.56   0.013 #> 3 llogis      0.487 0.0994 0.0595  241.  241.  244. 3.39   0.066 #> 4 lnorm       0.507 0.107  0.0703  239.  240.  242. 1.40   0.177 #> 5 lnorm_lnorm 0.320 0.116  0.0414  240.  243.  247. 4.98   0.03  #> 6 weibull     0.434 0.117  0.0542  238.  238.  240. 0      0.357"},{"path":"/reference/ssd_hc.html","id":null,"dir":"Reference","previous_headings":"","what":"Hazard Concentrations for Species Sensitivity Distributions — ssd_hc","title":"Hazard Concentrations for Species Sensitivity Distributions — ssd_hc","text":"Calculates concentration(s) bootstrap confidence intervals protect specified proportion(s) species individual model-averaged distributions using parametric non-parametric bootstrapping.","code":""},{"path":"/reference/ssd_hc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hazard Concentrations for Species Sensitivity Distributions — ssd_hc","text":"","code":"ssd_hc(x, ...)  # S3 method for list ssd_hc(x, percent, proportion = 0.05, ...)  # S3 method for fitdists ssd_hc(   x,   percent,   proportion = 0.05,   average = TRUE,   ci = FALSE,   level = 0.95,   nboot = 1000,   min_pboot = 0.95,   multi_est = TRUE,   ci_method = \"weighted_samples\",   parametric = TRUE,   delta = 9.21,   samples = FALSE,   save_to = NULL,   control = NULL,   ... )  # S3 method for fitburrlioz ssd_hc(   x,   percent,   proportion = 0.05,   ci = FALSE,   level = 0.95,   nboot = 1000,   min_pboot = 0.95,   parametric = FALSE,   samples = FALSE,   save_to = NULL,   ... )"},{"path":"/reference/ssd_hc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hazard Concentrations for Species Sensitivity Distributions — ssd_hc","text":"x object. ... Unused. percent numeric vector percent values estimate hazard concentrations . Soft-deprecated proportion = 0.05. proportion numeric vector proportion values estimate hazard concentrations . average flag specifying whether provide model averaged values opposed value distribution. ci flag specifying whether estimate confidence intervals (bootstrapping). level number 0 1 confidence level interval. nboot count number bootstrap samples use estimate confidence limits. value 10,000 recommended official guidelines. min_pboot number 0 1 minimum proportion bootstrap samples must successfully fit (return likelihood) report confidence intervals. multi_est flag specifying whether treat distributions constituting single distribution (opposed taking mean) calculating model averaged estimates. ci_method string specifying method use estimating bootstrap values. Possible values \"multi_free\" \"multi_fixed\" treat distributions constituting single distribution differ whether model weights fixed \"weighted_samples\" \"weighted_arithmetic\" take bootstrap samples distribution proportional weight versus calculating weighted arithmetic means lower upper confidence limits. parametric flag specifying whether perform parametric bootstrapping opposed non-parametrically resampling original data replacement. delta non-negative number specifying maximum absolute AIC difference cutoff. Distributions absolute AIC difference greater delta excluded calculations. samples flag specfying whether include numeric vector bootstrap samples list column output. save_to NULL string specifying directory save bootstrap datasets parameter estimates (successfully converged) . control list control parameters passed stats::optim().","code":""},{"path":"/reference/ssd_hc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hazard Concentrations for Species Sensitivity Distributions — ssd_hc","text":"tibble corresponding hazard concentrations.","code":""},{"path":"/reference/ssd_hc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hazard Concentrations for Species Sensitivity Distributions — ssd_hc","text":"Model-averaged estimates /confidence intervals (including standard error) can calculated  treating distributions constituting single mixture distribution versus 'taking mean'. calculating model averaged estimates treating distributions constituting single mixture distribution ensures ssd_hc() inverse ssd_hp(). treating distributions constituting single mixture distribution calculating model average confidence intervals weighted specifies whether use original model weights versus re-estimating bootstrap sample unless 'taking mean' case weighted specifies whether take bootstrap samples distribution proportional weight (sum nboot) versus calculating weighted arithmetic means lower upper confidence limits based nboot samples distribution. Distributions absolute AIC difference greater delta default 7 considerably less support (weight < 0.01) excluded prior calculation hazard concentrations reduce run time.","code":""},{"path":"/reference/ssd_hc.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Hazard Concentrations for Species Sensitivity Distributions — ssd_hc","text":"ssd_hc(list): Hazard Concentrations Distributional Estimates ssd_hc(fitdists): Hazard Concentrations fitdists Object ssd_hc(fitburrlioz): Hazard Concentrations fitburrlioz Object","code":""},{"path":"/reference/ssd_hc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hazard Concentrations for Species Sensitivity Distributions — ssd_hc","text":"Burnham, K.P., Anderson, D.R. 2002. Model Selection Multimodel Inference. Springer New York, New York, NY. doi:10.1007/b97636.","code":""},{"path":[]},{"path":"/reference/ssd_hc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hazard Concentrations for Species Sensitivity Distributions — ssd_hc","text":"","code":"ssd_hc(ssd_match_moments()) #> # A tibble: 6 × 9 #>   dist        proportion   est    se   lcl   ucl    wt nboot pboot #>   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <int> <dbl> #> 1 gamma             0.05 0.481    NA    NA    NA     1     0    NA #> 2 lgumbel           0.05 0.739    NA    NA    NA     1     0    NA #> 3 llogis            0.05 0.562    NA    NA    NA     1     0    NA #> 4 lnorm             0.05 0.558    NA    NA    NA     1     0    NA #> 5 lnorm_lnorm       0.05 0.469    NA    NA    NA     1     0    NA #> 6 weibull           0.05 0.501    NA    NA    NA     1     0    NA  fits <- ssd_fit_dists(ssddata::ccme_boron) ssd_hc(fits) #> # A tibble: 1 × 11 #>   dist    proportion   est    se   lcl   ucl    wt method    nboot pboot samples #>   <chr>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>     <int> <dbl> <I<lis> #> 1 average       0.05  1.26    NA    NA    NA     1 parametr…     0   NaN <dbl>    fit <- ssd_fit_burrlioz(ssddata::ccme_boron) ssd_hc(fit) #> # A tibble: 1 × 11 #>   dist      proportion   est    se   lcl   ucl    wt method  nboot pboot samples #>   <chr>          <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>   <int> <dbl> <I<lis> #> 1 invpareto       0.05 0.387    NA    NA    NA     1 non-pa…     0    NA <dbl>"},{"path":"/reference/ssd_hc_bcanz.html","id":null,"dir":"Reference","previous_headings":"","what":"BCANZ Hazard Concentrations — ssd_hc_bcanz","title":"BCANZ Hazard Concentrations — ssd_hc_bcanz","text":"Gets hazard concentrations confidence intervals protect 1, 5, 10 20% species using settings adopted BC, Canada, Australia New Zealand official guidelines. function can take several minutes run recommended 10,000 iterations.","code":""},{"path":"/reference/ssd_hc_bcanz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BCANZ Hazard Concentrations — ssd_hc_bcanz","text":"","code":"ssd_hc_bcanz(x, nboot = 10000, min_pboot = 0.95)"},{"path":"/reference/ssd_hc_bcanz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BCANZ Hazard Concentrations — ssd_hc_bcanz","text":"x object. nboot count number bootstrap samples use estimate confidence limits. value 10,000 recommended official guidelines. min_pboot number 0 1 minimum proportion bootstrap samples must successfully fit (return likelihood) report confidence intervals.","code":""},{"path":"/reference/ssd_hc_bcanz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BCANZ Hazard Concentrations — ssd_hc_bcanz","text":"tibble corresponding hazard concentrations.","code":""},{"path":[]},{"path":"/reference/ssd_hc_bcanz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BCANZ Hazard Concentrations — ssd_hc_bcanz","text":"","code":"fits <- ssd_fit_bcanz(ssddata::ccme_boron) ssd_hc_bcanz(fits, nboot = 100) #> # A tibble: 4 × 11 #>   dist    proportion   est    se    lcl   ucl    wt method   nboot pboot samples #>   <chr>        <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <chr>    <dbl> <dbl> <I<lis> #> 1 average       0.01 0.267 0.476 0.0596  1.73     1 paramet…   100     1 <dbl>   #> 2 average       0.05 1.26  0.880 0.453   3.94     1 paramet…   100     1 <dbl>   #> 3 average       0.1  2.38  1.22  1.11    5.89     1 paramet…   100     1 <dbl>   #> 4 average       0.2  4.81  1.81  2.70    9.50     1 paramet…   100     1 <dbl>"},{"path":"/reference/ssd_hc_burrlioz.html","id":null,"dir":"Reference","previous_headings":"","what":"Hazard Concentrations for Burrlioz Fit  — ssd_hc_burrlioz","title":"Hazard Concentrations for Burrlioz Fit  — ssd_hc_burrlioz","text":"Deprecated ssd_hc().","code":""},{"path":"/reference/ssd_hc_burrlioz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hazard Concentrations for Burrlioz Fit  — ssd_hc_burrlioz","text":"","code":"ssd_hc_burrlioz(   x,   percent,   proportion = 0.05,   ci = FALSE,   level = 0.95,   nboot = 1000,   min_pboot = 0.95,   parametric = FALSE )"},{"path":"/reference/ssd_hc_burrlioz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hazard Concentrations for Burrlioz Fit  — ssd_hc_burrlioz","text":"x object. percent numeric vector percent values estimate hazard concentrations . Soft-deprecated proportion = 0.05. proportion numeric vector proportion values estimate hazard concentrations . ci flag specifying whether estimate confidence intervals (bootstrapping). level number 0 1 confidence level interval. nboot count number bootstrap samples use estimate confidence limits. value 10,000 recommended official guidelines. min_pboot number 0 1 minimum proportion bootstrap samples must successfully fit (return likelihood) report confidence intervals. parametric flag specifying whether perform parametric bootstrapping opposed non-parametrically resampling original data replacement.","code":""},{"path":"/reference/ssd_hc_burrlioz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hazard Concentrations for Burrlioz Fit  — ssd_hc_burrlioz","text":"tibble corresponding hazard concentrations.","code":""},{"path":"/reference/ssd_hc_burrlioz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hazard Concentrations for Burrlioz Fit  — ssd_hc_burrlioz","text":"","code":"fit <- ssd_fit_burrlioz(ssddata::ccme_boron) ssd_hc_burrlioz(fit) #> Warning: `ssd_hc_burrlioz()` was deprecated in ssdtools 0.3.5. #> ℹ Please use `ssd_hc()` instead. #> # A tibble: 1 × 11 #>   dist      proportion   est    se   lcl   ucl    wt method  nboot pboot samples #>   <chr>          <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>   <int> <dbl> <I<lis> #> 1 invpareto       0.05 0.387    NA    NA    NA     1 non-pa…     0    NA <dbl>"},{"path":"/reference/ssd_hp.html","id":null,"dir":"Reference","previous_headings":"","what":"Hazard Proportion — ssd_hp","title":"Hazard Proportion — ssd_hp","text":"Calculates proportion species affected specified concentration(s) quantile based bootstrap confidence intervals individual model-averaged distributions using parametric non-parametric bootstrapping. information see inverse function ssd_hc().","code":""},{"path":"/reference/ssd_hp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hazard Proportion — ssd_hp","text":"","code":"ssd_hp(x, ...)  # S3 method for fitdists ssd_hp(   x,   conc = 1,   average = TRUE,   ci = FALSE,   level = 0.95,   nboot = 1000,   min_pboot = 0.95,   multi_est = TRUE,   ci_method = \"weighted_samples\",   parametric = TRUE,   delta = 9.21,   samples = FALSE,   save_to = NULL,   control = NULL,   ... )  # S3 method for fitburrlioz ssd_hp(   x,   conc = 1,   ci = FALSE,   level = 0.95,   nboot = 1000,   min_pboot = 0.95,   parametric = FALSE,   samples = FALSE,   save_to = NULL,   ... )"},{"path":"/reference/ssd_hp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hazard Proportion — ssd_hp","text":"x object. ... Unused. conc numeric vector concentrations calculate hazard proportions . average flag specifying whether provide model averaged values opposed value distribution. ci flag specifying whether estimate confidence intervals (bootstrapping). level number 0 1 confidence level interval. nboot count number bootstrap samples use estimate confidence limits. value 10,000 recommended official guidelines. min_pboot number 0 1 minimum proportion bootstrap samples must successfully fit (return likelihood) report confidence intervals. multi_est flag specifying whether treat distributions constituting single distribution (opposed taking mean) calculating model averaged estimates. ci_method string specifying method use estimating bootstrap values. Possible values \"multi_free\" \"multi_fixed\" treat distributions constituting single distribution differ whether model weights fixed \"weighted_samples\" \"weighted_arithmetic\" take bootstrap samples distribution proportional weight versus calculating weighted arithmetic means lower upper confidence limits. parametric flag specifying whether perform parametric bootstrapping opposed non-parametrically resampling original data replacement. delta non-negative number specifying maximum absolute AIC difference cutoff. Distributions absolute AIC difference greater delta excluded calculations. samples flag specfying whether include numeric vector bootstrap samples list column output. save_to NULL string specifying directory save bootstrap datasets parameter estimates (successfully converged) . control list control parameters passed stats::optim().","code":""},{"path":"/reference/ssd_hp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hazard Proportion — ssd_hp","text":"tibble corresponding hazard proportions.","code":""},{"path":"/reference/ssd_hp.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Hazard Proportion — ssd_hp","text":"ssd_hp(fitdists): Hazard Proportions fitdists Object ssd_hp(fitburrlioz): Hazard Proportions fitburrlioz Object","code":""},{"path":[]},{"path":"/reference/ssd_hp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hazard Proportion — ssd_hp","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) ssd_hp(fits, conc = 1) #> # A tibble: 1 × 11 #>   dist     conc   est    se   lcl   ucl    wt method     nboot pboot samples   #>   <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>      <int> <dbl> <I<list>> #> 1 average     1  3.90    NA    NA    NA     1 parametric     0   NaN <dbl [0]>  fit <- ssd_fit_burrlioz(ssddata::ccme_boron) ssd_hp(fit) #> # A tibble: 1 × 11 #>   dist       conc   est    se   lcl   ucl    wt method       nboot pboot samples #>   <chr>     <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>        <int> <dbl> <I<lis> #> 1 invpareto     1  8.58    NA    NA    NA     1 non-paramet…     0    NA <dbl>"},{"path":"/reference/ssd_hp_bcanz.html","id":null,"dir":"Reference","previous_headings":"","what":"BCANZ Hazard Proportion — ssd_hp_bcanz","title":"BCANZ Hazard Proportion — ssd_hp_bcanz","text":"Gets  proportion species affected specified concentration(s) using settings adopted BC, Canada, Australia New Zealand official guidelines. function can take several minutes run recommended 10,000 iterations.","code":""},{"path":"/reference/ssd_hp_bcanz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BCANZ Hazard Proportion — ssd_hp_bcanz","text":"","code":"ssd_hp_bcanz(x, conc = 1, nboot = 10000, min_pboot = 0.95)"},{"path":"/reference/ssd_hp_bcanz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BCANZ Hazard Proportion — ssd_hp_bcanz","text":"x object. conc numeric vector concentrations calculate hazard proportions . nboot count number bootstrap samples use estimate confidence limits. value 10,000 recommended official guidelines. min_pboot number 0 1 minimum proportion bootstrap samples must successfully fit (return likelihood) report confidence intervals.","code":""},{"path":"/reference/ssd_hp_bcanz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BCANZ Hazard Proportion — ssd_hp_bcanz","text":"tibble corresponding hazard concentrations.","code":""},{"path":[]},{"path":"/reference/ssd_hp_bcanz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BCANZ Hazard Proportion — ssd_hp_bcanz","text":"","code":"fits <- ssd_fit_bcanz(ssddata::ccme_boron) ssd_hp_bcanz(fits, nboot = 100) #> # A tibble: 1 × 11 #>   dist     conc   est    se   lcl   ucl    wt method     nboot pboot samples   #>   <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>      <dbl> <dbl> <I<list>> #> 1 average     1  3.90  2.84 0.393  10.9     1 parametric   100     1 <dbl [0]>"},{"path":"/reference/ssd_is_censored.html","id":null,"dir":"Reference","previous_headings":"","what":"Is Censored — ssd_is_censored","title":"Is Censored — ssd_is_censored","text":"Tests object censored data. Test data frame censored. Test fitdists object censored.","code":""},{"path":"/reference/ssd_is_censored.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is Censored — ssd_is_censored","text":"","code":"ssd_is_censored(x, ...)  # S3 method for data.frame ssd_is_censored(x, left = \"Conc\", right = left, ...)  # S3 method for fitdists ssd_is_censored(x, ...)"},{"path":"/reference/ssd_is_censored.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Is Censored — ssd_is_censored","text":"x object. ... Unused. left string column data concentrations. right string column data right concentration values.","code":""},{"path":"/reference/ssd_is_censored.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Is Censored — ssd_is_censored","text":"flag indicating whether object censored.","code":""},{"path":"/reference/ssd_is_censored.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Is Censored — ssd_is_censored","text":"","code":"ssd_is_censored(ssddata::ccme_boron) #> [1] FALSE ssd_is_censored(data.frame(Conc = 1, right = 2), right = \"right\") #> [1] TRUE  fits <- ssd_fit_dists(ssddata::ccme_boron) ssd_is_censored(fits) #> [1] FALSE"},{"path":"/reference/ssd_match_moments.html","id":null,"dir":"Reference","previous_headings":"","what":"Match Moments — ssd_match_moments","title":"Match Moments — ssd_match_moments","text":"Gets named list values produce moment values (meanlog sdlog) distribution term.","code":""},{"path":"/reference/ssd_match_moments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match Moments — ssd_match_moments","text":"","code":"ssd_match_moments(   dists = ssd_dists_bcanz(),   meanlog = 1,   sdlog = 1,   nsim = 1e+05 )"},{"path":"/reference/ssd_match_moments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Match Moments — ssd_match_moments","text":"dists character vector distribution names. meanlog mean log scale. sdlog standard deviation log scale. nsim positive whole number number simulations generate.","code":""},{"path":"/reference/ssd_match_moments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Match Moments — ssd_match_moments","text":"named list values produce moment values distribution term.","code":""},{"path":[]},{"path":"/reference/ssd_match_moments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Match Moments — ssd_match_moments","text":"","code":"moments <- ssd_match_moments() print(moments) #> $gamma #>    shape    scale  #> 1.479687 2.589063  #>  #> $lgumbel #> locationlog    scalelog  #>    0.534375    0.762500  #>  #> $llogis #> locationlog    scalelog  #>     0.96875     0.52500  #>  #> $lnorm #>   meanlog     sdlog  #> 0.9812500 0.9515625  #>  #> $lnorm_lnorm #>  meanlog1    sdlog1  meanlog2    sdlog2      pmix  #> 0.1409856 1.0659456 1.1849856 0.9799296 0.1487680  #>  #> $weibull #>    shape    scale  #> 1.352319 4.502075  #>  ssd_hc(moments) #> # A tibble: 6 × 9 #>   dist        proportion   est    se   lcl   ucl    wt nboot pboot #>   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <int> <dbl> #> 1 gamma             0.05 0.439    NA    NA    NA     1     0    NA #> 2 lgumbel           0.05 0.739    NA    NA    NA     1     0    NA #> 3 llogis            0.05 0.562    NA    NA    NA     1     0    NA #> 4 lnorm             0.05 0.558    NA    NA    NA     1     0    NA #> 5 lnorm_lnorm       0.05 0.469    NA    NA    NA     1     0    NA #> 6 weibull           0.05 0.501    NA    NA    NA     1     0    NA ssd_plot_cdf(moments)"},{"path":"/reference/ssd_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative Distribution Function — ssd_pburrIII3","title":"Cumulative Distribution Function — ssd_pburrIII3","text":"Cumulative Distribution Function","code":""},{"path":"/reference/ssd_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative Distribution Function — ssd_pburrIII3","text":"","code":"ssd_pburrIII3(   q,   shape1 = 1,   shape2 = 1,   scale = 1,   lower.tail = TRUE,   log.p = FALSE )  ssd_pgamma(q, shape = 1, scale = 1, lower.tail = TRUE, log.p = FALSE)  ssd_pgompertz(q, location = 1, shape = 1, lower.tail = TRUE, log.p = FALSE)  ssd_pinvpareto(q, shape = 3, scale = 1, lower.tail = TRUE, log.p = FALSE)  ssd_plgumbel(   q,   locationlog = 0,   scalelog = 1,   lower.tail = TRUE,   log.p = FALSE )  ssd_pllogis_llogis(   q,   locationlog1 = 0,   scalelog1 = 1,   locationlog2 = 1,   scalelog2 = 1,   pmix = 0.5,   lower.tail = TRUE,   log.p = FALSE )  ssd_pllogis(q, locationlog = 0, scalelog = 1, lower.tail = TRUE, log.p = FALSE)  ssd_plnorm_lnorm(   q,   meanlog1 = 0,   sdlog1 = 1,   meanlog2 = 1,   sdlog2 = 1,   pmix = 0.5,   lower.tail = TRUE,   log.p = FALSE )  ssd_plnorm(q, meanlog = 0, sdlog = 1, lower.tail = TRUE, log.p = FALSE)  ssd_pmulti(   q,   burrIII3.weight = 0,   burrIII3.shape1 = 1,   burrIII3.shape2 = 1,   burrIII3.scale = 1,   gamma.weight = 0,   gamma.shape = 1,   gamma.scale = 1,   gompertz.weight = 0,   gompertz.location = 1,   gompertz.shape = 1,   invpareto.weight = 0,   invpareto.shape = 3,   invpareto.scale = 1,   lgumbel.weight = 0,   lgumbel.locationlog = 0,   lgumbel.scalelog = 1,   llogis.weight = 0,   llogis.locationlog = 0,   llogis.scalelog = 1,   llogis_llogis.weight = 0,   llogis_llogis.locationlog1 = 0,   llogis_llogis.scalelog1 = 1,   llogis_llogis.locationlog2 = 1,   llogis_llogis.scalelog2 = 1,   llogis_llogis.pmix = 0.5,   lnorm.weight = 1,   lnorm.meanlog = 0,   lnorm.sdlog = 1,   lnorm_lnorm.weight = 0,   lnorm_lnorm.meanlog1 = 0,   lnorm_lnorm.sdlog1 = 1,   lnorm_lnorm.meanlog2 = 1,   lnorm_lnorm.sdlog2 = 1,   lnorm_lnorm.pmix = 0.5,   weibull.weight = 0,   weibull.shape = 1,   weibull.scale = 1,   lower.tail = TRUE,   log.p = FALSE )  ssd_pweibull(q, shape = 1, scale = 1, lower.tail = TRUE, log.p = FALSE)"},{"path":"/reference/ssd_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative Distribution Function — ssd_pburrIII3","text":"q vector quantiles. shape1 shape1 parameter. shape2 shape2 parameter. scale scale parameter. lower.tail logical; TRUE (default), probabilities P[X <= x], otherwise, P[X > x]. log.p logical; TRUE, probabilities p given log(p). shape shape parameter. location location parameter. locationlog location log scale parameter. scalelog scale log scale parameter. locationlog1 locationlog1 parameter. scalelog1 scalelog1 parameter. locationlog2 locationlog2 parameter. scalelog2 scalelog2 parameter. pmix Proportion mixture parameter. meanlog1 mean log scale parameter. sdlog1 standard deviation log scale parameter. meanlog2 mean log scale parameter. sdlog2 standard deviation log scale parameter. meanlog mean log scale parameter. sdlog standard deviation log scale parameter. burrIII3.weight weight parameter Burr III distribution. burrIII3.shape1 shape1 parameter Burr III distribution. burrIII3.shape2 shape2 parameter Burr III distribution. burrIII3.scale scale parameter Burr III distribution. gamma.weight weight parameter gamma distribution. gamma.shape shape parameter gamma distribution. gamma.scale scale parameter gamma distribution. gompertz.weight weight parameter Gompertz distribution. gompertz.location location parameter Gompertz distribution. gompertz.shape shape parameter Gompertz distribution. invpareto.weight weight parameter inverse Pareto distribution. invpareto.shape shape parameter inverse Pareto distribution. invpareto.scale scale parameter inverse Pareto distribution. lgumbel.weight weight parameter log-Gumbel distribution. lgumbel.locationlog location parameter log-Gumbel distribution. lgumbel.scalelog scale parameter log-Gumbel distribution. llogis.weight weight parameter log-logistic distribution. llogis.locationlog location parameter log-logistic distribution. llogis.scalelog scale parameter log-logistic distribution. llogis_llogis.weight weight parameter log-logistic log-logistic mixture distribution. llogis_llogis.locationlog1 locationlog1 parameter log-logistic log-logistic mixture distribution. llogis_llogis.scalelog1 scalelog1 parameter log-logistic log-logistic mixture distribution. llogis_llogis.locationlog2 locationlog2 parameter log-logistic log-logistic mixture distribution. llogis_llogis.scalelog2 scalelog2 parameter log-logistic log-logistic mixture distribution. llogis_llogis.pmix pmix parameter log-logistic log-logistic mixture distribution. lnorm.weight weight parameter log-normal distribution. lnorm.meanlog meanlog parameter log-normal distribution. lnorm.sdlog sdlog parameter log-normal distribution. lnorm_lnorm.weight weight parameter log-normal log-normal mixture distribution. lnorm_lnorm.meanlog1 meanlog1 parameter log-normal log-normal mixture distribution. lnorm_lnorm.sdlog1 sdlog1 parameter log-normal log-normal mixture distribution. lnorm_lnorm.meanlog2 meanlog2 parameter log-normal log-normal mixture distribution. lnorm_lnorm.sdlog2 sdlog2 parameter log-normal log-normal mixture distribution. lnorm_lnorm.pmix pmix parameter log-normal log-normal mixture distribution. weibull.weight weight parameter Weibull distribution. weibull.shape shape parameter Weibull distribution. weibull.scale scale parameter Weibull distribution.","code":""},{"path":"/reference/ssd_p.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Cumulative Distribution Function — ssd_pburrIII3","text":"ssd_pburrIII3(): Cumulative Distribution Function BurrIII Distribution ssd_pgamma(): Cumulative Distribution Function Gamma Distribution ssd_pgompertz(): Cumulative Distribution Function Gompertz Distribution ssd_pinvpareto(): Cumulative Distribution Function Inverse Pareto Distribution ssd_plgumbel(): Cumulative Distribution Function Log-Gumbel Distribution ssd_pllogis_llogis(): Cumulative Distribution Function Log-Logistic/Log-Logistic Mixture Distribution ssd_pllogis(): Cumulative Distribution Function Log-Logistic Distribution ssd_plnorm_lnorm(): Cumulative Distribution Function Log-Normal/Log-Normal Mixture Distribution ssd_plnorm(): Cumulative Distribution Function Log-Normal Distribution ssd_pmulti(): Cumulative Distribution Function Multiple Distributions ssd_pweibull(): Cumulative Distribution Function Weibull Distribution","code":""},{"path":[]},{"path":"/reference/ssd_p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative Distribution Function — ssd_pburrIII3","text":"","code":"ssd_pburrIII3(1) #> [1] 0.5  ssd_pgamma(1) #> [1] 0.6321206  ssd_pgompertz(1) #> [1] 0.8206259  ssd_pinvpareto(1) #> [1] 1  ssd_plgumbel(1) #> [1] 0.3678794  ssd_pllogis_llogis(1) #> [1] 0.3844707  ssd_pllogis(1) #> [1] 0.5  ssd_plnorm_lnorm(1) #> [1] 0.3293276  ssd_plnorm(1) #> [1] 0.5  # multi  ssd_pmulti(1) #> [1] 0.5  ssd_pweibull(1) #> [1] 0.6321206"},{"path":"/reference/ssd_pal.html","id":null,"dir":"Reference","previous_headings":"","what":"Color-blind Palette for SSD Plots — ssd_pal","title":"Color-blind Palette for SSD Plots — ssd_pal","text":"Color-blind Palette SSD Plots","code":""},{"path":"/reference/ssd_pal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Color-blind Palette for SSD Plots — ssd_pal","text":"","code":"ssd_pal()"},{"path":"/reference/ssd_pal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Color-blind Palette for SSD Plots — ssd_pal","text":"character vector color blind palette 8 colors.","code":""},{"path":[]},{"path":"/reference/ssd_pal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Color-blind Palette for SSD Plots — ssd_pal","text":"","code":"ssd_pal() #> function (n)  #> { #>     n_values <- length(values) #>     if (n > n_values) { #>         cli::cli_warn(\"This manual palette can handle a maximum of {n_values} values. You have supplied {n}\") #>     } #>     unname(values[seq_len(n)]) #> } #> <bytecode: 0x55952bcaf148> #> <environment: 0x55952ba0c4c0> #> attr(,\"max_n\") #> [1] 8"},{"path":"/reference/ssd_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Species Sensitivity Data and Distributions — ssd_plot","title":"Plot Species Sensitivity Data and Distributions — ssd_plot","text":"Plots species sensitivity data distributions.","code":""},{"path":"/reference/ssd_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Species Sensitivity Data and Distributions — ssd_plot","text":"","code":"ssd_plot(   data,   pred,   left = \"Conc\",   right = left,   label = NULL,   shape = NULL,   color = NULL,   size = 2.5,   linetype = NULL,   linecolor = NULL,   xlab = \"Concentration\",   ylab = \"Species Affected\",   ci = TRUE,   ribbon = TRUE,   hc = 0.05,   shift_x = 3,   add_x = 0,   bounds = c(left = 1, right = 1),   trans = \"log10\",   xbreaks = waiver() )"},{"path":"/reference/ssd_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Species Sensitivity Data and Distributions — ssd_plot","text":"data data frame. pred data frame predictions. left string column data concentrations. right string column data right concentration values. label string column data labels. shape string column data shape aesthetic. color string column data color aesthetic. size number size labels. linetype string column pred use linetype. linecolor string column pred use line color. xlab string x-axis label. ylab string x-axis label. ci flag specifying whether estimate confidence intervals (bootstrapping). ribbon flag indicating whether plot confidence interval grey ribbon opposed green solid lines. hc value 0 1 indicating proportion hazard concentration (NULL). shift_x value multiply label x values (adding add_x). add_x value add label x values (multiplying shift_x). bounds named non-negative numeric vector left right bounds uncensored missing (0 Inf) data terms orders magnitude relative extremes non-missing values. trans string transformation use default \"log10\". xbreaks x-axis breaks one : NULL breaks waiver() default breaks numeric vector positions","code":""},{"path":[]},{"path":"/reference/ssd_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Species Sensitivity Data and Distributions — ssd_plot","text":"","code":"ssd_plot(ssddata::ccme_boron, boron_pred, label = \"Species\", shape = \"Group\")"},{"path":"/reference/ssd_plot_cdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Cumulative Distribution Function (CDF) — ssd_plot_cdf","title":"Plot Cumulative Distribution Function (CDF) — ssd_plot_cdf","text":"Generic function plots cumulative distribution function (CDF).","code":""},{"path":"/reference/ssd_plot_cdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Cumulative Distribution Function (CDF) — ssd_plot_cdf","text":"","code":"ssd_plot_cdf(x, ...)  # S3 method for fitdists ssd_plot_cdf(x, average = FALSE, delta = 9.21, ...)  # S3 method for list ssd_plot_cdf(x, ...)"},{"path":"/reference/ssd_plot_cdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Cumulative Distribution Function (CDF) — ssd_plot_cdf","text":"x object. ... Additional arguments passed ssd_plot(). average flag specifying whether provide model averaged values opposed value distribution NA provides model averaged individual values. delta non-negative number specifying maximum absolute AIC difference cutoff. Distributions absolute AIC difference greater delta excluded calculations.","code":""},{"path":"/reference/ssd_plot_cdf.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Plot Cumulative Distribution Function (CDF) — ssd_plot_cdf","text":"ssd_plot_cdf(fitdists): Plot CDF fitdists object ssd_plot_cdf(list): Plot CDF named list distributional parameter values","code":""},{"path":[]},{"path":"/reference/ssd_plot_cdf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Cumulative Distribution Function (CDF) — ssd_plot_cdf","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) ssd_plot_cdf(fits)  ssd_plot_cdf(fits, average = NA)   ssd_plot_cdf(list(   llogis = c(locationlog = 2, scalelog = 1),   lnorm = c(meanlog = 2, sdlog = 2) ))"},{"path":"/reference/ssd_plot_cf.html","id":null,"dir":"Reference","previous_headings":"","what":"Cullen and Frey Plot  — ssd_plot_cf","title":"Cullen and Frey Plot  — ssd_plot_cf","text":"Plots Cullen Frey graph skewness kurtosis non-censored data.","code":""},{"path":"/reference/ssd_plot_cf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cullen and Frey Plot  — ssd_plot_cf","text":"","code":"ssd_plot_cf(data, left = \"Conc\")"},{"path":"/reference/ssd_plot_cf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cullen and Frey Plot  — ssd_plot_cf","text":"data data frame. left string column data concentrations.","code":""},{"path":"/reference/ssd_plot_cf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cullen and Frey Plot  — ssd_plot_cf","text":"Soft deprecated direct call fitdistrplus::descdist().","code":""},{"path":"/reference/ssd_plot_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Species Sensitivity Data — ssd_plot_data","title":"Plot Species Sensitivity Data — ssd_plot_data","text":"Plots species sensitivity data.","code":""},{"path":"/reference/ssd_plot_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Species Sensitivity Data — ssd_plot_data","text":"","code":"ssd_plot_data(   data,   left = \"Conc\",   right = left,   label = NULL,   shape = NULL,   color = NULL,   size = 2.5,   xlab = \"Concentration\",   ylab = \"Species Affected\",   shift_x = 3,   add_x = 0,   bounds = c(left = 1, right = 1),   trans = \"log10\",   xbreaks = waiver() )"},{"path":"/reference/ssd_plot_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Species Sensitivity Data — ssd_plot_data","text":"data data frame. left string column data concentrations. right string column data right concentration values. label string column data labels. shape string column data shape aesthetic. color string column data color aesthetic. size number size labels. xlab string x-axis label. ylab string x-axis label. shift_x value multiply label x values (adding add_x). add_x value add label x values (multiplying shift_x). bounds named non-negative numeric vector left right bounds uncensored missing (0 Inf) data terms orders magnitude relative extremes non-missing values. trans string transformation use default \"log10\". xbreaks x-axis breaks one : NULL breaks waiver() default breaks numeric vector positions","code":""},{"path":[]},{"path":"/reference/ssd_plot_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Species Sensitivity Data — ssd_plot_data","text":"","code":"ssd_plot_data(ssddata::ccme_boron, label = \"Species\", shape = \"Group\")"},{"path":"/reference/ssd_q.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile Function — ssd_qburrIII3","title":"Quantile Function — ssd_qburrIII3","text":"Quantile Function","code":""},{"path":"/reference/ssd_q.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile Function — ssd_qburrIII3","text":"","code":"ssd_qburrIII3(   p,   shape1 = 1,   shape2 = 1,   scale = 1,   lower.tail = TRUE,   log.p = FALSE )  ssd_qgamma(p, shape = 1, scale = 1, lower.tail = TRUE, log.p = FALSE)  ssd_qgompertz(p, location = 1, shape = 1, lower.tail = TRUE, log.p = FALSE)  ssd_qinvpareto(p, shape = 3, scale = 1, lower.tail = TRUE, log.p = FALSE)  ssd_qlgumbel(   p,   locationlog = 0,   scalelog = 1,   lower.tail = TRUE,   log.p = FALSE )  ssd_qllogis_llogis(   p,   locationlog1 = 0,   scalelog1 = 1,   locationlog2 = 1,   scalelog2 = 1,   pmix = 0.5,   lower.tail = TRUE,   log.p = FALSE )  ssd_qllogis(p, locationlog = 0, scalelog = 1, lower.tail = TRUE, log.p = FALSE)  ssd_qlnorm_lnorm(   p,   meanlog1 = 0,   sdlog1 = 1,   meanlog2 = 1,   sdlog2 = 1,   pmix = 0.5,   lower.tail = TRUE,   log.p = FALSE )  ssd_qlnorm(p, meanlog = 0, sdlog = 1, lower.tail = TRUE, log.p = FALSE)  ssd_qmulti(   p,   burrIII3.weight = 0,   burrIII3.shape1 = 1,   burrIII3.shape2 = 1,   burrIII3.scale = 1,   gamma.weight = 0,   gamma.shape = 1,   gamma.scale = 1,   gompertz.weight = 0,   gompertz.location = 1,   gompertz.shape = 1,   invpareto.weight = 0,   invpareto.shape = 3,   invpareto.scale = 1,   lgumbel.weight = 0,   lgumbel.locationlog = 0,   lgumbel.scalelog = 1,   llogis.weight = 0,   llogis.locationlog = 0,   llogis.scalelog = 1,   llogis_llogis.weight = 0,   llogis_llogis.locationlog1 = 0,   llogis_llogis.scalelog1 = 1,   llogis_llogis.locationlog2 = 1,   llogis_llogis.scalelog2 = 1,   llogis_llogis.pmix = 0.5,   lnorm.weight = 1,   lnorm.meanlog = 0,   lnorm.sdlog = 1,   lnorm_lnorm.weight = 0,   lnorm_lnorm.meanlog1 = 0,   lnorm_lnorm.sdlog1 = 1,   lnorm_lnorm.meanlog2 = 1,   lnorm_lnorm.sdlog2 = 1,   lnorm_lnorm.pmix = 0.5,   weibull.weight = 0,   weibull.shape = 1,   weibull.scale = 1,   lower.tail = TRUE,   log.p = FALSE )  ssd_qweibull(p, shape = 1, scale = 1, lower.tail = TRUE, log.p = FALSE)"},{"path":"/reference/ssd_q.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile Function — ssd_qburrIII3","text":"p vector probabilities. shape1 shape1 parameter. shape2 shape2 parameter. scale scale parameter. lower.tail logical; TRUE (default), probabilities P[X <= x], otherwise, P[X > x]. log.p logical; TRUE, probabilities p given log(p). shape shape parameter. location location parameter. locationlog location log scale parameter. scalelog scale log scale parameter. locationlog1 locationlog1 parameter. scalelog1 scalelog1 parameter. locationlog2 locationlog2 parameter. scalelog2 scalelog2 parameter. pmix Proportion mixture parameter. meanlog1 mean log scale parameter. sdlog1 standard deviation log scale parameter. meanlog2 mean log scale parameter. sdlog2 standard deviation log scale parameter. meanlog mean log scale parameter. sdlog standard deviation log scale parameter. burrIII3.weight weight parameter Burr III distribution. burrIII3.shape1 shape1 parameter Burr III distribution. burrIII3.shape2 shape2 parameter Burr III distribution. burrIII3.scale scale parameter Burr III distribution. gamma.weight weight parameter gamma distribution. gamma.shape shape parameter gamma distribution. gamma.scale scale parameter gamma distribution. gompertz.weight weight parameter Gompertz distribution. gompertz.location location parameter Gompertz distribution. gompertz.shape shape parameter Gompertz distribution. invpareto.weight weight parameter inverse Pareto distribution. invpareto.shape shape parameter inverse Pareto distribution. invpareto.scale scale parameter inverse Pareto distribution. lgumbel.weight weight parameter log-Gumbel distribution. lgumbel.locationlog location parameter log-Gumbel distribution. lgumbel.scalelog scale parameter log-Gumbel distribution. llogis.weight weight parameter log-logistic distribution. llogis.locationlog location parameter log-logistic distribution. llogis.scalelog scale parameter log-logistic distribution. llogis_llogis.weight weight parameter log-logistic log-logistic mixture distribution. llogis_llogis.locationlog1 locationlog1 parameter log-logistic log-logistic mixture distribution. llogis_llogis.scalelog1 scalelog1 parameter log-logistic log-logistic mixture distribution. llogis_llogis.locationlog2 locationlog2 parameter log-logistic log-logistic mixture distribution. llogis_llogis.scalelog2 scalelog2 parameter log-logistic log-logistic mixture distribution. llogis_llogis.pmix pmix parameter log-logistic log-logistic mixture distribution. lnorm.weight weight parameter log-normal distribution. lnorm.meanlog meanlog parameter log-normal distribution. lnorm.sdlog sdlog parameter log-normal distribution. lnorm_lnorm.weight weight parameter log-normal log-normal mixture distribution. lnorm_lnorm.meanlog1 meanlog1 parameter log-normal log-normal mixture distribution. lnorm_lnorm.sdlog1 sdlog1 parameter log-normal log-normal mixture distribution. lnorm_lnorm.meanlog2 meanlog2 parameter log-normal log-normal mixture distribution. lnorm_lnorm.sdlog2 sdlog2 parameter log-normal log-normal mixture distribution. lnorm_lnorm.pmix pmix parameter log-normal log-normal mixture distribution. weibull.weight weight parameter Weibull distribution. weibull.shape shape parameter Weibull distribution. weibull.scale scale parameter Weibull distribution.","code":""},{"path":"/reference/ssd_q.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Quantile Function — ssd_qburrIII3","text":"ssd_qburrIII3(): Quantile Function BurrIII Distribution ssd_qgamma(): Quantile Function Gamma Distribution ssd_qgompertz(): Quantile Function Gompertz Distribution ssd_qinvpareto(): Quantile Function Inverse Pareto Distribution ssd_qlgumbel(): Quantile Function Log-Gumbel Distribution ssd_qllogis_llogis(): Cumulative Distribution Function Log-Logistic/Log-Logistic Mixture Distribution ssd_qllogis(): Cumulative Distribution Function Log-Logistic Distribution ssd_qlnorm_lnorm(): Cumulative Distribution Function Log-Normal/Log-Normal Mixture Distribution ssd_qlnorm(): Cumulative Distribution Function Log-Normal Distribution ssd_qmulti(): Quantile Function Multiple Distributions ssd_qweibull(): Cumulative Distribution Function Weibull Distribution","code":""},{"path":[]},{"path":"/reference/ssd_q.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile Function — ssd_qburrIII3","text":"","code":"ssd_qburrIII3(0.5) #> [1] 1  ssd_qgamma(0.5) #> [1] 0.6931472  ssd_qgompertz(0.5) #> [1] 0.526589  ssd_qinvpareto(0.5) #> [1] 0.7937005  ssd_qlgumbel(0.5) #> [1] 1.442695  ssd_qllogis_llogis(0.5) #> [1] 1.648721  ssd_qllogis(0.5) #> [1] 1  ssd_qlnorm_lnorm(0.5) #> [1] 1.648721  ssd_qlnorm(0.5) #> [1] 1  # multi  ssd_qmulti(0.5) #> [1] 1  ssd_qweibull(0.5) #> [1] 0.6931472"},{"path":"/reference/ssd_r.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Number Generation — ssd_rburrIII3","title":"Random Number Generation — ssd_rburrIII3","text":"Random Number Generation","code":""},{"path":"/reference/ssd_r.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Number Generation — ssd_rburrIII3","text":"","code":"ssd_rburrIII3(n, shape1 = 1, shape2 = 1, scale = 1, chk = TRUE)  ssd_rgamma(n, shape = 1, scale = 1, chk = TRUE)  ssd_rgompertz(n, location = 1, shape = 1, chk = TRUE)  ssd_rinvpareto(n, shape = 3, scale = 1, chk = TRUE)  ssd_rlgumbel(n, locationlog = 0, scalelog = 1, chk = TRUE)  ssd_rllogis_llogis(   n,   locationlog1 = 0,   scalelog1 = 1,   locationlog2 = 1,   scalelog2 = 1,   pmix = 0.5,   chk = TRUE )  ssd_rllogis(n, locationlog = 0, scalelog = 1, chk = TRUE)  ssd_rlnorm_lnorm(   n,   meanlog1 = 0,   sdlog1 = 1,   meanlog2 = 1,   sdlog2 = 1,   pmix = 0.5,   chk = TRUE )  ssd_rlnorm(n, meanlog = 0, sdlog = 1, chk = TRUE)  ssd_rmulti(   n,   burrIII3.weight = 0,   burrIII3.shape1 = 1,   burrIII3.shape2 = 1,   burrIII3.scale = 1,   gamma.weight = 0,   gamma.shape = 1,   gamma.scale = 1,   gompertz.weight = 0,   gompertz.location = 1,   gompertz.shape = 1,   invpareto.weight = 0,   invpareto.shape = 3,   invpareto.scale = 1,   lgumbel.weight = 0,   lgumbel.locationlog = 0,   lgumbel.scalelog = 1,   llogis.weight = 0,   llogis.locationlog = 0,   llogis.scalelog = 1,   llogis_llogis.weight = 0,   llogis_llogis.locationlog1 = 0,   llogis_llogis.scalelog1 = 1,   llogis_llogis.locationlog2 = 1,   llogis_llogis.scalelog2 = 1,   llogis_llogis.pmix = 0.5,   lnorm.weight = 1,   lnorm.meanlog = 0,   lnorm.sdlog = 1,   lnorm_lnorm.weight = 0,   lnorm_lnorm.meanlog1 = 0,   lnorm_lnorm.sdlog1 = 1,   lnorm_lnorm.meanlog2 = 1,   lnorm_lnorm.sdlog2 = 1,   lnorm_lnorm.pmix = 0.5,   weibull.weight = 0,   weibull.shape = 1,   weibull.scale = 1,   chk = TRUE )  ssd_rweibull(n, shape = 1, scale = 1, chk = TRUE)"},{"path":"/reference/ssd_r.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Number Generation — ssd_rburrIII3","text":"n positive number observations. shape1 shape1 parameter. shape2 shape2 parameter. scale scale parameter. chk flag specifying whether check arguments. shape shape parameter. location location parameter. locationlog location log scale parameter. scalelog scale log scale parameter. locationlog1 locationlog1 parameter. scalelog1 scalelog1 parameter. locationlog2 locationlog2 parameter. scalelog2 scalelog2 parameter. pmix Proportion mixture parameter. meanlog1 mean log scale parameter. sdlog1 standard deviation log scale parameter. meanlog2 mean log scale parameter. sdlog2 standard deviation log scale parameter. meanlog mean log scale parameter. sdlog standard deviation log scale parameter. burrIII3.weight weight parameter Burr III distribution. burrIII3.shape1 shape1 parameter Burr III distribution. burrIII3.shape2 shape2 parameter Burr III distribution. burrIII3.scale scale parameter Burr III distribution. gamma.weight weight parameter gamma distribution. gamma.shape shape parameter gamma distribution. gamma.scale scale parameter gamma distribution. gompertz.weight weight parameter Gompertz distribution. gompertz.location location parameter Gompertz distribution. gompertz.shape shape parameter Gompertz distribution. invpareto.weight weight parameter inverse Pareto distribution. invpareto.shape shape parameter inverse Pareto distribution. invpareto.scale scale parameter inverse Pareto distribution. lgumbel.weight weight parameter log-Gumbel distribution. lgumbel.locationlog location parameter log-Gumbel distribution. lgumbel.scalelog scale parameter log-Gumbel distribution. llogis.weight weight parameter log-logistic distribution. llogis.locationlog location parameter log-logistic distribution. llogis.scalelog scale parameter log-logistic distribution. llogis_llogis.weight weight parameter log-logistic log-logistic mixture distribution. llogis_llogis.locationlog1 locationlog1 parameter log-logistic log-logistic mixture distribution. llogis_llogis.scalelog1 scalelog1 parameter log-logistic log-logistic mixture distribution. llogis_llogis.locationlog2 locationlog2 parameter log-logistic log-logistic mixture distribution. llogis_llogis.scalelog2 scalelog2 parameter log-logistic log-logistic mixture distribution. llogis_llogis.pmix pmix parameter log-logistic log-logistic mixture distribution. lnorm.weight weight parameter log-normal distribution. lnorm.meanlog meanlog parameter log-normal distribution. lnorm.sdlog sdlog parameter log-normal distribution. lnorm_lnorm.weight weight parameter log-normal log-normal mixture distribution. lnorm_lnorm.meanlog1 meanlog1 parameter log-normal log-normal mixture distribution. lnorm_lnorm.sdlog1 sdlog1 parameter log-normal log-normal mixture distribution. lnorm_lnorm.meanlog2 meanlog2 parameter log-normal log-normal mixture distribution. lnorm_lnorm.sdlog2 sdlog2 parameter log-normal log-normal mixture distribution. lnorm_lnorm.pmix pmix parameter log-normal log-normal mixture distribution. weibull.weight weight parameter Weibull distribution. weibull.shape shape parameter Weibull distribution. weibull.scale scale parameter Weibull distribution.","code":""},{"path":"/reference/ssd_r.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Random Number Generation — ssd_rburrIII3","text":"ssd_rburrIII3(): Random Generation BurrIII Distribution ssd_rgamma(): Random Generation Gamma Distribution ssd_rgompertz(): Random Generation Gompertz Distribution ssd_rinvpareto(): Random Generation Inverse Pareto Distribution ssd_rlgumbel(): Random Generation log-Gumbel Distribution ssd_rllogis_llogis(): Random Generation Log-Logistic/Log-Logistic Mixture Distribution ssd_rllogis(): Random Generation Log-Logistic Distribution ssd_rlnorm_lnorm(): Random Generation Log-Normal/Log-Normal Mixture Distribution ssd_rlnorm(): Random Generation Log-Normal Distribution ssd_rmulti(): Random Generation Multiple Distributions ssd_rweibull(): Random Generation Weibull Distribution","code":""},{"path":[]},{"path":"/reference/ssd_r.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Number Generation — ssd_rburrIII3","text":"","code":"set.seed(50) hist(ssd_rburrIII3(10000), breaks = 1000)   set.seed(50) hist(ssd_rgamma(10000), breaks = 1000)   set.seed(50) hist(ssd_rgompertz(10000), breaks = 1000)   set.seed(50) hist(ssd_rinvpareto(10000), breaks = 1000)   set.seed(50) hist(ssd_rlgumbel(10000), breaks = 1000)   set.seed(50) hist(ssd_rllogis_llogis(10000), breaks = 1000)   set.seed(50) hist(ssd_rllogis(10000), breaks = 1000)   set.seed(50) hist(ssd_rlnorm_lnorm(10000), breaks = 1000)   set.seed(50) hist(ssd_rlnorm(10000), breaks = 1000)   # multi  set.seed(50) hist(ssd_rmulti(1000), breaks = 100)   set.seed(50) hist(ssd_rweibull(10000), breaks = 1000)"},{"path":"/reference/ssd_sort_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort Species Sensitivity Data — ssd_sort_data","title":"Sort Species Sensitivity Data — ssd_sort_data","text":"Sorts Species Sensitivity Data empirical cumulative density (ECD).","code":""},{"path":"/reference/ssd_sort_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort Species Sensitivity Data — ssd_sort_data","text":"","code":"ssd_sort_data(data, left = \"Conc\", right = left)"},{"path":"/reference/ssd_sort_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sort Species Sensitivity Data — ssd_sort_data","text":"data data frame. left string column data concentrations. right string column data right concentration values.","code":""},{"path":"/reference/ssd_sort_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sort Species Sensitivity Data — ssd_sort_data","text":"data sorted empirical cumulative density.","code":""},{"path":"/reference/ssd_sort_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sort Species Sensitivity Data — ssd_sort_data","text":"Useful sorting data using geom_ssdpoint() geom_ssdsegment() construct plots censored data stat = identity ensure order various components.","code":""},{"path":[]},{"path":"/reference/ssd_sort_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sort Species Sensitivity Data — ssd_sort_data","text":"","code":"ssd_sort_data(ssddata::ccme_boron) #> # A tibble: 28 × 5 #>    Chemical Species                Conc Group        Units #>    <chr>    <chr>                 <dbl> <fct>        <chr> #>  1 Boron    Elodea canadensis       1   Plant        mg/L  #>  2 Boron    Spirodella polyrrhiza   1.8 Plant        mg/L  #>  3 Boron    Chlorella pyrenoidosa   2   Plant        mg/L  #>  4 Boron    Oncorhynchus mykiss     2.1 Fish         mg/L  #>  5 Boron    Ictalurus punctatus     2.4 Fish         mg/L  #>  6 Boron    Phragmites australis    4   Plant        mg/L  #>  7 Boron    Micropterus salmoides   4.1 Fish         mg/L  #>  8 Boron    Chlorella vulgaris      5.2 Plant        mg/L  #>  9 Boron    Daphnia magna           6   Invertebrate mg/L  #> 10 Boron    Brachydanio rerio      10   Fish         mg/L  #> # ℹ 18 more rows"},{"path":"/reference/ssd_wqg_bc.html","id":null,"dir":"Reference","previous_headings":"","what":"Water Quality Guideline for British Columbia — ssd_wqg_bc","title":"Water Quality Guideline for British Columbia — ssd_wqg_bc","text":"Calculates 5% Hazard Concentration British Columbia rescaling data based log-logistic, log-normal gamma distributions using parametric bootstrap AICc model averaging.","code":""},{"path":"/reference/ssd_wqg_bc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Water Quality Guideline for British Columbia — ssd_wqg_bc","text":"","code":"ssd_wqg_bc(data, left = \"Conc\")"},{"path":"/reference/ssd_wqg_bc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Water Quality Guideline for British Columbia — ssd_wqg_bc","text":"data data frame. left string column data concentrations.","code":""},{"path":"/reference/ssd_wqg_bc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Water Quality Guideline for British Columbia — ssd_wqg_bc","text":"tibble 5% hazard concentration 95% confidence intervals.","code":""},{"path":"/reference/ssd_wqg_bc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Water Quality Guideline for British Columbia — ssd_wqg_bc","text":"Returns tibble model averaged 5% hazard concentration standard errors, 95% lower upper confidence limits number bootstrap samples well proportion bootstrap samples successfully returned likelihood (convergence bootstrap sample required).","code":""},{"path":[]},{"path":"/reference/ssd_wqg_bc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Water Quality Guideline for British Columbia — ssd_wqg_bc","text":"","code":"if (FALSE) { ssd_wqg_bc(ssddata::ccme_boron) }"},{"path":"/reference/ssd_wqg_burrlioz.html","id":null,"dir":"Reference","previous_headings":"","what":"Water Quality Guideline for Burrlioz — ssd_wqg_burrlioz","title":"Water Quality Guideline for Burrlioz — ssd_wqg_burrlioz","text":"Calculates 5% Hazard Concentration (rescaling data) using approach Burrlioz based 10,000 non-parametric bootstrap samples.","code":""},{"path":"/reference/ssd_wqg_burrlioz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Water Quality Guideline for Burrlioz — ssd_wqg_burrlioz","text":"","code":"ssd_wqg_burrlioz(data, left = \"Conc\")"},{"path":"/reference/ssd_wqg_burrlioz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Water Quality Guideline for Burrlioz — ssd_wqg_burrlioz","text":"data data frame. left string column data concentrations.","code":""},{"path":"/reference/ssd_wqg_burrlioz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Water Quality Guideline for Burrlioz — ssd_wqg_burrlioz","text":"tibble 5% hazard concentration 95% confidence intervals.","code":""},{"path":"/reference/ssd_wqg_burrlioz.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Water Quality Guideline for Burrlioz — ssd_wqg_burrlioz","text":"Returns tibble model averaged 5% hazard concentration standard errors, 95% lower upper confidence limits number bootstrap samples well proportion bootstrap samples successfully returned likelihood (convergence bootstrap sample required).","code":""},{"path":[]},{"path":"/reference/ssd_wqg_burrlioz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Water Quality Guideline for Burrlioz — ssd_wqg_burrlioz","text":"","code":"if (FALSE) { ssd_wqg_burrlioz(ssddata::ccme_boron) }"},{"path":"/reference/ssdtools-ggproto.html","id":null,"dir":"Reference","previous_headings":"","what":"ggproto Classes for Plotting Species Sensitivity Data and Distributions — ssdtools-ggproto","title":"ggproto Classes for Plotting Species Sensitivity Data and Distributions — ssdtools-ggproto","text":"ggproto Classes Plotting Species Sensitivity Data Distributions","code":""},{"path":"/reference/ssdtools-ggproto.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ggproto Classes for Plotting Species Sensitivity Data and Distributions — ssdtools-ggproto","text":"","code":"StatSsdpoint  StatSsdsegment  GeomSsdpoint  GeomSsdsegment  GeomHcintersect  GeomXribbon"},{"path":"/reference/ssdtools-ggproto.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"ggproto Classes for Plotting Species Sensitivity Data and Distributions — ssdtools-ggproto","text":"object class StatSsdpoint (inherits Stat, ggproto, gg) length 4. object class StatSsdsegment (inherits Stat, ggproto, gg) length 4. object class GeomSsdpoint (inherits GeomPoint, Geom, ggproto, gg) length 1. object class GeomSsdsegment (inherits GeomSegment, Geom, ggproto, gg) length 1. object class GeomHcintersect (inherits Geom, ggproto, gg) length 5. object class GeomXribbon (inherits Geom, ggproto, gg) length 6.","code":""},{"path":[]},{"path":"/reference/ssdtools-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ssdtools: Species Sensitivity Distributions — ssdtools-package","title":"ssdtools: Species Sensitivity Distributions — ssdtools-package","text":"Species sensitivity distributions cumulative probability distributions fitted toxicity concentrations different species described Posthuma et al.(2001) <isbn:9781566705783>. ssdtools package uses Maximum Likelihood fit distributions gamma, log-logistic, log-normal log-normal log-normal mixture. Multiple distributions can averaged using Akaike Information Criteria. Confidence intervals hazard concentrations proportions produced parametric bootstrapping.","code":""},{"path":[]},{"path":"/reference/ssdtools-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ssdtools: Species Sensitivity Distributions — ssdtools-package","text":"Maintainer: Joe Thorley joe@poissonconsulting.ca (ORCID) Authors: Rebecca Fisher R.Fisher@aims.gov.au David Fox david.fox@environmetrics.net.au Carl Schwarz contributors: Angeline Tillmanns [contributor] Seb Dalgarno seb@poissonconsulting.ca (ORCID) [contributor] Kathleen McTavish [contributor] Heather Thompson [contributor] Doug Spry [contributor] Rick van Dam [contributor] Graham Batley [contributor] Yulia Cuthbertson [contributor] Tony Bigwood [contributor] Michael Antenucci [contributor] Ali Azizishirazi [contributor] Nadine Hussein nadine@poissonconsulting.ca (ORCID) [contributor] Sarah Lyons sarah@poissonconsulting.ca (ORCID) [contributor] Stephanie Hazlitt [contributor] Hadley Wickham [contributor] Sergio Ibarra Espinosa [contributor] Andy Teucher [contributor] Emilie Doussantousse [contributor] Nan-Hung Hsieh [contributor] Province British Columbia [funder, copyright holder] Environment Climate Change Canada [funder, copyright holder] Australian Government Department Climate Change, Energy, Environment Water [funder, copyright holder]","code":""},{"path":"/reference/stat_ssd.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Species Sensitivity Data  — stat_ssd","title":"Plot Species Sensitivity Data  — stat_ssd","text":"Uses empirical cumulative density/distribution visualize species sensitivity data.","code":""},{"path":"/reference/stat_ssd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Species Sensitivity Data  — stat_ssd","text":"","code":"stat_ssd(   mapping = NULL,   data = NULL,   geom = \"point\",   position = \"identity\",   ...,   na.rm = FALSE,   show.legend = NA,   inherit.aes = TRUE )"},{"path":"/reference/stat_ssd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Species Sensitivity Data  — stat_ssd","text":"mapping Set aesthetic mappings created aes(). specified inherit.aes = TRUE (default), combined default mapping top level plot. must supply mapping plot mapping. data data displayed layer. three options: NULL, default, data inherited plot data specified call ggplot(). data.frame, object, override plot data. objects fortified produce data frame. See fortify() variables created. function called single argument, plot data. return value must data.frame, used layer data. function can created formula (e.g. ~ head(.x, 10)). geom geometric object use display data layer. using stat_*() function construct layer, geom argument can used override default coupling stats geoms. geom argument accepts following: Geom ggproto subclass, example GeomPoint. string naming geom. give geom string, strip function name geom_ prefix. example, use geom_point(), give geom \"point\". information ways specify geom, see layer geom documentation. position position adjustment use data layer. can used various ways, including prevent overplotting improving display. position argument accepts following: result calling position function, position_jitter(). method allows passing extra arguments position. string naming position adjustment. give position string, strip function name position_ prefix. example, use position_jitter(), give position \"jitter\". information ways specify position, see layer position documentation. ... arguments passed layer()'s params argument. arguments broadly fall one 4 categories . Notably, arguments position argument, aesthetics required can passed .... Unknown arguments part 4 categories ignored. Static aesthetics mapped scale, fixed value apply layer whole. example, colour = \"red\" linewidth = 3. geom's documentation Aesthetics section lists available options. 'required' aesthetics passed params. Please note passing unmapped aesthetics vectors technically possible, order required length guaranteed parallel input data. constructing layer using stat_*() function, ... argument can used pass parameters geom part layer. example stat_density(geom = \"area\", outline.type = \"\"). geom's documentation lists parameters can accept. Inversely, constructing layer using geom_*() function, ... argument can used pass parameters stat part layer. example geom_area(stat = \"density\", adjust = 0.5). stat's documentation lists parameters can accept. key_glyph argument layer() may also passed .... can one functions described key glyphs, change display layer legend. na.rm FALSE, default, missing values removed warning. TRUE, missing values silently removed. show.legend logical. layer included legends? NA, default, includes aesthetics mapped. FALSE never includes, TRUE always includes. can also named logical vector finely select aesthetics display. inherit.aes FALSE, overrides default aesthetics, rather combining . useful helper functions define data aesthetics inherit behaviour default plot specification, e.g. borders().","code":""},{"path":[]},{"path":"/reference/stat_ssd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Species Sensitivity Data  — stat_ssd","text":"","code":"if (FALSE) { ggplot2::ggplot(ssddata::ccme_boron, ggplot2::aes(x = Conc)) +   stat_ssd() }"},{"path":"/reference/subset.fitdists.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset fitdists Object — subset.fitdists","title":"Subset fitdists Object — subset.fitdists","text":"Select subset distributions fitdists object. Akaike Information-theoretic Criterion differences calculated selecting distributions named select.","code":""},{"path":"/reference/subset.fitdists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset fitdists Object — subset.fitdists","text":"","code":"# S3 method for fitdists subset(x, select = names(x), delta = Inf, ...)"},{"path":"/reference/subset.fitdists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset fitdists Object — subset.fitdists","text":"x object. select character vector distributions select. delta non-negative number specifying maximum absolute AIC difference cutoff. Distributions absolute AIC difference greater delta excluded calculations. ... Unused.","code":""},{"path":"/reference/subset.fitdists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subset fitdists Object — subset.fitdists","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) subset(fits, c(\"gamma\", \"lnorm\")) #> Distribution 'gamma' #>   scale 25.1268 #>   shape 0.950179 #>  #> Distribution 'lnorm' #>   meanlog 2.56165 #>   sdlog 1.24154 #>  #> Parameters estimated from 28 rows of data."},{"path":"/reference/tidy.fitdists.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn a fitdists Object into a Tibble — tidy.fitdists","title":"Turn a fitdists Object into a Tibble — tidy.fitdists","text":"Turns fitdists object tidy tibble estimates (est) standard errors (se) terms (term) distributions (dist).","code":""},{"path":"/reference/tidy.fitdists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn a fitdists Object into a Tibble — tidy.fitdists","text":"","code":"# S3 method for fitdists tidy(x, all = FALSE, ...)"},{"path":"/reference/tidy.fitdists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn a fitdists Object into a Tibble — tidy.fitdists","text":"x object. flag specifying whether also return transformed parameters. ... Unused.","code":""},{"path":"/reference/tidy.fitdists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn a fitdists Object into a Tibble — tidy.fitdists","text":"tidy tibble estimates standard errors.","code":""},{"path":[]},{"path":"/reference/tidy.fitdists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Turn a fitdists Object into a Tibble — tidy.fitdists","text":"","code":"fits <- ssd_fit_dists(ssddata::ccme_boron) tidy(fits) #> # A tibble: 15 × 4 #>    dist        term           est    se #>    <chr>       <chr>        <dbl> <dbl> #>  1 gamma       scale       25.1   7.64  #>  2 gamma       shape        0.950 0.223 #>  3 lgumbel     locationlog  1.92  0.247 #>  4 lgumbel     scalelog     1.23  0.173 #>  5 llogis      locationlog  2.63  0.248 #>  6 llogis      scalelog     0.740 0.114 #>  7 lnorm       meanlog      2.56  0.235 #>  8 lnorm       sdlog        1.24  0.166 #>  9 lnorm_lnorm meanlog1     0.949 0.318 #> 10 lnorm_lnorm meanlog2     3.20  0.253 #> 11 lnorm_lnorm pmix         0.284 0.123 #> 12 lnorm_lnorm sdlog1       0.555 0.212 #> 13 lnorm_lnorm sdlog2       0.769 0.194 #> 14 weibull     scale       23.5   4.86  #> 15 weibull     shape        0.966 0.145 tidy(fits, all = TRUE) #> # A tibble: 24 × 4 #>    dist    term             est    se #>    <chr>   <chr>          <dbl> <dbl> #>  1 gamma   log_scale     3.22   0.304 #>  2 gamma   log_shape    -0.0511 0.234 #>  3 gamma   scale        25.1    7.64  #>  4 gamma   shape         0.950  0.223 #>  5 lgumbel locationlog   1.92   0.247 #>  6 lgumbel log_scalelog  0.209  0.140 #>  7 lgumbel scalelog      1.23   0.173 #>  8 llogis  locationlog   2.63   0.248 #>  9 llogis  log_scalelog -0.301  0.154 #> 10 llogis  scalelog      0.740  0.114 #> # ℹ 14 more rows"},{"path":[]},{"path":"/news/index.html","id":"additions-1-0-6-9015","dir":"Changelog","previous_headings":"","what":"Additions","title":"ssdtools 1.0.6.9015","text":"multi_est = TRUE argument calculate model averaged estimates treating distributions constituting single mixture distribution. method_ci = \"weighted_samples\" specify whether use \"weighted_samples\", \"weighted_arithmetic\", \"multi_free\" \"multi_fixed\" methods generate confidence intervals. samples argument include bootstrap samples list numeric vector(s). save_to argument specify directory save bootstrap datasets csv files parameter estimates rds files. files named data_000000001_xx.csv estimates_000000001_xx.rds etc xx distribution. parent data set estimates named boot_000000000_xx.csv estimates_000000000_xx.csv. Added ssd_hp_bcanz() ssd_hp.fitburrlioz() function get hazard proportions. Added trans = \"log10\" add_x = 0 arguments ssd_plot() ssd_plot_data(). Added ssd_pmulti(), ssd_qmulti() ssd_rmulti() combined mixture distributions. Added ssd_exx() functions get default parameter estimates distributions. Added David Fox Rebecca Fisher co-authors. Added npars argument ssd_dists_bcanz().","code":""},{"path":"/news/index.html","id":"modifications-1-0-6-9015","dir":"Changelog","previous_headings":"","what":"Modifications","title":"ssdtools 1.0.6.9015","text":"Changed min_pboot = 0.95 functions. estimates.fitdists() now includes weights returned parameters well all_estimates = FALSE argument allow parameter values implemented distributions included. ssd_fit_bcanz(), ssd_wqg_bc() ssd_wqg_burrlioz() longer rescale data default. rescale = TRUE now divides geometric mean minimum maximum positive finite values opposed dividing geometric mean maximum finite value. Replaced column percentage 0 100 proportion 0 1 output ssd_hc() Changed delta = 7 delta = 9.21 weight included models 0.01. seeds now allocated bootstrap samples opposed distributions (results speed gain cores number distributions). Exported dists = ssd_dists_bcanz() argument ssd_fit_bcanz() allow packages modify. Check ... unused appropriate. ssd_plot_cdf() now includes average distributions average = NA (@poissonconsulting, #351). switched logit_pmix pmix mixture distributions lnorm longer initializes optimization maximum likelihood estimates Offset starting values gompertz distribution.","code":""},{"path":"/news/index.html","id":"fixes-1-0-6-9015","dir":"Changelog","previous_headings":"","what":"Fixes","title":"ssdtools 1.0.6.9015","text":"ssd_hc() ssd_hp() now include parametric column. ssd_hp() now includes wt column","code":""},{"path":"/news/index.html","id":"deprecation-1-0-6-9015","dir":"Changelog","previous_headings":"","what":"Deprecation","title":"ssdtools 1.0.6.9015","text":"Soft-deprecated argument percent = 5 proportion = 0.05 ssd_hc() predict(). is_censored(), ssd_plot_cf() comma_signif(...) now warn deprecated unconditionally. plot.fitdists() now defunct. Removed defunct ssd_cfplot() Removed ccme_data ccme_boron data set.","code":""},{"path":"/news/index.html","id":"ssdtools-106","dir":"Changelog","previous_headings":"","what":"ssdtools 1.0.6","title":"ssdtools 1.0.6","text":"CRAN release: 2023-09-07 Fix CRAN ATLAS error","code":""},{"path":"/news/index.html","id":"ssdtools-105","dir":"Changelog","previous_headings":"","what":"ssdtools 1.0.5","title":"ssdtools 1.0.5","text":"CRAN release: 2023-08-29 Stopped predict hc/hp test errors linux.","code":""},{"path":"/news/index.html","id":"ssdtools-104","dir":"Changelog","previous_headings":"","what":"ssdtools 1.0.4","title":"ssdtools 1.0.4","text":"CRAN release: 2023-05-17 Added contributors. Now tests table values 6 significant figures. Fixed bug preserving NaN (returning NA_real_) cumulative distribution quantile functions.","code":""},{"path":"/news/index.html","id":"ssdtools-103","dir":"Changelog","previous_headings":"","what":"ssdtools 1.0.3","title":"ssdtools 1.0.3","text":"CRAN release: 2023-04-12 Replaced size = 0.5 linewidth = 0.5 geom_hcintersect() geom_xribbon(). Replaced aes_string() aes() examples (internally). Removed use tidyverse package. Now tests values 12 significant digits. Fixed description ssd_hp() percent affected rather percent protected.","code":""},{"path":"/news/index.html","id":"ssdtools-102","dir":"Changelog","previous_headings":"","what":"ssdtools 1.0.2","title":"ssdtools 1.0.2","text":"CRAN release: 2022-05-14 Fixed bug producing estimates 0 lower HCx values log-normal mixture model rescaled data spanning many orders magnitude.","code":""},{"path":"/news/index.html","id":"ssdtools-101","dir":"Changelog","previous_headings":"","what":"ssdtools 1.0.1","title":"ssdtools 1.0.1","text":"CRAN release: 2022-04-10 Added delta = 7 argument ssd_plot_cdf().","code":""},{"path":"/news/index.html","id":"ssdtools-100","dir":"Changelog","previous_headings":"","what":"ssdtools 1.0.0","title":"ssdtools 1.0.0","text":"CRAN release: 2022-04-01 ssdtools version 1.0.0 first major release ssdtools important improvements breaking changes.","code":""},{"path":"/news/index.html","id":"fitting-1-0-0","dir":"Changelog","previous_headings":"","what":"Fitting","title":"ssdtools 1.0.0","text":"important change functionality ssd_fit_dists() switch model fitting using fitdistrplus TMB resulted improved handling censored data. Although hoped model fitting faster currently case. result change fitdists objects returned ssd_fit_dists() previous versions ssdtools compatible major release regenerated.","code":""},{"path":"/news/index.html","id":"bcanz-1-0-0","dir":"Changelog","previous_headings":"","what":"BCANZ","title":"ssdtools 1.0.0","text":"result international collaboration British Columbia Canada Australia New Zealand selected set recommended distributions model averaging settings generating final guidelines. distributions {r} > ssd_dists_bcanz() [1] \"gamma\"       \"lgumbel\"     \"llogis\"      \"lnorm\"       \"lnorm_lnorm\" \"weibull\" ssd_fit_bcanz() ssd_hc_bcanz() functions added package facilitate fitting distributions estimation hazard concentrations using recommended settings.","code":""},{"path":"/news/index.html","id":"convergence-1-0-0","dir":"Changelog","previous_headings":"BCANZ","what":"Convergence","title":"ssdtools 1.0.0","text":"previous version ssdtools distribution considered converged following condition met stats::optim() returns code 0 (indicating successful completion). new version additional two conditions must also met Bounded parameters boundary (condition can turned setting at_boundary_ok = TRUE user can specify different boundary values - see ) Standard errors computable parameter values (condition can turned setting computable = FALSE)","code":""},{"path":"/news/index.html","id":"censored-data-1-0-0","dir":"Changelog","previous_headings":"BCANZ","what":"Censored Data","title":"ssdtools 1.0.0","text":"Censoring can now specified providing data set one rows finite value left column smaller finite value right column (interval censored) zero missing value left column finite value right column (left censored) currently possible fit distributions data sets infinite missing value right column finite value left column (right censored) Rows zero missing value left column infinite missing value right column (fully censored) uninformative result error.","code":""},{"path":"/news/index.html","id":"akaike-weights-1-0-0","dir":"Changelog","previous_headings":"BCANZ > Censored Data","what":"Akaike Weights","title":"ssdtools 1.0.0","text":"uncensored data, Akaike Weights calculated using AICc (corrects small sample size). case censored data, Akaike Weights calculated using AIC (sample size estimated) distributions number parameters (ensure weights valid).","code":""},{"path":"/news/index.html","id":"weighted-data-1-0-0","dir":"Changelog","previous_headings":"BCANZ","what":"Weighted Data","title":"ssdtools 1.0.0","text":"Weighting must positive values <= 1000.","code":""},{"path":"/news/index.html","id":"distributions-1-0-0","dir":"Changelog","previous_headings":"BCANZ","what":"Distributions","title":"ssdtools 1.0.0","text":"Previously density functions available distributions exported R functions make accessible fitdistrplus. meant ssdtools loaded fit distributions. density functions now defined C++ TMB templates longer exported. distribution, quantile random generation functions generally useful still exported now prefixed ssd_ prevent clashes existing functions packages. Thus example plnorm(), qlnorm() rlnorm() renamed ssd_plnorm(), ssd_qlnorm() ssd_rlnorm(). following distributions added (case burrIII3 readded) new version burrIII3 - burrIII three parameter distribution invpareto - inverse pareto (bias correction scale order statistic) lnorm_lnorm log-normal/log-normal mixture distribution llogis_llogis log-logistic/log-logistic mixture distribution following arguments added ssd_fit_dists() rescale (default FALSE) specify whether rescale concentrations values dividing largest (finite) value. alters parameter estimates, can help distributions converge, estimates hazard concentrations/protections. reweight (default FALSE) specify whether reweight data points dividing largest weight. at_boundary_ok (default FALSE) specifying whether distribution one parameters boundary converged. min_pmix (default 0) specify boundary minimum proportion mixture distribution. range_shape1 (default c(0.05, 20)) specify lower upper boundaries shape1 parameter burrIII3 distribution. range_shape2 (default range_shape2) specify lower upper boundaries shape2 parameter burrIII3 distribution. control (default empty list) pass list control parameters stats::optim(). also worth noting default value computable argument switched FALSE TRUE enforce stricter requirements convergence (see ).","code":""},{"path":"/news/index.html","id":"subsets-of-distributions-1-0-0","dir":"Changelog","previous_headings":"BCANZ > Distributions","what":"Subsets of Distributions","title":"ssdtools 1.0.0","text":"following added handle multiple distributions ssd_dists() specify subsets available distributions. delta argument (default 7) subset() generic keep distributions within specified AIC(c) difference best supported distribution.","code":""},{"path":"/news/index.html","id":"burrlioz-1-0-0","dir":"Changelog","previous_headings":"BCANZ","what":"Burrlioz","title":"ssdtools 1.0.0","text":"function ssd_fit_burrlioz() added approximate behaviour Burrlioz.","code":""},{"path":"/news/index.html","id":"hazard-concentrationprotection-estimation-1-0-0","dir":"Changelog","previous_headings":"","what":"Hazard Concentration/Protection Estimation","title":"ssdtools 1.0.0","text":"Hazard concentration estimation performed ssd_hc() (wrapped predict()) hazard protection estimation ssd_hp(). default confidence intervals estimated parametric bootstrapping. reduce time required bootstrapping, parallelization implemented using future package. following arguments added ssd_hc() ssd_hp() delta (default 7) keep distributions within specified AIC difference best supported distribution. min_pboot (default 0.90) specify minimum proportion bootstrap samples must successfully fit. parametric (default TRUE) allow non-parametric bootstrapping. control (default empty list) pass list control parameters stats::optim(). following columns added output data frame wt specify Akaike weight. method indicate whether parametric non-parametric bootstrap used. nboot indicate many bootstrap samples used. pboot indicate proportion bootstrap samples fitted. also worth noting dist column moved last first position output data frame.","code":""},{"path":"/news/index.html","id":"censored-data-1-0-0-1","dir":"Changelog","previous_headings":"Hazard Concentration/Protection Estimation","what":"Censored Data","title":"ssdtools 1.0.0","text":"Confidence intervals estimated interval censored data.","code":""},{"path":"/news/index.html","id":"weighted-data-1-0-0-1","dir":"Changelog","previous_headings":"Hazard Concentration/Protection Estimation","what":"Weighted Data","title":"ssdtools 1.0.0","text":"Confidence intervals estimated unequally weighted data.","code":""},{"path":"/news/index.html","id":"goodness-of-fit-1-0-0","dir":"Changelog","previous_headings":"","what":"Goodness of Fit","title":"ssdtools 1.0.0","text":"pvalue argument (default FALSE) added ssd_gof() specify whether return p-values test statistics opposed test statistics .","code":""},{"path":"/news/index.html","id":"plotting-1-0-0","dir":"Changelog","previous_headings":"","what":"Plotting","title":"ssdtools 1.0.0","text":"also substantive changes plotting functionality. Added following functions ssd_plot_data() plot censored uncensored data calling geom_ssdpoint() left right column (alpha parameter values adjusted accordingly) geom_ssdsegment() allow plotting range censored data points using segments. scale_colour_ssd() (scale_color_ssd()) provide 8 color-blind scale. Made following changes ssd_plot() added bounds (default c(left = 1, right = 1)) argument specify many orders magnitude extend plot beyond minimum maximum (non-missing) values. added linetype (default NULL) argument specify line type. added linecolor (default NULL) argument specify line color. changed default value ylab “Percent Species Affected” “Species Affected”. Renamed - GeomSsd GeomSsdpoint. - StatSsd StatSsdpoint Soft-deprecated - geom_ssd() geom_ssdpoint(). - stat_ssd(). - ssd_plot_cf() fitdistrplus::descdist().","code":""},{"path":[]},{"path":"/news/index.html","id":"ssddata-1-0-0","dir":"Changelog","previous_headings":"Data","what":"ssddata","title":"ssdtools 1.0.0","text":"dataset boron_data renamed ccme_boron moved ssddata R package together CCME datasets. ssddata package provides suite datasets testing comparing species sensitivity distribution fitting software.","code":""},{"path":"/news/index.html","id":"data-handling-functions-1-0-0","dir":"Changelog","previous_headings":"Data","what":"Data Handling Functions","title":"ssdtools 1.0.0","text":"Added ssd_data() return original data fitdists object. ssd_ecd_data() get empirical cumulative density data. ssd_sort_data() sort data empirical cumulative density.","code":""},{"path":"/news/index.html","id":"miscellaneous-1-0-0","dir":"Changelog","previous_headings":"","what":"Miscellaneous","title":"ssdtools 1.0.0","text":"npars() now orders distribution name. functions arguments soft-deprecated prior v0.3.0 now warn unconditionally.","code":""},{"path":"/news/index.html","id":"generics-1-0-0","dir":"Changelog","previous_headings":"Miscellaneous","what":"Generics","title":"ssdtools 1.0.0","text":"Implemented following generics fitdists objects glance() get model likelihoods, information-theoretic criteria etc. augment() return original data set. logLik() return log-likelihood. summary.fitdists() summarize.","code":""},{"path":"/news/index.html","id":"ssdtools-0379000","dir":"Changelog","previous_headings":"","what":"ssdtools 0.3.7.9000","title":"ssdtools 0.3.7.9000","text":"previous version.","code":""},{"path":"/news/index.html","id":"ssdtools-037","dir":"Changelog","previous_headings":"","what":"ssdtools 0.3.7","title":"ssdtools 0.3.7","text":"CRAN release: 2021-10-27 fix unequal indentation Rmd ```","code":""},{"path":"/news/index.html","id":"ssdtools-036","dir":"Changelog","previous_headings":"","what":"ssdtools 0.3.6","title":"ssdtools 0.3.6","text":"CRAN release: 2021-09-22 Added wt (Akaike weight) column predict(), ssd_hc() ssd_hp() Deprecated argument ic predict(), ssd_hc() ssd_hp() unused. Silenced output ssd_fit_dists().","code":""},{"path":"/news/index.html","id":"ssdtools-035","dir":"Changelog","previous_headings":"","what":"ssdtools 0.3.5","title":"ssdtools 0.3.5","text":"CRAN release: 2021-09-03 Bump requirement R >= 4.1 actuar package.","code":""},{"path":"/news/index.html","id":"ssdtools-034","dir":"Changelog","previous_headings":"","what":"ssdtools 0.3.4","title":"ssdtools 0.3.4","text":"CRAN release: 2021-05-14 Update Apache License url https.","code":""},{"path":"/news/index.html","id":"ssdtools-033","dir":"Changelog","previous_headings":"","what":"ssdtools 0.3.3","title":"ssdtools 0.3.3","text":"CRAN release: 2021-02-19 Increased requirement R >= 3.5 due VGAM. Modified comma_signif() now rounds 3 significant digits default applies scales::comma() values >= 1000. Soft-deprecated ... argument comma_signif().","code":""},{"path":"/news/index.html","id":"ssdtools-032","dir":"Changelog","previous_headings":"","what":"ssdtools 0.3.2","title":"ssdtools 0.3.2","text":"CRAN release: 2020-09-02 Fix moved URLs.","code":""},{"path":"/news/index.html","id":"ssdtools-031","dir":"Changelog","previous_headings":"","what":"ssdtools 0.3.1","title":"ssdtools 0.3.1","text":"CRAN release: 2020-09-01 Internal changes .","code":""},{"path":"/news/index.html","id":"ssdtools-030","dir":"Changelog","previous_headings":"","what":"ssdtools 0.3.0","title":"ssdtools 0.3.0","text":"CRAN release: 2020-07-09","code":""},{"path":"/news/index.html","id":"breaking-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"ssdtools 0.3.0","text":"Soft-deprecated ‘burrIII3’ distribution poorly defined. Soft-deprecated ‘pareto’ distribution poor fit SSD data.","code":""},{"path":"/news/index.html","id":"major-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"ssdtools 0.3.0","text":"Reparameterized ‘llogis’ distribution terms locationlog scalelog. Reparameterized ‘burrIII3’ distribution terms lshape1, lshape2 lscale. Reparamaterized ‘burrIII2’ distribution terms locationlog scalelog. Reparamaterized ‘lgumbel’ distribution terms locationlog scalelog. Reparamaterized ‘gompertz’ distribution terms llocation lshape. Standardized handling arguments d,p,q,r s functions distributions.","code":""},{"path":"/news/index.html","id":"minor-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"ssdtools 0.3.0","text":"rdist() functions now use length n length(n) > 1. Added slnorm() get starting values ‘dlnorm’ distribution.","code":""},{"path":"/news/index.html","id":"internal-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Internal Changes","title":"ssdtools 0.3.0","text":"Switch C++ implementation distributions.","code":""},{"path":"/news/index.html","id":"ssdtools-020","dir":"Changelog","previous_headings":"","what":"ssdtools 0.2.0","title":"ssdtools 0.2.0","text":"CRAN release: 2020-04-15","code":""},{"path":"/news/index.html","id":"breaking-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"ssdtools 0.2.0","text":"Changed computable (whether standard errors must computable considered converged) FALSE default. Enforces one ‘llogis’, ‘llog’ ‘burrIII2’ sets (identical).","code":""},{"path":"/news/index.html","id":"major-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"ssdtools 0.2.0","text":"Deprecated ‘burrIII2’ ‘llogis’ identical. Replaced ‘burrIII2’ (identical) ‘llogis’ default set. Fixed bug rllog() causing error. Fixed parameterisation ‘lgumbel’ causing fail fit data.","code":""},{"path":"/news/index.html","id":"minor-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"ssdtools 0.2.0","text":"Provides warning message change default ci argument predict function. gives warning standard errors computable computable = TRUE. Uses tibble package create tibbles. Removed dependency checkr.","code":""},{"path":"/news/index.html","id":"ssdtools-011","dir":"Changelog","previous_headings":"","what":"ssdtools 0.1.1","title":"ssdtools 0.1.1","text":"CRAN release: 2020-01-24 Fix test CRAN R 3.5","code":""},{"path":"/news/index.html","id":"ssdtools-010","dir":"Changelog","previous_headings":"","what":"ssdtools 0.1.0","title":"ssdtools 0.1.0","text":"CRAN release: 2020-01-13","code":""},{"path":"/news/index.html","id":"breaking-changes-0-1-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"ssdtools 0.1.0","text":"Default distributions changed ‘burrIII2’, ‘gamma’ ‘lnorm’ ‘gamma’, ‘gompertz’, ‘lgumbel’, ‘llog’, ‘lnorm’ ‘weibull’. Changed implicit behaviour ssd_hc() predict() ci = TRUE explicit ssd_hc(ci = FALSE) predict(ci = FALSE). Replaced shape scale arguments llog() lshape lscale. Replaced location scale arguments lgumbel() llocation lscale.","code":""},{"path":"/news/index.html","id":"major-features-0-1-0","dir":"Changelog","previous_headings":"","what":"Major Features","title":"ssdtools 0.1.0","text":"Added Burr Type-III Two-Parameter Distribution (burrIII2). Added ssd_hp() calculate hazard percent specific concentrations. Added ssd_exposure() calculate proportion exposed based distribution concentrations. Optimized predict() added parallel argument. Tidyverse style error warning messages.","code":""},{"path":"/news/index.html","id":"minor-features-0-1-0","dir":"Changelog","previous_headings":"","what":"Minor Features","title":"ssdtools 0.1.0","text":"ssd_fit_dists() now checks standard errors computable. Added Burr Type-III Three-Parameter Distribution (burrIII3). Added sdist(x) functionality set starting values distributions. Added ssd_plot_cdf() plot cumulative distribution function (equivalent autoplot()) nobs() censored data now returns missing value. Default ssd_fit_dists() distributions now ordered alphabetically.","code":""},{"path":"/news/index.html","id":"deprecated-0-1-0","dir":"Changelog","previous_headings":"","what":"Deprecated","title":"ssdtools 0.1.0","text":"Deprecated ssd_hc() argument hc = 5L percent = 5L. Deprecated dllog() etc dllogis(). Deprecated ssd_cfplot() ssd_plot_cf().","code":""},{"path":"/news/index.html","id":"bug-fixes-0-1-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"ssdtools 0.1.0","text":"Fixed llog distribution small concentrations. Ensured concentrations 1 1 significant figure plots.","code":""},{"path":"/news/index.html","id":"ssdtools-003","dir":"Changelog","previous_headings":"","what":"ssdtools 0.0.3","title":"ssdtools 0.0.3","text":"CRAN release: 2018-11-25 added citation Added ssdtools-manual vignette Changed predict() ssd_hc() nboot argument 1001 1000 Added hc5_boron data object longer export ssd_fit_dist() ssd_fit_dists() renders redundant geom_hcintersect() now takes multiple values information DESCRIPTION Added CRAN badge Removed dependencies: dplyr, magrittr, plyr, purrr Moved depends imports: VGAM, fitdistrplus, graphics, ggplot, stats Moved imports suggests: tibble","code":""},{"path":"/news/index.html","id":"ssdtools-002","dir":"Changelog","previous_headings":"","what":"ssdtools 0.0.2","title":"ssdtools 0.0.2","text":"CRAN release: 2018-10-14 Added contributors Added hex","code":""},{"path":"/news/index.html","id":"ssdtools-001","dir":"Changelog","previous_headings":"","what":"ssdtools 0.0.1","title":"ssdtools 0.0.1","text":"Initial Release","code":""}]
